{"meta":{"version":1,"warehouse":"1.0.3"},"models":{"Asset":[{"_id":"source/upload/image/avatar.png","path":"upload/image/avatar.png","modified":0},{"_id":"source/robots.txt","path":"robots.txt","modified":0},{"_id":"source/mail.gif","path":"mail.gif","modified":0},{"_id":"source/favicon.ico","path":"favicon.ico","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","path":"vendors/velocity/velocity.ui.min.js","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","path":"vendors/velocity/velocity.ui.js","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","path":"vendors/velocity/velocity.min.js","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.js","path":"vendors/velocity/velocity.js","modified":0},{"_id":"themes/next/source/vendors/velocity/bower.json","path":"vendors/velocity/bower.json","modified":0},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.scrollstop.js","path":"vendors/jquery_lazyload/jquery.scrollstop.js","modified":0},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.lazyload.js","path":"vendors/jquery_lazyload/jquery.lazyload.js","modified":0},{"_id":"themes/next/source/vendors/jquery_lazyload/bower.json","path":"vendors/jquery_lazyload/bower.json","modified":0},{"_id":"themes/next/source/vendors/jquery_lazyload/README.md","path":"vendors/jquery_lazyload/README.md","modified":0},{"_id":"themes/next/source/vendors/jquery_lazyload/CONTRIBUTING.md","path":"vendors/jquery_lazyload/CONTRIBUTING.md","modified":0},{"_id":"themes/next/source/vendors/jquery/index.js","path":"vendors/jquery/index.js","modified":0},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff2","path":"vendors/font-awesome/fonts/fontawesome-webfont.woff2","modified":0},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff","path":"vendors/font-awesome/fonts/fontawesome-webfont.woff","modified":0},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.ttf","path":"vendors/font-awesome/fonts/fontawesome-webfont.ttf","modified":0},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.svg","path":"vendors/font-awesome/fonts/fontawesome-webfont.svg","modified":0},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.eot","path":"vendors/font-awesome/fonts/fontawesome-webfont.eot","modified":0},{"_id":"themes/next/source/vendors/font-awesome/fonts/FontAwesome.otf","path":"vendors/font-awesome/fonts/FontAwesome.otf","modified":0},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.min.css","path":"vendors/font-awesome/css/font-awesome.min.css","modified":0},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css.map","path":"vendors/font-awesome/css/font-awesome.css.map","modified":0},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css","path":"vendors/font-awesome/css/font-awesome.css","modified":0},{"_id":"themes/next/source/vendors/font-awesome/bower.json","path":"vendors/font-awesome/bower.json","modified":0},{"_id":"themes/next/source/vendors/font-awesome/HELP-US-OUT.txt","path":"vendors/font-awesome/HELP-US-OUT.txt","modified":0},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.min.js","path":"vendors/fastclick/lib/fastclick.min.js","modified":0},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.js","path":"vendors/fastclick/lib/fastclick.js","modified":0},{"_id":"themes/next/source/vendors/fastclick/bower.json","path":"vendors/fastclick/bower.json","modified":0},{"_id":"themes/next/source/vendors/fastclick/README.md","path":"vendors/fastclick/README.md","modified":0},{"_id":"themes/next/source/vendors/fastclick/LICENSE","path":"vendors/fastclick/LICENSE","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","path":"vendors/fancybox/source/jquery.fancybox.pack.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","path":"vendors/fancybox/source/jquery.fancybox.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","path":"vendors/fancybox/source/jquery.fancybox.css","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","path":"vendors/fancybox/source/helpers/fancybox_buttons.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","path":"vendors/fancybox/source/fancybox_sprite@2x.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","path":"vendors/fancybox/source/fancybox_sprite.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","path":"vendors/fancybox/source/fancybox_overlay.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","path":"vendors/fancybox/source/fancybox_loading@2x.gif","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","path":"vendors/fancybox/source/fancybox_loading.gif","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","path":"vendors/fancybox/source/blank.gif","modified":0},{"_id":"themes/next/source/js/ua-parser.min.js","path":"js/ua-parser.min.js","modified":0},{"_id":"themes/next/source/js/motion.js","path":"js/motion.js","modified":0},{"_id":"themes/next/source/js/hook-duoshuo.js","path":"js/hook-duoshuo.js","modified":0},{"_id":"themes/next/source/js/helpers.js","path":"js/helpers.js","modified":0},{"_id":"themes/next/source/js/fancy-box.js","path":"js/fancy-box.js","modified":0},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","path":"js/bootstrap.scrollspy.js","modified":0},{"_id":"themes/next/source/js/bootstrap.js","path":"js/bootstrap.js","modified":0},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0},{"_id":"source/CNAME","path":"CNAME","modified":0}],"Cache":[{"_id":"source/404.html","shasum":"15b3008eb9f50e42d1589516d00f68d0f54a3887","modified":1452652240153},{"_id":"source/404_old.html","shasum":"b6aeb71b363dfbbb24bbb74f3e33e02e7abfd44c","modified":1452652240159},{"_id":"source/CNAME","shasum":"211316d9451b7030c6a24b89c228e7d5ef540a99","modified":1461134754834},{"_id":"source/_posts/2015-campus-recruit-summary.md","shasum":"43b7f17354de5d0289c83161a18e9e3fdc34e642","modified":1457398530999},{"_id":"source/_posts/2015-campus-recurit-technology-interview-summary.md","shasum":"401bdc166ba467aafbe5b8a7285a828ceaf13b0b","modified":1464058381126},{"_id":"source/_posts/blog-on-gitcafe-with-dns-settings.md","shasum":"fae28e178265c305494161fe987cc5921ccc2722","modified":1463046000840},{"_id":"source/_posts/cnn-apply-on-modelling-sentence.md","shasum":"754bb470cc07524cd4214e5bf27aa58cefdc5655","modified":1460365121081},{"_id":"source/_posts/cnn-learning-notes-1.md","shasum":"e2db540a8def1db8d005421e88c066229e6847a7","modified":1457489565988},{"_id":"source/_posts/cnn-learning-notes-2.md","shasum":"6651fd72b87f59d18b9e936631afcd0e94bf2167","modified":1457004339607},{"_id":"source/_posts/hexo-github-blog-building.md","shasum":"90293a8d599c1ecd428c82bad562425c8d20cb0f","modified":1453475182739},{"_id":"source/_posts/hexo-next-add-post-views.md","shasum":"b5280a642565824dd3aee5879a43c90ad3f4dbc4","modified":1461134754834},{"_id":"source/_posts/hexo-website-seo.md","shasum":"be4575cb786caad10f2ba0b8c657fc596d80ac46","modified":1453643441931},{"_id":"source/_posts/how-to-insert-equations-in-markdown.md","shasum":"b17402029e9a916d6f87b9e2802725d7301c3f32","modified":1456987969879},{"_id":"source/_posts/introduction-to-word-representation.md","shasum":"a28127e4563197577a564fec15c1c575e47f37b4","modified":1461134754834},{"_id":"source/_posts/markdown-common-problems.md","shasum":"caafa8728c72f98010e238619a9c9f93e89ee8fd","modified":1459410181321},{"_id":"source/_posts/network-connection-problems-in-win10.md","shasum":"42f1204c92364f63a0bc86f5171376337cad1ee2","modified":1456483775539},{"_id":"source/_posts/next-theme-personal-settings.md","shasum":"e492693728db9bfcbe41ee803e9ef8222cd28d26","modified":1453475474081},{"_id":"source/_posts/problems-with-solution-in-tensorflow.md","shasum":"35533040762fa3a5d5d42e366e9408885ffc890f","modified":1458984511290},{"_id":"source/_posts/python-learning-notes-and-common-problems.md","shasum":"dd72d31204dbc9c5e94d5b4d4afb90ad5074cdec","modified":1462706996174},{"_id":"source/_posts/realization-of-full-chinese-text-search-using-whoosh-and-jieba.md","shasum":"695af5e74977b602c4dc367a8ee76f797cb04bde","modified":1462706996181},{"_id":"source/_posts/tensorflow-learning-notes-2.md","shasum":"bcbba599184c65df225ee8c066d139c9a2c67e67","modified":1462706976750},{"_id":"source/_posts/tensorflow-learning-notes-3.md","shasum":"1a4fb465b8d04ab17343e01575d6b83a0a72e256","modified":1458220503661},{"_id":"source/_posts/tensorflow-learning-notes.md","shasum":"e89dc72034736310cf3c49added041eb28d4d4fd","modified":1458524909695},{"_id":"source/about/index.md","shasum":"30924acaafccbd688ee4cb907f9ab8bcf28c0459","modified":1453641581927},{"_id":"source/categories/index.md","shasum":"1ef3d0c994054bfe4518a11822058937e1096340","modified":1452652240212},{"_id":"source/favicon.ico","shasum":"9eae51ac749b50c6ebe4d1d69e4fc56bc14bbb5e","modified":1461134754834},{"_id":"source/mail.gif","shasum":"a861aea9d589b864c990040488974fbbcc6e5d3e","modified":1461134754834},{"_id":"source/robots.txt","shasum":"ab72d2370ef57792c98fd11375a904fcd2c2821e","modified":1452652240216},{"_id":"source/tags/index.md","shasum":"8890f2cc83e67227bb5f517fac2197ccd300e777","modified":1452652240223},{"_id":"source/upload/image/avatar.png","shasum":"4cd3d5741c7bd49e4dfbeec7cc92a3ce37416ce1","modified":1461134754834},{"_id":"themes/next/source/css/_common/_page/home.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1461134754846},{"_id":"themes/next/source/css/_mixins/Mist.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1461134754846},{"_id":"themes/next/source/css/_mixins/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1461134754846},{"_id":"themes/next/source/css/_mixins/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1461134754846},{"_id":"themes/next/README.en.md","shasum":"fa31bbc6dd8778b8dee469740c92b3b5b59702af","modified":1452652240883},{"_id":"themes/next/README.md","shasum":"b2499c61ef9cf6ee31ed5606ed43ef247c73de63","modified":1452652240889},{"_id":"themes/next/_config.yml","shasum":"07b2c6af593d8296db06ef2faa73bb885b7ae44f","modified":1452652240893},{"_id":"themes/next/bower.json","shasum":"d46717b4a025790cda33d78339780c8749aee7fd","modified":1452652240896},{"_id":"themes/next/languages/de.yml","shasum":"3af67eda28640a99e17d06eec0c664e54e95fb2d","modified":1452652240897},{"_id":"themes/next/languages/default.yml","shasum":"982bfffdb6ab495867255e79d852a9adb68bd10c","modified":1452652240901},{"_id":"themes/next/languages/en.yml","shasum":"212b142c5a597936f63915e7524623e11872cdea","modified":1453378768005},{"_id":"themes/next/languages/fr-FR.yml","shasum":"eb05b50f49a29d46e90e45fabb12a14be6d7631d","modified":1452652240908},{"_id":"themes/next/languages/pt.yml","shasum":"e32711ad646d05911b515cc30e14c57f534a0045","modified":1452652240912},{"_id":"themes/next/languages/ru.yml","shasum":"4d1c2d4f4040d447a3511da51dc9fea7b177a7a6","modified":1452652240916},{"_id":"themes/next/languages/zh-Hans.yml","shasum":"dfd2010063de0cba30bacefa7887d408999ca50a","modified":1453378751858},{"_id":"themes/next/languages/zh-hk.yml","shasum":"f80a494ecf23166152011cb5f4e9174fefa9197c","modified":1452652240924},{"_id":"themes/next/languages/zh-tw.yml","shasum":"f60af901f90fab657a1d27f981ad3381069842d0","modified":1452652240927},{"_id":"themes/next/layout/_layout.swig","shasum":"900470e2d47aee37dc68c915e5d35353ff5282ff","modified":1453378609290},{"_id":"themes/next/layout/_macro/post-collapse.swig","shasum":"60766ca0cf5ba834d445c3304695d1a7ce0e1a36","modified":1452652240935},{"_id":"themes/next/layout/_macro/post.swig","shasum":"671dbd612ccc80eb157cddf443da40edf5c62053","modified":1453430168300},{"_id":"themes/next/layout/_macro/sidebar.swig","shasum":"c0f68851e8835b41fb60e7a78f096235067f7754","modified":1452652240946},{"_id":"themes/next/layout/_partials/comments.swig","shasum":"93055fc8e034037321280c182997a2a726e10c41","modified":1452652240950},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","shasum":"ba75672183d94f1de7c8bd0eeee497a58c70e889","modified":1452652240953},{"_id":"themes/next/layout/_partials/footer.swig","shasum":"ffeea8af8140f4c35f68539f1737dea2c0a110d5","modified":1453513168510},{"_id":"themes/next/layout/_partials/head.swig","shasum":"471e197800829e9704ba9bb8f2d8f342c3e65c44","modified":1452652240963},{"_id":"themes/next/layout/_partials/header.swig","shasum":"8c8ae71c41722815540950ccefac47d6876d0413","modified":1452652240967},{"_id":"themes/next/layout/_partials/old-browsers.swig","shasum":"3c4d930d34c234725065173780a23673e1c574f5","modified":1452652240971},{"_id":"themes/next/layout/_partials/pagination.swig","shasum":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1452652240974},{"_id":"themes/next/layout/_partials/search/swiftype.swig","shasum":"73e8294939bbbb46755798215c605ebe5af5918f","modified":1452652240984},{"_id":"themes/next/layout/_partials/search/tinysou.swig","shasum":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1452652240988},{"_id":"themes/next/layout/_partials/search.swig","shasum":"1b86eb85017599392071d1230171e900045f8e69","modified":1452652240978},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","shasum":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1452652240992},{"_id":"themes/next/layout/_partials/share/jiathis.swig","shasum":"12684840de632eb16e53ffa863166306a756fd4f","modified":1452652240998},{"_id":"themes/next/layout/_scripts/analytics/baidu-analytics.swig","shasum":"ae5b8597603d4e42ee66ed121544e7b1c644767e","modified":1452652241009},{"_id":"themes/next/layout/_scripts/analytics/facebook-sdk.swig","shasum":"61347b9cf5c42a02f28cda4b6d920d6d17099d44","modified":1452652241015},{"_id":"themes/next/layout/_scripts/analytics/google-analytics.swig","shasum":"1b6af02fd0ba3f729675cd95429a0cea4aebf358","modified":1452652241044},{"_id":"themes/next/layout/_scripts/analytics.swig","shasum":"5e1b2b547a8f07ea0e3ab2a97dac9cc7d1e13c9a","modified":1452652241001},{"_id":"themes/next/layout/_scripts/baidushare.swig","shasum":"640d4dda003f54a0dffa4508fba4d91ac0dcfa6e","modified":1452652241050},{"_id":"themes/next/layout/_scripts/bootstrap.scrollspy.swig","shasum":"0aad8d447567b683108b274c841c536b2daa176d","modified":1452652241054},{"_id":"themes/next/layout/_scripts/comments/disqus.swig","shasum":"c1186e609d4810ebfb3e675e9045b023a557d1db","modified":1452652241061},{"_id":"themes/next/layout/_scripts/comments/duoshuo.swig","shasum":"b03b2f596b7b9795f63dc4174329bf14aee7a48c","modified":1452652241069},{"_id":"themes/next/layout/_scripts/fancy-box.swig","shasum":"701dfc53d750635de2f08f08d072d6ceb83b636c","modified":1452652241074},{"_id":"themes/next/layout/_scripts/helpers.swig","shasum":"4d2cbfca0aaf546a2b5813288073e824c1498fdf","modified":1461134754846},{"_id":"themes/next/layout/_scripts/lean-analytics.swig","shasum":"19afa1a4a829d6b789d0b87ecb0f4dbd6dc7e5df","modified":1453381132962},{"_id":"themes/next/layout/_scripts/mathjax.swig","shasum":"8eecd19c756df615afb3f5ec6a527cd7bd06d20c","modified":1452652241088},{"_id":"themes/next/layout/_scripts/motion.swig","shasum":"de1fc505acbe8dc84f7376fe6ae9871f22d5582e","modified":1452652241092},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","shasum":"ac600616e83e23ee446a646c57500706936bb45e","modified":1452652241106},{"_id":"themes/next/layout/_scripts/tinysou.swig","shasum":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1452652241113},{"_id":"themes/next/layout/archive.swig","shasum":"40e899e690172d8dd19317b17ec7be94406f114f","modified":1452652241122},{"_id":"themes/next/layout/category.swig","shasum":"c777432e1587826ccad5a4aa50309763a82df52b","modified":1452652241127},{"_id":"themes/next/layout/index.swig","shasum":"7e7e463a9e5f513d83805d72ef75fa0e862df754","modified":1452652241130},{"_id":"themes/next/layout/page.swig","shasum":"a91e3fd7aef26e8a02e339e3372801c517f400cf","modified":1452652241131},{"_id":"themes/next/layout/post.swig","shasum":"e67a6aabe4d71cbcf01a4cace652424bd49acc9b","modified":1452652241134},{"_id":"themes/next/layout/tag.swig","shasum":"06417b0b050c66d816323b6178c9376ba2e58dd9","modified":1452652241141},{"_id":"themes/next/scripts/filters/sticky.js","shasum":"4e4c9a837e186f94f256bd6eabb89b138cfc0db6","modified":1452652241145},{"_id":"themes/next/scripts/merge-configs.js","shasum":"f8cde6953939802f92da5b7a2458c6c539e9be69","modified":1452652241151},{"_id":"themes/next/scripts/tags/center-quote.js","shasum":"99b66949f18398689b904907af23c013be1b978f","modified":1452652241156},{"_id":"themes/next/scripts/tags/full-image.js","shasum":"86194a05a8c6499de0b2aaa525d6de135778c0ae","modified":1452652241160},{"_id":"themes/next/scripts/tags/group-pictures.js","shasum":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1452652241167},{"_id":"themes/next/source/css/_common/_component/back-to-top.styl","shasum":"dac21141c7893ab9de697a8183d3b3f4eb7f0a5a","modified":1452652241171},{"_id":"themes/next/source/css/_common/_component/blockquote-center.styl","shasum":"2fe76476432b31993338cb45cdb3b29a518b6379","modified":1452652241175},{"_id":"themes/next/source/css/_common/_component/buttons.styl","shasum":"0a1730773478d843e123404ab4dae24d7cb0f2b7","modified":1452652241179},{"_id":"themes/next/source/css/_common/_component/comments.styl","shasum":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1452652241182},{"_id":"themes/next/source/css/_common/_component/duoshuo.styl","shasum":"cd2ec04433d6c98a0994945475fb47155d1015c0","modified":1452652241185},{"_id":"themes/next/source/css/_common/_component/gallery.styl","shasum":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1452652241190},{"_id":"themes/next/source/css/_common/_component/group-pictures.styl","shasum":"70d7c3b5f8f2485dcce1a27e2c9b43df988fbc6f","modified":1452652241193},{"_id":"themes/next/source/css/_common/_component/jiathis.styl","shasum":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1452652241196},{"_id":"themes/next/source/css/_common/_component/pagination.styl","shasum":"88559b13ce94311405b170a0506ded91273beceb","modified":1452652241200},{"_id":"themes/next/source/css/_common/_component/posts-collapse.styl","shasum":"8909298333c6dfc6e3686d85e4d98c76dfcf75c9","modified":1452652241204},{"_id":"themes/next/source/css/_common/_component/posts-expand.styl","shasum":"008d5f951144c7fe5c7e66dac330d5fb715a0a83","modified":1452652241208},{"_id":"themes/next/source/css/_common/_component/posts-type.styl","shasum":"f28f00b2acb0df0343e77400bcc8246b40ac046c","modified":1452652241211},{"_id":"themes/next/source/css/_common/_component/posts.styl","shasum":"52badf0e8a0a44bb67f16486ada44d945b1aba6b","modified":1452652241214},{"_id":"themes/next/source/css/_common/_component/tag-cloud.styl","shasum":"6eb4bcc3056bd279d000607e8b4dad50d368ca69","modified":1452652241217},{"_id":"themes/next/source/css/_common/_core/base.styl","shasum":"90a36892f5f595dda58a86901782b1addbdb3b46","modified":1452652241223},{"_id":"themes/next/source/css/_common/_core/helpers.styl","shasum":"b8e1b52b7aaa94b7c52d1681225e80f1af1219fa","modified":1452652241228},{"_id":"themes/next/source/css/_common/_core/normalize.styl","shasum":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1452652241232},{"_id":"themes/next/source/css/_common/_core/scaffolding.styl","shasum":"3702c4c350524622f7dd658b05449fc425a819ef","modified":1452652241236},{"_id":"themes/next/source/css/_common/_core/tables.styl","shasum":"16a98866f5025c050c56e52312228355a16d00d9","modified":1452652241240},{"_id":"themes/next/source/css/_common/_fonts/icon-default.styl","shasum":"c46d16429b85570347373fd11db8c222f6ff914e","modified":1452652241244},{"_id":"themes/next/source/css/_common/_fonts/icon-feather.styl","shasum":"7bdc92a55f2eee20b6b546e93e4566696b459b9d","modified":1452652241248},{"_id":"themes/next/source/css/_common/_fonts/icon-fifty-shades.styl","shasum":"dbb0843ea5aa7c2ac2755a2d1ce60fa662f1b939","modified":1452652241252},{"_id":"themes/next/source/css/_common/_fonts/icon-font.styl","shasum":"692c01dcdc612c3e1e245cf93d0ace0a4e2aaf3f","modified":1452652241257},{"_id":"themes/next/source/css/_common/_fonts/icon-linecons.styl","shasum":"a9f5260198225801eb5c16345a69a7e3cab904fe","modified":1452652241261},{"_id":"themes/next/source/css/_common/_page/archive.styl","shasum":"df9e5a418f6e54abe69c1ab84649be46fb0c51a6","modified":1452652241265},{"_id":"themes/next/source/css/_common/_page/categories.styl","shasum":"6c34f2cf9ad9b9b787007cfca522deeb6b1ae3b7","modified":1452652241269},{"_id":"themes/next/source/css/_common/_page/post-detail.styl","shasum":"4e3838d7ac81d9ad133960f0f7ed58a44a015285","modified":1452652241274},{"_id":"themes/next/source/css/_common/_section/body.styl","shasum":"6eaa5d9cb08ecfb2d377a475e541e41fbfe4c1b6","modified":1452652241278},{"_id":"themes/next/source/css/_common/_section/footer.styl","shasum":"4c4ef6e997d0c6e21de39c2daa0c768e12c8c6fa","modified":1452652241281},{"_id":"themes/next/source/css/_common/_section/header.styl","shasum":"cd6527e4877f62f08e8668b020ec9f9e53f625a9","modified":1452652241284},{"_id":"themes/next/source/css/_common/_section/layout.styl","shasum":"9a9630b7aae08b5008f3a0ff1152bdca427ff644","modified":1452652241291},{"_id":"themes/next/source/css/_common/_section/media.styl","shasum":"482784c04c0cd15a3f0d86444966fe306af7d13a","modified":1452652241291},{"_id":"themes/next/source/css/_common/_section/sidebar.styl","shasum":"406b78061c45bda0376ce2360ff2932262f5f2f0","modified":1452652241295},{"_id":"themes/next/source/css/_common/_vendor/highlight/highlight.styl","shasum":"627cdd38b34b15c9fc17f4dc332b1be928f8ed0d","modified":1452652241300},{"_id":"themes/next/source/css/_common/_vendor/highlight/theme.styl","shasum":"9f0606d4d94ffa6bd77f91628507bba19133cf36","modified":1452652241304},{"_id":"themes/next/source/css/_custom/custom.styl","shasum":"3403fdd8efde1a0afd11ae8a5a97673f5903087f","modified":1452652241309},{"_id":"themes/next/source/css/_mixins/base.styl","shasum":"10ca6744a8594c1a085b50120f4ed0a1ef433f40","modified":1452652241313},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","shasum":"e4b5b56e1a035c99ebd50d00e93d89e2e8d0b735","modified":1452652241317},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","shasum":"452e71caf2c37fa5a06f8d9ada81337a57485885","modified":1452652241322},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","shasum":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1452652241326},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","shasum":"3b0a186e8d9d5cfe30dd611456b61053ea535d7b","modified":1452652241335},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","shasum":"55b44e03054cd20ed8129bf986b15fba5fd85aad","modified":1452652241341},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","shasum":"f10be4b0c642104a6f533b94ac09e22019aa640e","modified":1452652241345},{"_id":"themes/next/source/css/_schemes/default/_logo.styl","shasum":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1452652241348},{"_id":"themes/next/source/css/_schemes/default/_menu.styl","shasum":"dd667be3f5f24cebdc15d0262c7d397f23d751c5","modified":1452652241353},{"_id":"themes/next/source/css/_schemes/default/_search.styl","shasum":"e315ee6f604c2bcc44a5ef9078f5ce420c153a4b","modified":1452652241357},{"_id":"themes/next/source/css/_schemes/default/index.styl","shasum":"ecd76494cea5fbf592cc13ba1e4ccdfedbc5bf1b","modified":1452652241361},{"_id":"themes/next/source/css/_variables/Mist.styl","shasum":"932cb9c53d64b086638adca05dcf4e2df239a8f9","modified":1452652241364},{"_id":"themes/next/source/css/_variables/base.styl","shasum":"ca2773ea89b008d05832eb6d05cf477fd62d96b2","modified":1453376214882},{"_id":"themes/next/source/css/_variables/custom.styl","shasum":"49892257bd159477e601687855a91d61b53a1d1b","modified":1452652241377},{"_id":"themes/next/source/css/_variables/default.styl","shasum":"17779fa6fa3c9e1262ba100a86a8dec730c2f312","modified":1452652241380},{"_id":"themes/next/source/css/main.styl","shasum":"6bb842ad45a575774299bed3848d46475820fb9f","modified":1452652241386},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","shasum":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1452652241394},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","shasum":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1452652241400},{"_id":"themes/next/source/images/cc-by-nc.svg","shasum":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1452652241405},{"_id":"themes/next/source/images/cc-by-nd.svg","shasum":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1452652241411},{"_id":"themes/next/source/images/cc-by-sa.svg","shasum":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1452652241416},{"_id":"themes/next/source/images/cc-by.svg","shasum":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1452652241420},{"_id":"themes/next/source/images/cc-zero.svg","shasum":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1452652241422},{"_id":"themes/next/source/images/loading.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1461134754850},{"_id":"themes/next/source/images/placeholder.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1461134754850},{"_id":"themes/next/source/images/quote-l.svg","shasum":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1452652241425},{"_id":"themes/next/source/images/quote-r.svg","shasum":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1452652241426},{"_id":"themes/next/source/images/searchicon.png","shasum":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1461134754850},{"_id":"themes/next/source/js/bootstrap.js","shasum":"5a963f40fb81d265a31679f8f543e50ffdcc7485","modified":1452652241429},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","shasum":"97640be11a524b203781c1a03f623ef0b9195a02","modified":1452652241431},{"_id":"themes/next/source/js/fancy-box.js","shasum":"fbeabc936667a9e15556c8defb5fcd582add8067","modified":1452652241435},{"_id":"themes/next/source/js/helpers.js","shasum":"69d8ae9b686a82e3a4397b61a477eb8da68bd153","modified":1452652241437},{"_id":"themes/next/source/js/hook-duoshuo.js","shasum":"ccb32e0a1acf798337c9697e1aab5484b52f9df4","modified":1452652241443},{"_id":"themes/next/source/js/motion.js","shasum":"a9327a3c0a5df289799c5ffe3e8bf7dd6e407797","modified":1452652241450},{"_id":"themes/next/source/js/ua-parser.min.js","shasum":"fc57202d8d952fceb3f1ad5b6e7183f47a3f1a0e","modified":1452652241523},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1461134754850},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1461134754850},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1461134754850},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1461134754850},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1461134754850},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1461134754850},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1461134754850},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","shasum":"6394c48092085788a8c0ef72670b0652006231a1","modified":1452652241535},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","shasum":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1452652241538},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","shasum":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1452652241540},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","shasum":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1452652241542},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","shasum":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1452652241543},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","shasum":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1452652241547},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","shasum":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1452652241559},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","shasum":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1452652241573},{"_id":"themes/next/source/vendors/fastclick/LICENSE","shasum":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1452652241577},{"_id":"themes/next/source/vendors/fastclick/README.md","shasum":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1452652241578},{"_id":"themes/next/source/vendors/fastclick/bower.json","shasum":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1452652241581},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.js","shasum":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1452652241590},{"_id":"themes/next/source/vendors/fastclick/lib/fastclick.min.js","shasum":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1461134754850},{"_id":"themes/next/source/vendors/font-awesome/HELP-US-OUT.txt","shasum":"ed80b43dbc7e3009b2f436741b9796df8eb3be02","modified":1452652241605},{"_id":"themes/next/source/vendors/font-awesome/bower.json","shasum":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1452652241609},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css","shasum":"811432ad1e2d6c1f6da9a63fd919bf2a02b71dd9","modified":1452652241615},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.css.map","shasum":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1452652241619},{"_id":"themes/next/source/vendors/font-awesome/css/font-awesome.min.css","shasum":"4c2c5f5f6cc86d775a44b944661e038b7be98149","modified":1452652241627},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff2","shasum":"574ea2698c03ae9477db2ea3baf460ee32f1a7ea","modified":1461134754854},{"_id":"themes/next/source/vendors/jquery_lazyload/CONTRIBUTING.md","shasum":"4ded6fee668544778e97e38c2b211fc56c848e77","modified":1452652241779},{"_id":"themes/next/source/vendors/jquery_lazyload/README.md","shasum":"b930297cb98b8e1dbd5abe9bc1ed9d5935d18ce8","modified":1452652241782},{"_id":"themes/next/source/vendors/jquery_lazyload/bower.json","shasum":"e0acf1db27b0cc16128a59c46db1db406b5c4c58","modified":1452652241790},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.lazyload.js","shasum":"f4a570908f6c89c6edfb1c74959e733eaadea4f2","modified":1452652241799},{"_id":"themes/next/source/vendors/jquery_lazyload/jquery.scrollstop.js","shasum":"bf773ad48a0b9aa77681a89d7569eefc0f7b7b18","modified":1452652241807},{"_id":"themes/next/source/vendors/velocity/bower.json","shasum":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1452652241816},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","shasum":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1452652241861},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","shasum":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1452652241901},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","shasum":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1452652241910},{"_id":"themes/next/test/helpers.js","shasum":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1452652241923},{"_id":"themes/next/test/intern.js","shasum":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1452652241930},{"_id":"themes/next/source/vendors/font-awesome/fonts/FontAwesome.otf","shasum":"0112e96f327d413938d37c1693806f468ffdbace","modified":1461134754850},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.eot","shasum":"b3c2f08e73320135b69c23a3908b87a12053a2f6","modified":1461134754854},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.woff","shasum":"507970402e328b2baeb05bde73bf9ded4e2c3a2d","modified":1461134754854},{"_id":"themes/next/source/vendors/jquery/index.js","shasum":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1452652241767},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.ttf","shasum":"27cf1f2ec59aece6938c7bb2feb0e287ea778ff9","modified":1461134754854},{"_id":"themes/next/source/vendors/velocity/velocity.js","shasum":"4237c6e9d59da349639de20e559e87c2c0218cfd","modified":1452652241842},{"_id":"themes/next/source/vendors/font-awesome/fonts/fontawesome-webfont.svg","shasum":"f346b8b3df147e4059e1a7d66c52c9a6e1cec3e8","modified":1452652241683},{"_id":"public/upload/image/avatar.png","modified":1461814765399,"shasum":"4cd3d5741c7bd49e4dfbeec7cc92a3ce37416ce1"},{"_id":"public/robots.txt","modified":1463042717750,"shasum":"ab72d2370ef57792c98fd11375a904fcd2c2821e"},{"_id":"public/mail.gif","modified":1461814765425,"shasum":"a861aea9d589b864c990040488974fbbcc6e5d3e"},{"_id":"public/favicon.ico","modified":1461814765428,"shasum":"9eae51ac749b50c6ebe4d1d69e4fc56bc14bbb5e"},{"_id":"public/vendors/velocity/velocity.ui.min.js","modified":1461814765434,"shasum":"ed5e534cd680a25d8d14429af824f38a2c7d9908"},{"_id":"public/vendors/velocity/velocity.ui.js","modified":1461814765436,"shasum":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df"},{"_id":"public/vendors/velocity/velocity.min.js","modified":1461814765441,"shasum":"2f1afadc12e4cf59ef3b405308d21baa97e739c6"},{"_id":"public/vendors/velocity/velocity.js","modified":1461814765444,"shasum":"9f08181baea0cc0e906703b7e5df9111b9ef3373"},{"_id":"public/vendors/velocity/bower.json","modified":1461814765464,"shasum":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409"},{"_id":"public/vendors/jquery_lazyload/jquery.scrollstop.js","modified":1461814765466,"shasum":"0e9a81785a011c98be5ea821a8ed7d411818cfd1"},{"_id":"public/vendors/jquery_lazyload/jquery.lazyload.js","modified":1461814765484,"shasum":"481fd478650e12b67c201a0ea41e92743f8b45a3"},{"_id":"public/vendors/jquery_lazyload/bower.json","modified":1461814765487,"shasum":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53"},{"_id":"public/vendors/jquery_lazyload/README.html","modified":1461814765496,"shasum":"1eeb7414f97f8ac1f91c19eed31ebba591df787d"},{"_id":"public/vendors/jquery_lazyload/CONTRIBUTING.html","modified":1461814765573,"shasum":"0bd87f225f3d850b299f68efc2ffafce870c0333"},{"_id":"public/vendors/jquery/index.js","modified":1461814765618,"shasum":"41b4bfbaa96be6d1440db6e78004ade1c134e276"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.woff2","modified":1461814765623,"shasum":"574ea2698c03ae9477db2ea3baf460ee32f1a7ea"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.woff","modified":1461814765626,"shasum":"507970402e328b2baeb05bde73bf9ded4e2c3a2d"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.ttf","modified":1461814765633,"shasum":"27cf1f2ec59aece6938c7bb2feb0e287ea778ff9"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.svg","modified":1463042717859,"shasum":"f346b8b3df147e4059e1a7d66c52c9a6e1cec3e8"},{"_id":"public/vendors/font-awesome/fonts/fontawesome-webfont.eot","modified":1461814765642,"shasum":"b3c2f08e73320135b69c23a3908b87a12053a2f6"},{"_id":"public/vendors/font-awesome/fonts/FontAwesome.otf","modified":1461814765652,"shasum":"0112e96f327d413938d37c1693806f468ffdbace"},{"_id":"public/vendors/font-awesome/css/font-awesome.min.css","modified":1461814765657,"shasum":"05ea25bc9b3ac48993e1fee322d3bc94b49a6e22"},{"_id":"public/vendors/font-awesome/css/font-awesome.css.map","modified":1463042717877,"shasum":"1573904b82807abbb32c97a3632c6c6808eaac50"},{"_id":"public/vendors/font-awesome/css/font-awesome.css","modified":1461814765666,"shasum":"3b87c2560832748cd06f9bfd2fd6ea8edbdae8c7"},{"_id":"public/vendors/font-awesome/bower.json","modified":1461814765676,"shasum":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad"},{"_id":"public/vendors/font-awesome/HELP-US-OUT.txt","modified":1463042717886,"shasum":"ed80b43dbc7e3009b2f436741b9796df8eb3be02"},{"_id":"public/vendors/fastclick/lib/fastclick.min.js","modified":1461814765703,"shasum":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18"},{"_id":"public/vendors/fastclick/lib/fastclick.js","modified":1461814765706,"shasum":"06cef196733a710e77ad7e386ced6963f092dc55"},{"_id":"public/vendors/fastclick/bower.json","modified":1461814765714,"shasum":"4dcecf83afddba148464d5339c93f6d0aa9f42e9"},{"_id":"public/vendors/fastclick/README.html","modified":1461814765724,"shasum":"4a6074903daa9004301ef30a6fb96556ba3eab60"},{"_id":"public/vendors/fastclick/LICENSE","modified":1463042717904,"shasum":"6f474ea75c42442da7bbcf2e9143ce98258efd8d"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.pack.js","modified":1461814765766,"shasum":"53360764b429c212f424399384417ccc233bb3be"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.js","modified":1461814765806,"shasum":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.css","modified":1461814765808,"shasum":"5f163444617b6cf267342f06ac166a237bb62df9"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1461814765810,"shasum":"53e194f4a72e649c04fb586dd57762b8c022800b"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1461814765815,"shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":1461814765817,"shasum":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1461814765829,"shasum":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1461814765832,"shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8"},{"_id":"public/vendors/fancybox/source/helpers/fancybox_buttons.png","modified":1461814765837,"shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3"},{"_id":"public/vendors/fancybox/source/fancybox_sprite@2x.png","modified":1461814765838,"shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"public/vendors/fancybox/source/fancybox_sprite.png","modified":1461814765841,"shasum":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"public/vendors/fancybox/source/fancybox_overlay.png","modified":1461814765843,"shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"public/vendors/fancybox/source/fancybox_loading@2x.gif","modified":1461814765848,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/vendors/fancybox/source/fancybox_loading.gif","modified":1461814765850,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/vendors/fancybox/source/blank.gif","modified":1461814765852,"shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"public/js/ua-parser.min.js","modified":1461814765856,"shasum":"1148fa2bcb8b2e40c31e5f597bf794a57369a2e6"},{"_id":"public/js/motion.js","modified":1461814765878,"shasum":"b4132517fe499538ad725094593fb7ead8c04bf7"},{"_id":"public/js/hook-duoshuo.js","modified":1461814765881,"shasum":"eedaf52377991728f1e3e94f2bc4bf23ec41ecea"},{"_id":"public/js/helpers.js","modified":1461814765883,"shasum":"c15216ef897334362789ba37464298948b2eef95"},{"_id":"public/js/fancy-box.js","modified":1461814765884,"shasum":"b5fa638ed371b5f658b0826ec4afee25d9986ef2"},{"_id":"public/js/bootstrap.scrollspy.js","modified":1461814765886,"shasum":"ae7bdce88b515aade4eea8bf7407eec458bcd625"},{"_id":"public/js/bootstrap.js","modified":1461814765890,"shasum":"f9b637b6d064f728d7dc2b6b5058a006a4454299"},{"_id":"public/images/searchicon.png","modified":1461814765893,"shasum":"67727a6a969be0b2659b908518fa6706eed307b8"},{"_id":"public/images/quote-r.svg","modified":1463042717946,"shasum":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41"},{"_id":"public/images/quote-l.svg","modified":1463042717949,"shasum":"cd108d6f44351cadf8e6742565217f88818a0458"},{"_id":"public/images/placeholder.gif","modified":1461814765905,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/loading.gif","modified":1461814765910,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/cc-zero.svg","modified":1463042717955,"shasum":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d"},{"_id":"public/images/cc-by.svg","modified":1463042717958,"shasum":"e92a33c32d1dac8ed94849b2b4e6456e887efe70"},{"_id":"public/images/cc-by-sa.svg","modified":1463042717966,"shasum":"70c1535f43e54e5ff35ca81419e77e4c0c301398"},{"_id":"public/images/cc-by-nd.svg","modified":1463042717973,"shasum":"42cd73da328077ccc92f859bb8f3cf621b3484f8"},{"_id":"public/images/cc-by-nc.svg","modified":1463042717981,"shasum":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab"},{"_id":"public/images/cc-by-nc-sa.svg","modified":1463042717992,"shasum":"6f55543d1fb9cbc436c101d24f802dec7b41efc3"},{"_id":"public/images/cc-by-nc-nd.svg","modified":1463042718009,"shasum":"bc3588c9b2d7c68830524783120ff6cf957cf668"},{"_id":"public/css/main.css","modified":1463042718701,"shasum":"2e42c0e0e9d686775e47023dc2a4227986535dc1"},{"_id":"public/CNAME","modified":1461814766830,"shasum":"211316d9451b7030c6a24b89c228e7d5ef540a99"},{"_id":"public/404.html","modified":1463046025630,"shasum":"6dbcaf63eb29a50d2a93072aa74681f46175eae8"},{"_id":"public/tags/index.html","modified":1463046025769,"shasum":"ac5b9c1873284fc734c4cd8c953dd4aa18c538a2"},{"_id":"public/categories/index.html","modified":1463046025856,"shasum":"9546a28357f5f286b98d20f9b835692e5433092b"},{"_id":"public/about/index.html","modified":1463046025960,"shasum":"35d96defcfc7d7aaf176245088598be5ab10fad6"},{"_id":"public/404_old.html","modified":1463046026031,"shasum":"c8f2e2c9a076413244e828aa95fc17376b79cf59"},{"_id":"public/realization-of-full-chinese-text-search-using-whoosh-and-jieba.html","modified":1463046026222,"shasum":"345066d3cb324ae6c12df3d0f167e42e503a21db"},{"_id":"public/python-learning-notes-and-common-problems.html","modified":1463046026371,"shasum":"8013b43d009acb93de797a83fac59f16b746ead6"},{"_id":"public/problems-with-solution-in-tensorflow.html","modified":1463046026590,"shasum":"81da9c864a44c43d6a13eb0486c2715bb1cf6c0b"},{"_id":"public/tensorflow-learning-notes-3.html","modified":1463046026736,"shasum":"6518e743ca8fac37ed524350ed9611337332242f"},{"_id":"public/cnn-apply-on-modelling-sentence.html","modified":1463046026900,"shasum":"ac876a1e893065ef23e7e1d0566b98022dbaf705"},{"_id":"public/introduction-to-word-representation.html","modified":1463046027017,"shasum":"142c0185e0847263ed6e47d372efb143c2e74c50"},{"_id":"public/2015-campus-recurit-technology-interview-summary.html","modified":1464058421014,"shasum":"d72f693173192ce8cf2149ae897c6aeeb2ee700b"},{"_id":"public/cnn-learning-notes-2.html","modified":1463046027296,"shasum":"d59f4b65fb7976376e244ceb77bb5e276988d747"},{"_id":"public/cnn-learning-notes-1.html","modified":1463046027446,"shasum":"3394365098867bcbb4529fa7f8ecf21319ebe0d8"},{"_id":"public/tensorflow-learning-notes-2.html","modified":1463046027630,"shasum":"f663ddd3a5f9e06599071a3df2b96c217b85f9a9"},{"_id":"public/network-connection-problems-in-win10.html","modified":1463046027771,"shasum":"7a3e1840722e2da439f6d05e372be3a2d0917db6"},{"_id":"public/markdown-common-problems.html","modified":1463046027900,"shasum":"289ed808d7b4ba56717fdca144c3ce6e27bbdcc7"},{"_id":"public/hexo-next-add-post-views.html","modified":1463046028053,"shasum":"17b53db482e16f110ebf524dd9018093623ef5af"},{"_id":"public/how-to-insert-equations-in-markdown.html","modified":1463046028181,"shasum":"30ca1ea91e5acdc808d1800e68373a766b59d8bb"},{"_id":"public/tensorflow-learning-notes.html","modified":1463046028335,"shasum":"526db318d2afbeef3b2b1d4b3473ce297db15d5d"},{"_id":"public/blog-on-gitcafe-with-dns-settings.html","modified":1463046028465,"shasum":"c5bde6ca6f4f8d104543f588334aeb39162451df"},{"_id":"public/hexo-website-seo.html","modified":1463046028581,"shasum":"cb084da5eb8b08185c29a93b2120d89e3bfb7a04"},{"_id":"public/2015-campus-recruit-summary.html","modified":1463046028764,"shasum":"5526f5dd6091303f3da1af2012d94f9938665215"},{"_id":"public/next-theme-personal-settings.html","modified":1463046028904,"shasum":"ef7fad59314e8ec6d766aaae168baf69ea8ff5e1"},{"_id":"public/hexo-github-blog-building.html","modified":1463046029037,"shasum":"e315c967ba62cb37ca5d66d76161fc84c5ba4db1"},{"_id":"public/archives/index.html","modified":1463046029140,"shasum":"ca3ae01eab5a7157a8a8b9641e07f8b20256aea1"},{"_id":"public/archives/2015/index.html","modified":1463046029280,"shasum":"73d5681ade44634f7fb300c0d47b23dc33a4cd31"},{"_id":"public/archives/2015/12/index.html","modified":1463046029375,"shasum":"1d169896c88c6d2e7e864d225f534d149dd7c49e"},{"_id":"public/archives/2016/index.html","modified":1463046029451,"shasum":"aa6ed824d364ad73ccc2daeeff31f68319d5817e"},{"_id":"public/archives/2016/01/index.html","modified":1463046029553,"shasum":"f21816e1d69c3cc9f73775ba975e8ce2457dbb7c"},{"_id":"public/archives/2016/03/index.html","modified":1463046029657,"shasum":"5d9eed2dc0d0caf90522c2c7fa5af9dfb84f568f"},{"_id":"public/archives/2016/04/index.html","modified":1463046029740,"shasum":"b8022d876302ca8779d7da0afb8705a46b23e143"},{"_id":"public/baidusitemap.xml","modified":1464058422874,"shasum":"2090f55ee9c1c64d9cb73b411dc981dab8e67e2a"},{"_id":"public/categories/Machine-Learning/index.html","modified":1463046029872,"shasum":"d4d3ead7f3742f5c1db3edb7d531d36ab4493639"},{"_id":"public/categories/Python/index.html","modified":1463046030006,"shasum":"c3fed34b2ead7cca989731087ade3a1cbd7135df"},{"_id":"public/categories/Hexo/index.html","modified":1463046030110,"shasum":"9a60961173de6128bae14ff1d3c4f2e464c761a7"},{"_id":"public/categories/Network/index.html","modified":1463046030214,"shasum":"8c3e3f1fc63207c529acccde7b2a4ba1de05181f"},{"_id":"public/categories/Markdown/index.html","modified":1463046030320,"shasum":"63ff7975cdfd61a2cc5ef2614825870031d2fcf5"},{"_id":"public/categories/Interview/index.html","modified":1463046030445,"shasum":"26f6f9b971c5a1c4b63129de78e2537b87f69c5c"},{"_id":"public/index.html","modified":1463046030619,"shasum":"9f16ff3be6393dab7db6d58b60326e554765777e"},{"_id":"public/page/2/index.html","modified":1464058423436,"shasum":"57eb509859194781834cadc69fb61c4fff55edaa"},{"_id":"public/page/3/index.html","modified":1463046030909,"shasum":"88360546068fd00098314aecc5b0edc0c02dbd5b"},{"_id":"public/page/4/index.html","modified":1464058423650,"shasum":"1b86ca2c60ffbf247969bda46d100bdf575d31cb"},{"_id":"public/sitemap.xml","modified":1464058423652,"shasum":"aa1c76169c6975c20660bda522dab54df76fb886"},{"_id":"public/tags/TensorFlow/index.html","modified":1463046031215,"shasum":"5b255efeacbaafd601e8490d434f180df3c65d22"},{"_id":"public/tags/Machine-Learning/index.html","modified":1463046031355,"shasum":"d8e4ab0c9f9c7ac4f24d270b58b1717ef9db5571"},{"_id":"public/tags/Deep-Learning/index.html","modified":1463046031530,"shasum":"f0b02b44d21c7dae9c384db1e7a211c5b2b7a30e"},{"_id":"public/tags/Artificial-Intelligence/index.html","modified":1463046031657,"shasum":"b633d99046774662e1d7bc441f10ac67cd97fd84"},{"_id":"public/tags/Python/index.html","modified":1463046031774,"shasum":"a2da4b44a8e671124f66e65787bb422f11497b37"},{"_id":"public/tags/Whoosh/index.html","modified":1463046031839,"shasum":"9e1c404d8f2bd2ad8f4b69cfbc8f1ad7accf2ac6"},{"_id":"public/tags/Jieba/index.html","modified":1463046031948,"shasum":"f9eaaeca5589b899a195d8e439e8f9ab7062dae7"},{"_id":"public/tags/Search-Engine/index.html","modified":1463046032236,"shasum":"3fa777e98224b09432c0467f9ab469d9c3c17b62"},{"_id":"public/tags/Hexo/index.html","modified":1463046032300,"shasum":"f02acbe87cdfad883dbb82685ddf3c63431b817f"},{"_id":"public/tags/Next/index.html","modified":1463046032405,"shasum":"2c6a6e2dd3a4a2c7b0c0e8dc1bfe4c481803f253"},{"_id":"public/tags/Network/index.html","modified":1463046032535,"shasum":"e20161d25fc2a9ed404927bf192696c26bf2137c"},{"_id":"public/tags/Windows/index.html","modified":1463046032608,"shasum":"99752a1d7ab7d93db2401c94e853a33a65da5872"},{"_id":"public/tags/Win10/index.html","modified":1463046032686,"shasum":"15aebc6dc35606c60d9c1b383ca59852ca34023b"},{"_id":"public/tags/Markdown/index.html","modified":1463046032801,"shasum":"58074b7412ad1a293a7145555ceafd83ed450e57"},{"_id":"public/tags/Word2Vector/index.html","modified":1463046032912,"shasum":"0f80574e7067595976afcc46e5d6f1a7d3f5c9f5"},{"_id":"public/tags/Word-Embedding/index.html","modified":1463046033037,"shasum":"353863f76d34d2e1d10dc80f807ceaa23ddbb183"},{"_id":"public/tags/Equation/index.html","modified":1463046033122,"shasum":"7c0e2d7051bf73f09ec6a6a3c677d5101cbc6a42"},{"_id":"public/tags/MathJax/index.html","modified":1463046033231,"shasum":"e8ff853c1d45d8c8b2cf85f7470ed76c4d7bbe16"},{"_id":"public/tags/MarkdownPad-2/index.html","modified":1463046033373,"shasum":"3f5bf0676988a97bbead587f4339689fcdd3e957"},{"_id":"public/tags/SEO/index.html","modified":1463046033497,"shasum":"3d5597c4732ed644d5b665efae17ee7261bcb02f"},{"_id":"public/tags/Web/index.html","modified":1463046033573,"shasum":"f34056bf59ace5c00e9daef1b9436e1b130c8110"},{"_id":"public/tags/LeanCloud/index.html","modified":1463046033651,"shasum":"b6a296edd4d299788f3c16c284219d01b779782c"},{"_id":"public/tags/Github-Page/index.html","modified":1463046033744,"shasum":"48abdd1484d624baae88a10ce2c3ca6934afe703"},{"_id":"public/tags/Blog/index.html","modified":1463046033829,"shasum":"bf4b3f10be5c4c5b723d36c5df5255d3cd250a3a"},{"_id":"public/tags/Personal-Website/index.html","modified":1463046033912,"shasum":"ef31517f5f94c5bd14bdd4e1acd4feeeb654e3b0"},{"_id":"public/tags/CNN/index.html","modified":1463046033983,"shasum":"c9d8deedf2f1862ce06334e67aa1ec006408919b"},{"_id":"public/tags/Sentence-Model/index.html","modified":1463046034069,"shasum":"4e17d057c6ff0c28ca6ae60d4559dbdf9ac1fa49"},{"_id":"public/tags/NLP/index.html","modified":1463046034136,"shasum":"0c688469e5b89efce6844244d55988a7086eb2ef"},{"_id":"public/tags/Gitcafe/index.html","modified":1463046034223,"shasum":"a43068343130138d86fd8582f3d4a2a13d29767e"},{"_id":"public/tags/DNS/index.html","modified":1463046034337,"shasum":"300e41145b1b9a99b0f6ea114f4a009371c49778"},{"_id":"public/tags/Github/index.html","modified":1463046034447,"shasum":"70ec1b91433d9c248dbb456b8fecbd1af56887c5"},{"_id":"public/tags/Interview/index.html","modified":1463046034521,"shasum":"8d0899efe19d0dbf6c74a35334fe15d1dabfbab2"},{"_id":"public/tags/Job/index.html","modified":1463046034663,"shasum":"2496aeed41245dbe392dcca5bcabc7c77dc40b87"},{"_id":"public/tags/IT/index.html","modified":1463046034762,"shasum":"1490857f307415cab6aa2afd95f7a1c3f5c00f56"},{"_id":"public/tags/Algorithm/index.html","modified":1463046034832,"shasum":"735ec5e61acc5aabd95c0c897e70959773215761"},{"_id":"public/tags/Coding/index.html","modified":1463046034919,"shasum":"a02304a265a8b843f9a185075a017f4a8055fee1"}],"Category":[{"name":"Machine Learning","_id":"cinjqrknn0005nfq6t9al9hdm"},{"name":"Python","_id":"cinjqrkoh0011nfq6j35bk49c"},{"name":"Hexo","_id":"cinjqrkop001bnfq6ykq7nfxt"},{"name":"Network","_id":"cinjqrkou001infq6vbrbgpv0"},{"name":"Markdown","_id":"cinjqrkp0001rnfq6k3zc1k2x"},{"name":"Interview","_id":"cinjqrkr9003snfq61qpsh1aj"}],"Data":[],"Page":[{"_content":"<!DOCTYPE HTML>\n<html>\n<head>\n\t<title>404</title>\n\t<meta name=\"description\" content=\"404������ҳ�治���ڣ�\">\n\t<meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n\t<meta name=\"robots\" content=\"all\" />\n\t<meta name=\"robots\" content=\"index,follow\"/>\n</head>\n<body>\n\t<script type=\"text/javascript\" src=\"http://qzonestyle.gtimg.cn/qzone_v6/lostchild/search_children.js\" charset=\"utf-8\"></script>\n</body>\n</html>","source":"404.html","raw":"<!DOCTYPE HTML>\n<html>\n<head>\n\t<title>404</title>\n\t<meta name=\"description\" content=\"404������ҳ�治���ڣ�\">\n\t<meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n\t<meta name=\"robots\" content=\"all\" />\n\t<meta name=\"robots\" content=\"index,follow\"/>\n</head>\n<body>\n\t<script type=\"text/javascript\" src=\"http://qzonestyle.gtimg.cn/qzone_v6/lostchild/search_children.js\" charset=\"utf-8\"></script>\n</body>\n</html>","date":"2016-01-22T02:53:23.464Z","updated":"2016-01-13T02:30:40.153Z","path":"404.html","_id":"cinjqrkkc0000nfq6nsiiz18e","title":"","comments":1,"layout":"page"},{"title":"tags","date":"2015-12-04T03:42:32.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"title: tags\ndate: 2015-12-04 11:42:32\ntype: \"tags\"\ncomments: false\n---\n","updated":"2016-01-13T02:30:40.223Z","path":"tags/index.html","_id":"cinjqrkmc0001nfq693o5nws7","layout":"page"},{"title":"categories","date":"2015-12-04T07:37:22.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"title: categories\ndate: 2015-12-04 15:37:22\ntype: \"categories\"\ncomments: false\n---\n","updated":"2016-01-13T02:30:40.212Z","path":"categories/index.html","_id":"cinjqrkmg0002nfq6bfak1lt1","layout":"page"},{"title":"About","date":"2015-12-11T03:42:32.000Z","type":"About","_content":"\n## Name ##\n\nEN: Jey Zhang | CN: 张 捷\n\n## Abstract ##\n\n- A master student in Peking University, and my major is Computer Inteligent Science (CIS). I have some project experience on machine learning (NLP, big data processing, etc) through internship in Sogou and Microsoft STCA.\n- Be interested in fields of Data Science. Data Scientist is my dream position.\n- Love all wonderful things in the world, such as fantastic music, design and stories, etc. Hope to experience more beautiful things:). \n\n## Keyword ##\n\nPositive; Planned; Goal-directed; Indomitable; Coder; Scientist (want to be XD).\n\n## Contact ##\n\n![](http://i.imgur.com/HzMvtp6.gif)\n","source":"about/index.md","raw":"title: About\ndate: 2015-12-11 11:42:32\ntype: \"About\"\n---\n\n## Name ##\n\nEN: Jey Zhang | CN: 张 捷\n\n## Abstract ##\n\n- A master student in Peking University, and my major is Computer Inteligent Science (CIS). I have some project experience on machine learning (NLP, big data processing, etc) through internship in Sogou and Microsoft STCA.\n- Be interested in fields of Data Science. Data Scientist is my dream position.\n- Love all wonderful things in the world, such as fantastic music, design and stories, etc. Hope to experience more beautiful things:). \n\n## Keyword ##\n\nPositive; Planned; Goal-directed; Indomitable; Coder; Scientist (want to be XD).\n\n## Contact ##\n\n![](http://i.imgur.com/HzMvtp6.gif)\n","updated":"2016-01-24T13:19:41.927Z","path":"about/index.html","_id":"cinjqrknc0003nfq691o0me56","comments":1,"layout":"page"},{"_content":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n</head>\n<body>\n\n<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"http://www.jeyzhang.com\" homePageName=\"Return Jey Zhang's Homepage\"></script>\n\n</body>\n</html>","source":"404_old.html","raw":"<!DOCTYPE HTML>\n<html>\n<head>\n  <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n  <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n  <meta name=\"robots\" content=\"all\" />\n  <meta name=\"robots\" content=\"index,follow\"/>\n</head>\n<body>\n\n<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"http://www.jeyzhang.com\" homePageName=\"Return Jey Zhang's Homepage\"></script>\n\n</body>\n</html>","date":"2016-01-22T02:53:23.466Z","updated":"2016-01-13T02:30:40.159Z","path":"404_old.html","_id":"cinjqrkrh0047nfq60quxquye","title":"","comments":1,"layout":"page"}],"Post":[{"title":"TensorFlow学习笔记1：入门","date":"2016-01-13T08:49:49.000Z","_content":"\n![Tensor Flow](http://i.imgur.com/UT4vj57.jpg)\n\n## TensorFlow 简介 ##\n\nTensorFlow是Google在2015年11月份开源的人工智能系统（[**Github项目地址**](https://github.com/tensorflow/tensorflow)），是之前所开发的深度学习基础架构DistBelief的改进版本，该系统可以被用于语音识别、图片识别等多个领域。\n\n[官网](https://www.tensorflow.org/)上对TensorFlow的介绍是，一个使用数据流图(data flow graphs)技术来进行数值计算的开源软件库。数据流图中的节点，代表数值运算；节点节点之间的边，代表**多维数据**(tensors)之间的某种联系。你可以在多种设备（含有CPU或GPU）上通过简单的API调用来使用该系统的功能。TensorFlow是由Google Brain团队的研发人员负责的项目。\n\n### 什么是数据流图(Data Flow Graph) ###\n\n数据流图是描述`有向图`中的数值计算过程。`有向图`中的节点通常代表数学运算，但也可以表示数据的输入、输出和读写等操作；`有向图`中的边表示节点之间的某种联系，它负责传输多维数据(Tensors)。图中这些`tensors`的`flow`也就是TensorFlow的命名来源。\n\n节点可以被分配到多个计算设备上，可以异步和并行地执行操作。因为是有向图，所以只有等到之前的入度节点们的计算状态完成后，当前节点才能执行操作。\n\n### TensorFlow的特性 ###\n\n**1 灵活性**\n\nTensorFlow不是一个严格的神经网络工具包，只要你可以使用数据流图来描述你的计算过程，你可以使用TensorFlow做任何事情。你还可以方便地根据需要来构建数据流图，用简单的Python语言来实现高层次的功能。\n\n**2 可移植性**\n\nTensorFlow可以在任意具备CPU或者GPU的设备上运行，你可以专注于实现你的想法，而不用去考虑硬件环境问题，你甚至可以利用Docker技术来实现相关的云服务。\n\n**3 提高开发效率**\n\nTensorFlow可以提升你所研究的东西产品化的效率，并且可以方便与同行们共享代码。\n\n**4 支持语言选项**\n\n目前TensorFlow支持Python和C++语言。（但是你可以自己编写喜爱语言的SWIG接口）\n\n**5 充分利用硬件资源，最大化计算性能**\n\n## 基本使用 ##\n\n你需要理解在TensorFlow中，是如何：\n\n- 将计算流程表示成图；\n- 通过**`Sessions`**来执行图计算；\n- 将数据表示为**`tensors`**；\n- 使用**`Variables`**来保持状态信息；\n- 分别使用**`feeds`**和**`fetches`**来填充数据和抓取任意的操作结果；\n\n### 概览 ###\n\nTensorFlow是一种将计算表示为图的编程系统。图中的节点称为**`ops`**(operation的简称)。一个**`ops`**使用0个或以上的`Tensors`，通过执行某些运算，产生0个或以上的`Tensors`。**一个`Tensor`是一个多维数组**，例如，你可以将一批图像表示为一个四维的数组`[batch, height, width, channels]`，数组中的值均为浮点数。\n\nTensorFlow中的图描述了计算过程，图通过`Session`的运行而执行计算。`Session`将图的节点们(即ops)放置到计算设备(如CPUs和GPUs)上，然后通过方法执行它们；这些方法执行完成后，将返回tensors。在Python中的tensor的形式是`numpy ndarray`对象，而在C/C++中则是`tensorflow::Tensor`.\n\n### 图计算 ###\n\nTensorFlow程序中图的创建类似于一个 [施工阶段]，而在 [执行阶段] 则利用一个`session`来执行图中的节点。很常见的情况是，在 [施工阶段] 创建一个图来表示和训练神经网络，而在 [执行阶段] 在图中重复执行一系列的训练操作。\n\n#### 创建图 ####\n\n在TensorFlow中，`Constant`是一种没有输入的`ops`，但是你可以将它作为其他`ops`的输入。Python库中的`ops构造器`将返回构造器的输出。TensorFlow的Python库中有一个默认的图，将`ops构造器`作为节点，更多可了解[Graph Class文档](https://www.tensorflow.org/versions/r0.7/api_docs/python/framework.html#Graph)。\n\n见下面的示例代码：\n\n\timport tensorflow as tf\n\t\n\t# Create a Constant op that produces a 1x2 matrix.  The op is\n\t# added as a node to the default graph.\n\t#\n\t# The value returned by the constructor represents the output\n\t# of the Constant op.\n\tmatrix1 = tf.constant([[3., 3.]])\n\t\n\t# Create another Constant that produces a 2x1 matrix.\n\tmatrix2 = tf.constant([[2.],[2.]])\n\t\n\t# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n\t# The returned value, 'product', represents the result of the matrix\n\t# multiplication.\n\tproduct = tf.matmul(matrix1, matrix2)\n\n默认的图(Default Graph)现在有了三个节点：两个 `Constant()`ops和一个`matmul()`op。为了得到这两个矩阵的乘积结果，还需要在一个`session`中启动图计算。\n\n#### 在Session中执行图计算 ####\n\n见下面的示例代码，更多可了解[Session Class](https://www.tensorflow.org/versions/r0.7/api_docs/python/client.html#session-management)：\n\n\t# Launch the default graph.\n\tsess = tf.Session()\n\t\n\t# To run the matmul op we call the session 'run()' method, passing 'product'\n\t# which represents the output of the matmul op.  This indicates to the call\n\t# that we want to get the output of the matmul op back.\n\t#\n\t# All inputs needed by the op are run automatically by the session.  They\n\t# typically are run in parallel.\n\t#\n\t# The call 'run(product)' thus causes the execution of threes ops in the\n\t# graph: the two constants and matmul.\n\t#\n\t# The output of the op is returned in 'result' as a numpy `ndarray` object.\n\tresult = sess.run(product)\n\tprint(result)\n\t# ==> [[ 12.]]\n\t\n\t# Close the Session when we're done.\n\tsess.close()\n\nSessions最后需要关闭，以释放相关的资源；你也可以使用`with`模块，session在`with`模块中自动会关闭：\n\n\twith tf.Session() as sess:\n\t  result = sess.run([product])\n\t  print(result)\n\nTensorFlow的这些节点最终将在计算设备(CPUs,GPus)上执行运算。如果是使用GPU，默认会在第一块GPU上执行，如果你想在第二块多余的GPU上执行：\n\n\twith tf.Session() as sess:\n\t  with tf.device(\"/gpu:1\"):\n\t    matrix1 = tf.constant([[3., 3.]])\n\t    matrix2 = tf.constant([[2.],[2.]])\n\t    product = tf.matmul(matrix1, matrix2)\n\t    ...\n\ndevice中的各个字符串含义如下：\n\n- `\"/cpu:0\"`: 你机器的CPU；\n- `\"/gpu:0\"`: 你机器的第一个GPU；\n- `\"/gpu:1\"`: 你机器的第二个GPU；\n\n关于TensorFlow中GPU的使用见[这里](https://www.tensorflow.org/versions/r0.7/how_tos/using_gpu/index.html)。\n\n### 交互环境下的使用 ###\n\n以上的python示例中，使用了`Session`和`Session.run()`来执行图计算。然而，在一些Python的交互环境下(如IPython中)，你可以使用`InteractiveSession`类，以及`Tensor.eval()`、`Operation.run()`等方法。例如，在交互的Python环境下执行以下代码：\n\n\t# Enter an interactive TensorFlow Session.\n\timport tensorflow as tf\n\tsess = tf.InteractiveSession()\n\t\n\tx = tf.Variable([1.0, 2.0])\n\ta = tf.constant([3.0, 3.0])\n\t\n\t# Initialize 'x' using the run() method of its initializer op.\n\tx.initializer.run()\n\t\n\t# Add an op to subtract 'a' from 'x'.  Run it and print the result\n\tsub = tf.sub(x, a)\n\tprint(sub.eval())\n\t# ==> [-2. -1.]\n\t\n\t# Close the Session when we're done.\n\tsess.close()\n\n### Tensors ###\n\nTensorFlow中使用`tensor`数据结构（实际上就是一个多维数据）表示所有的数据，并在图计算中的节点之间传递数据。一个`tensor`具有固定的类型、级别和大小，更加深入理解这些概念可参考[Rank, Shape, and Type](https://www.tensorflow.org/versions/r0.7/resources/dims_types.html)。\n\n### 变量(Variables) ###\n\n变量在图执行的过程中，保持着自己的状态信息。下面代码中的变量充当了一个简单的计数器角色：\n\n\t# Create a Variable, that will be initialized to the scalar value 0.\n\tstate = tf.Variable(0, name=\"counter\")\n\t\n\t# Create an Op to add one to `state`.\n\t\n\tone = tf.constant(1)\n\tnew_value = tf.add(state, one)\n\tupdate = tf.assign(state, new_value)\n\t\n\t# Variables must be initialized by running an `init` Op after having\n\t# launched the graph.  We first have to add the `init` Op to the graph.\n\tinit_op = tf.initialize_all_variables()\n\t\n\t# Launch the graph and run the ops.\n\twith tf.Session() as sess:\n\t  # Run the 'init' op\n\t  sess.run(init_op)\n\t  # Print the initial value of 'state'\n\t  print(sess.run(state))\n\t  # Run the op that updates 'state' and print 'state'.\n\t  for _ in range(3):\n\t    sess.run(update)\n\t    print(sess.run(state))\n\t\n\t# output:\n\t\n\t# 0\n\t# 1\n\t# 2\n\t# 3\n\n赋值函数`assign()`和`add()`函数类似，直到session的`run()`之后才会执行操作。与之类似的，一般我们会将神经网络模型中的参数表示为一系列的变量，在模型的训练过程中对变量进行更新操作。\n\n### 抓取(Fetches) ###\n\n为了抓取`ops`的输出，需要先执行`session`的`run`函数。然后，通过`print`函数打印状态信息。\n\n\tinput1 = tf.constant(3.0)\n\tinput2 = tf.constant(2.0)\n\tinput3 = tf.constant(5.0)\n\tintermed = tf.add(input2, input3)\n\tmul = tf.mul(input1, intermed)\n\t\n\twith tf.Session() as sess:\n\t  result = sess.run([mul, intermed])\n\t  print(result)\n\t\n\t# output:\n\t# [array([ 21.], dtype=float32), array([ 7.], dtype=float32)]\n\n所有tensors的输出都是一次性 [连贯] 执行的。\n\n### 填充(Feeds) ###\n\nTensorFlow也提供这样的机制：先创建特定数据类型的占位符(placeholder)，之后再进行数据的填充。例如下面的程序：\n\n\tinput1 = tf.placeholder(tf.float32)\n\tinput2 = tf.placeholder(tf.float32)\n\toutput = tf.mul(input1, input2)\n\t\n\twith tf.Session() as sess:\n\t  print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))\n\t\n\t# output:\n\t# [array([ 14.], dtype=float32)]\n\n如果不对`placeholder()`的变量进行数据填充，将会引发错误，更多的例子可参考[MNIST fully-connected feed tutorial (source code)](https://www.tensorflow.org/versions/r0.7/tutorials/mnist/tf/index.html)。\n\n\n## 示例：曲线拟合 ##\n\n下面是一段使用Python写的，曲线拟合计算。官网将此作为刚开始介绍的示例程序。\n\n\t# 简化调用库名\n\timport tensorflow as tf\n\timport numpy as np\n\t\n\t# 模拟生成100对数据对, 对应的函数为y = x * 0.1 + 0.3\n\tx_data = np.random.rand(100).astype(\"float32\")\n\ty_data = x_data * 0.1 + 0.3\n\t\n\t# 指定w和b变量的取值范围（注意我们要利用TensorFlow来得到w和b的值）\n\tW = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n\tb = tf.Variable(tf.zeros([1]))\n\ty = W * x_data + b\n\t\n\t# 最小化均方误差\n\tloss = tf.reduce_mean(tf.square(y - y_data))\n\toptimizer = tf.train.GradientDescentOptimizer(0.5)\n\ttrain = optimizer.minimize(loss)\n\t\n\t# 初始化TensorFlow参数\n\tinit = tf.initialize_all_variables()\n\t\n\t# 运行数据流图（注意在这一步才开始执行计算过程）\n\tsess = tf.Session()\n\tsess.run(init)\n\t\n\t# 观察多次迭代计算时，w和b的拟合值\n\tfor step in xrange(201):\n\t    sess.run(train)\n\t    if step % 20 == 0:\n\t        print(step, sess.run(W), sess.run(b))\n\t\n\t# 最好的情况是w和b分别接近甚至等于0.1和0.3\n\n\n## MNIST手写体识别任务 ##\n\n下面我们介绍一个神经网络中的经典示例，MNIST手写体识别。这个任务相当于是机器学习中的HelloWorld程序。\n\n### MNIST数据集介绍 ###\n\nMNIST是一个简单的图片数据集（[数据集下载地址](http://yann.lecun.com/exdb/mnist/)），包含了大量的数字手写体图片。下面是一些示例图片：\n\n![MNIST](http://i.imgur.com/SQTMzsC.png)\n\nMNIST数据集是含标注信息的，以上图片分别代表5, 0, 4和1。\n\n由于MNIST数据集是TensorFlow的示例数据，所以我们不必下载。只需要下面两行代码，即可实现数据集的读取工作：\n\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\tmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\t\n\nMNIST数据集一共包含三个部分：训练数据集(55,000份，mnist.train)、测试数据集(10,000份，mnist.test)和验证数据集(5,000份，mnist.validation)。一般来说，训练数据集是用来训练模型，验证数据集可以检验所训练出来的模型的正确性和是否过拟合，测试集是不可见的（相当于一个黑盒），但我们最终的目的是使得所训练出来的模型在测试集上的效果（这里是准确性）达到最佳。\n\nMNIST中的一个数据样本包含两块：手写体图片和对于的label。这里我们用`xs`和`ys`分别代表图片和对应的label，训练数据集和测试数据集都有xs和ys，我们使用 mnist.train.images 和 mnist.train.labels 表示训练数据集中图片数据和对于的label数据。\n\n一张图片是一个28*28的像素点矩阵，我们可以用一个同大小的二维整数矩阵来表示。如下：\n\n![](http://i.imgur.com/QoBA21J.png)\n\n但是，这里我们可以先简单地使用一个长度为28 * 28 = 784的一维数组来表示图像，因为下面仅仅使用softmax regression来对图片进行识别分类（尽管这样做会损失图片的二维空间信息，所以实际上最好的计算机视觉算法是会利用图片的二维信息的）。\n\n所以MNIST的训练数据集可以是一个形状为55000 * 784位的`tensor`，也就是一个多维数组，第一维表示图片的索引，第二维表示图片中像素的索引（\"tensor\"中的像素值在0到1之间）。如下图：\n\n![](http://i.imgur.com/rnNXzOC.png)\n\nMNIST中的数字手写体图片的label值在1到9之间，是图片所表示的真实数字。这里用One-hot vector来表述label值，vector的长度为label值的数目，vector中有且只有一位为1，其他为0.为了方便，我们表示某个数字时在vector中所对应的索引位置设置1，其他位置元素为0. 例如用[0,0,0,1,0,0,0,0,0,0]来表示`3`。所以，mnist.train.labels是一个55000 * 10的二维数组。如下：\n\n![](http://i.imgur.com/8X0IbcY.png)\n\n以上是MNIST数据集的描述及TensorFlow中表示。下面介绍Softmax Regression模型。\n\n### Softmax Regression模型 ###\n\n数字手写体图片的识别，实际上可以转化成一个概率问题，如果我们知道一张图片表示`9`的概率为80%，而剩下的20%概率分布在`8`，`6`和其他数字上，那么从概率的角度上，我们可以大致推断该图片表示的是9.\n\nSoftmax Regression是一个简单的模型，很适合用来处理得到一个待分类对象在多个类别上的概率分布。所以，这个模型通常是很多高级模型的最后一步。\n\nSoftmax Regression大致分为两步（暂时不知道如何合理翻译，转原话）：\n\n**Step 1**: add up the evidence of our input being in certain classes;\n**Step 2**: convert that evidence into probabilities.\n\n为了利用图片中各个像素点的信息，我们将图片中的各个像素点的值与一定的权值相乘并累加，权值的正负是有意义的，如果是正的，那么表示对应像素值（不为0的话）对表示该数字类别是积极的；否则，对应像素值(不为0的话)对表示该数字类别是起负面作用的。下面是一个直观的例子，图片中蓝色表示正值，红色表示负值（蓝色区域的形状趋向于数字形状）：\n\n![](http://i.imgur.com/Zff5Y7Q.png)\n\n最后，我们在一个图片类别的evidence(不知如何翻译..)中加入偏置(bias)，加入偏置的目的是加入一些与输入独立无关的信息。所以图片类别的evidence可表示为\n\n$$ evidence\\_{i}=\\sum \\_{j}W\\_{ij}x\\_{j}+b\\_{i} $$\n\n其中，\\\\( W\\_i \\\\) 和 \\\\( b\\_i \\\\) 分别为类别 \\\\( i \\\\) 的权值和偏置，\\\\( j \\\\) 是输入图片 \\\\( x \\\\) 的像素索引。然后，我们将得到的evidence值通过一个\"softmax\"函数转化为概率值 \\\\( y \\\\) :\n\n$$ y = softmax(evidence) $$\n\n这里softmax函数的作用相当于是一个转换函数，它的作用是将原始的线性函数输出结果以某种方式转换为我们需要的值，这里我们需要0-9十个类别上的概率分布。softmax函数的定义如下：\n\n$$ softmax(x) = normalize(exp(x)) $$\n\n具体计算方式如下\n\n$$ softmax(x)\\_{i} = \\dfrac {exp\\left( x\\_{i}\\right) } {\\Sigma \\_{j}exp\\left( x\\_{j}\\right) } $$\n\n这里的softmax函数能够得到类别上的概率值分布，并保证所有类别上的概率值之和为1. 下面的图示将有助于你理解softmax函数的计算过程：\n\n![](http://i.imgur.com/sqlI5oC.png)\n\n如果我们将这个过程公式化，将得到\n\n![](http://i.imgur.com/ANwDWKW.png)\n\n实际的计算中，我们通常采用矢量计算的方式，如下\n\n![](http://i.imgur.com/f0c2kWB.png)\n\n也可以简化成\n\n$$ y = softmax( Wx + b ) $$\n\n### Softmax Regression的程序实现 ###\n\n为了在Python中进行科学计算工作，我们常常使用一些独立库函数包，例如NumPy来实现复杂的矩阵计算。但是由于Python的运行效率并不够快，所以常常用一些更加高效的语言来实现。但是，这样做会带来语言转换（例如转换回python操作）的开销。TensorFlow在这方面做了一些优化，可以对你所描述的一系列的交互计算的流程完全独立于Python之外，从而避免了语言切换的开销。\n\n为了使用TensorFlow，我们需要引用该库函数\n\n\timport tensorflow as tf\n\n我们利用一些符号变量来描述交互计算的过程，创建如下\n\n\tx = tf.placeholder(tf.float32, [None, 784])\n\n这里的 \\\\( x \\\\) 不是一个特定的值，而是一个占位符，即需要时指定。如前所述，我们用一个1 * 784维的向量来表示一张MNIST中的图片。我们用[None, 784]这样一个二维的tensor来表示整个MNIST数据集，其中`None`表示可以为任意值。\n\n我们使用`Variable`(变量)来表示模型中的权值和偏置，这些参数是可变的。如下，\n\n\tW = tf.Variable(tf.zeros([784, 10]))\n\tb = tf.Variable(tf.zeros([10]))\n\n这里的W和b均被初始化为0值矩阵。W的维数为784 * 10，是因为我们需要将一个784维的像素值经过相应的权值之乘转化为10个类别上的evidence值；b是十个类别上累加的偏置值。\n\n**实现softmax regression模型仅需要一行代码**，如下\n  \n\ty = tf.nn.softmax(tf.matmul(x, W) + b)\n\n其中，`matmul`函数实现了 x 和 W 的乘积，这里 x 为二维矩阵，所以放在前面。可以看出，在TensorFlow中实现softmax regression模型是很简单的。\n\n### 模型的训练 ###\n\n在机器学习中，通常需要选择一个代价函数（或者损失函数），来指示训练模型的好坏。这里，我们使用交叉熵函数（cross-entropy）作为代价函数，交叉熵是一个源于信息论中信息压缩领域的概念，但是现在已经应用在多个领域。它的定义如下：\n\n$$ H\\_{y'}\\left( y\\right) = -\\sum \\_{i}y\\_{i}'\\log \\left( y\\_{i}\\right) $$\n\n这里 \\\\( y \\\\) 是所预测的概率分布，而 \\\\( y' \\\\) 是真实的分布(one-hot vector表示的图片label)。直观上，交叉熵函数的输出值表示了预测的概率分布与真实的分布的符合程度。更加深入地理解交叉熵函数，可参考[这篇博文](http://colah.github.io/posts/2015-09-Visual-Information/)。\n\n为了实现交叉熵函数，我们需要先设置一个占位符在存放图片的正确label值，\n\n\ty_ = tf.placeholder(tf.float32, [None, 10])\n\n然后得到交叉熵，即\\\\( -\\sum y'\\log \\left( y\\right) \\\\)：\n\n\tcross_entropy = -tf.reduce_sum(y_*tf.log(y))\n\n注意，以上的交叉熵不是局限于一张图片，而是整个可用的数据集。\n\n接下来我们以代价函数最小化为目标，来训练模型以得到相应的参数值(即权值和偏置)。TensorFlow知道你的计算过程，它会自动利用[后向传播算法](http://colah.github.io/posts/2015-08-Backprop/)来得到相应的参数变化，对代价函数最小化的影响作用。然后，你可以选择一个优化算法来决定如何最小化代价函数。如下，\n\n\ttrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n\n在这里，我们使用了一个学习率为0.01的梯度下降算法来最小化代价函数。梯度下降是一个简单的计算方式，即使得变量值朝着减小代价函数值的方向变化。TensorFlow也提供了许多[其他的优化算法](https://www.tensorflow.org/versions/master/api_docs/python/train.html#optimizers)，仅需要一行代码即可实现调用。\n\nTensorFlow提供了以上简单抽象的函数调用功能，你不需要关心其底层实现，可以更加专心于整个计算流程。在模型训练之前，还需要对所有的参数进行初始化：\n\n\tinit = tf.initialize_all_variables()\n\n我们可以在一个Session里面运行模型，并且进行初始化：\n\n\tsess = tf.Session()\n\tsess.run(init)\t\n\n接下来，进行模型的训练\n\n\tfor i in range(1000):\n\t  batch_xs, batch_ys = mnist.train.next_batch(100)\n\t  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\n每一次的循环中，我们取训练数据中的100个随机数据，这种操作成为批处理(batch)。然后，每次运行train_step时，将之前所选择的数据，填充至所设置的占位符中，作为模型的输入。\n\n以上过程成为**随机梯度下降**，在这里使用它是非常合适的。因为它既能保证运行效率，也能一定程度上保证程序运行的正确性。（理论上，我们应该在每一次循环过程中，利用所有的训练数据来得到正确的梯度下降方向，但这样将非常耗时）。\n\n### 模型的评价 ###\n\n怎样评价所训练出来的模型？显然，我们可以用图片预测类别的准确率。\n\n首先，利用`tf.argmax()`函数来得到预测和实际的图片label值，再用一个`tf.equal()`函数来判断预测值和真实值是否一致。如下：\n\n\tcorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n\ncorrect_prediction是一个布尔值的列表，例如 [True, False, True, True]。可以使用`tf.cast()`函数将其转换为[1, 0, 1, 1]，以方便准确率的计算（以上的是准确率为0.75）。\n\n\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n最后，我们来获取模型在测试集上的准确率，\n\n\tprint(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n\nSoftmax regression模型由于模型较简单，所以在测试集上的准确率在91%左右，这个结果并不算太好。通过一些简单的优化，准确率可以达到97%，目前最好的模型的准确率为99.7%。（[**这里**](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)有众多模型在MNIST数据集上的运行结果）。\n\n### 完整代码及运行结果 ###\n\n利用Softmax模型实现手写体识别的完整代码如下：\n\n\t__author__ = 'chapter'\n\t\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\tmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\tprint(\"Download Done!\")\n\t\n\tx = tf.placeholder(tf.float32, [None, 784])\n\t\n\t# paras\n\tW = tf.Variable(tf.zeros([784, 10]))\n\tb = tf.Variable(tf.zeros([10]))\n\t\n\ty = tf.nn.softmax(tf.matmul(x, W) + b)\n\ty_ = tf.placeholder(tf.float32, [None, 10])\n\t\n\t# loss func\n\tcross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n\t\n\ttrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n\t\n\t# init\n\tinit = tf.initialize_all_variables()\n\t\n\tsess = tf.Session()\n\tsess.run(init)\n\t\n\t# train\n\tfor i in range(1000):\n\t    batch_xs, batch_ys = mnist.train.next_batch(100)\n\t    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\t\n\tcorrect_prediction = tf.equal(tf.arg_max(y, 1), tf.arg_max(y_, 1))\n\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\t\n\tprint(\"Accuarcy on Test-dataset: \", sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n\n\n运行结果如下图：\n\n![](http://i.imgur.com/7lEZf7M.png)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/tensorflow-learning-notes.html\n\n**参考资料**\n\n[TensorFlow官方帮助文档](https://www.tensorflow.org/versions/master/get_started/index.html)\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/tensorflow-learning-notes.md","raw":"title: TensorFlow学习笔记1：入门\ndate: 2016-01-13 16:49:49\ntags: [TensorFlow, Machine Learning, Deep Learning, Artificial Intelligence]\ncategories: Machine Learning\n---\n\n![Tensor Flow](http://i.imgur.com/UT4vj57.jpg)\n\n## TensorFlow 简介 ##\n\nTensorFlow是Google在2015年11月份开源的人工智能系统（[**Github项目地址**](https://github.com/tensorflow/tensorflow)），是之前所开发的深度学习基础架构DistBelief的改进版本，该系统可以被用于语音识别、图片识别等多个领域。\n\n[官网](https://www.tensorflow.org/)上对TensorFlow的介绍是，一个使用数据流图(data flow graphs)技术来进行数值计算的开源软件库。数据流图中的节点，代表数值运算；节点节点之间的边，代表**多维数据**(tensors)之间的某种联系。你可以在多种设备（含有CPU或GPU）上通过简单的API调用来使用该系统的功能。TensorFlow是由Google Brain团队的研发人员负责的项目。\n\n### 什么是数据流图(Data Flow Graph) ###\n\n数据流图是描述`有向图`中的数值计算过程。`有向图`中的节点通常代表数学运算，但也可以表示数据的输入、输出和读写等操作；`有向图`中的边表示节点之间的某种联系，它负责传输多维数据(Tensors)。图中这些`tensors`的`flow`也就是TensorFlow的命名来源。\n\n节点可以被分配到多个计算设备上，可以异步和并行地执行操作。因为是有向图，所以只有等到之前的入度节点们的计算状态完成后，当前节点才能执行操作。\n\n### TensorFlow的特性 ###\n\n**1 灵活性**\n\nTensorFlow不是一个严格的神经网络工具包，只要你可以使用数据流图来描述你的计算过程，你可以使用TensorFlow做任何事情。你还可以方便地根据需要来构建数据流图，用简单的Python语言来实现高层次的功能。\n\n**2 可移植性**\n\nTensorFlow可以在任意具备CPU或者GPU的设备上运行，你可以专注于实现你的想法，而不用去考虑硬件环境问题，你甚至可以利用Docker技术来实现相关的云服务。\n\n**3 提高开发效率**\n\nTensorFlow可以提升你所研究的东西产品化的效率，并且可以方便与同行们共享代码。\n\n**4 支持语言选项**\n\n目前TensorFlow支持Python和C++语言。（但是你可以自己编写喜爱语言的SWIG接口）\n\n**5 充分利用硬件资源，最大化计算性能**\n\n## 基本使用 ##\n\n你需要理解在TensorFlow中，是如何：\n\n- 将计算流程表示成图；\n- 通过**`Sessions`**来执行图计算；\n- 将数据表示为**`tensors`**；\n- 使用**`Variables`**来保持状态信息；\n- 分别使用**`feeds`**和**`fetches`**来填充数据和抓取任意的操作结果；\n\n### 概览 ###\n\nTensorFlow是一种将计算表示为图的编程系统。图中的节点称为**`ops`**(operation的简称)。一个**`ops`**使用0个或以上的`Tensors`，通过执行某些运算，产生0个或以上的`Tensors`。**一个`Tensor`是一个多维数组**，例如，你可以将一批图像表示为一个四维的数组`[batch, height, width, channels]`，数组中的值均为浮点数。\n\nTensorFlow中的图描述了计算过程，图通过`Session`的运行而执行计算。`Session`将图的节点们(即ops)放置到计算设备(如CPUs和GPUs)上，然后通过方法执行它们；这些方法执行完成后，将返回tensors。在Python中的tensor的形式是`numpy ndarray`对象，而在C/C++中则是`tensorflow::Tensor`.\n\n### 图计算 ###\n\nTensorFlow程序中图的创建类似于一个 [施工阶段]，而在 [执行阶段] 则利用一个`session`来执行图中的节点。很常见的情况是，在 [施工阶段] 创建一个图来表示和训练神经网络，而在 [执行阶段] 在图中重复执行一系列的训练操作。\n\n#### 创建图 ####\n\n在TensorFlow中，`Constant`是一种没有输入的`ops`，但是你可以将它作为其他`ops`的输入。Python库中的`ops构造器`将返回构造器的输出。TensorFlow的Python库中有一个默认的图，将`ops构造器`作为节点，更多可了解[Graph Class文档](https://www.tensorflow.org/versions/r0.7/api_docs/python/framework.html#Graph)。\n\n见下面的示例代码：\n\n\timport tensorflow as tf\n\t\n\t# Create a Constant op that produces a 1x2 matrix.  The op is\n\t# added as a node to the default graph.\n\t#\n\t# The value returned by the constructor represents the output\n\t# of the Constant op.\n\tmatrix1 = tf.constant([[3., 3.]])\n\t\n\t# Create another Constant that produces a 2x1 matrix.\n\tmatrix2 = tf.constant([[2.],[2.]])\n\t\n\t# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n\t# The returned value, 'product', represents the result of the matrix\n\t# multiplication.\n\tproduct = tf.matmul(matrix1, matrix2)\n\n默认的图(Default Graph)现在有了三个节点：两个 `Constant()`ops和一个`matmul()`op。为了得到这两个矩阵的乘积结果，还需要在一个`session`中启动图计算。\n\n#### 在Session中执行图计算 ####\n\n见下面的示例代码，更多可了解[Session Class](https://www.tensorflow.org/versions/r0.7/api_docs/python/client.html#session-management)：\n\n\t# Launch the default graph.\n\tsess = tf.Session()\n\t\n\t# To run the matmul op we call the session 'run()' method, passing 'product'\n\t# which represents the output of the matmul op.  This indicates to the call\n\t# that we want to get the output of the matmul op back.\n\t#\n\t# All inputs needed by the op are run automatically by the session.  They\n\t# typically are run in parallel.\n\t#\n\t# The call 'run(product)' thus causes the execution of threes ops in the\n\t# graph: the two constants and matmul.\n\t#\n\t# The output of the op is returned in 'result' as a numpy `ndarray` object.\n\tresult = sess.run(product)\n\tprint(result)\n\t# ==> [[ 12.]]\n\t\n\t# Close the Session when we're done.\n\tsess.close()\n\nSessions最后需要关闭，以释放相关的资源；你也可以使用`with`模块，session在`with`模块中自动会关闭：\n\n\twith tf.Session() as sess:\n\t  result = sess.run([product])\n\t  print(result)\n\nTensorFlow的这些节点最终将在计算设备(CPUs,GPus)上执行运算。如果是使用GPU，默认会在第一块GPU上执行，如果你想在第二块多余的GPU上执行：\n\n\twith tf.Session() as sess:\n\t  with tf.device(\"/gpu:1\"):\n\t    matrix1 = tf.constant([[3., 3.]])\n\t    matrix2 = tf.constant([[2.],[2.]])\n\t    product = tf.matmul(matrix1, matrix2)\n\t    ...\n\ndevice中的各个字符串含义如下：\n\n- `\"/cpu:0\"`: 你机器的CPU；\n- `\"/gpu:0\"`: 你机器的第一个GPU；\n- `\"/gpu:1\"`: 你机器的第二个GPU；\n\n关于TensorFlow中GPU的使用见[这里](https://www.tensorflow.org/versions/r0.7/how_tos/using_gpu/index.html)。\n\n### 交互环境下的使用 ###\n\n以上的python示例中，使用了`Session`和`Session.run()`来执行图计算。然而，在一些Python的交互环境下(如IPython中)，你可以使用`InteractiveSession`类，以及`Tensor.eval()`、`Operation.run()`等方法。例如，在交互的Python环境下执行以下代码：\n\n\t# Enter an interactive TensorFlow Session.\n\timport tensorflow as tf\n\tsess = tf.InteractiveSession()\n\t\n\tx = tf.Variable([1.0, 2.0])\n\ta = tf.constant([3.0, 3.0])\n\t\n\t# Initialize 'x' using the run() method of its initializer op.\n\tx.initializer.run()\n\t\n\t# Add an op to subtract 'a' from 'x'.  Run it and print the result\n\tsub = tf.sub(x, a)\n\tprint(sub.eval())\n\t# ==> [-2. -1.]\n\t\n\t# Close the Session when we're done.\n\tsess.close()\n\n### Tensors ###\n\nTensorFlow中使用`tensor`数据结构（实际上就是一个多维数据）表示所有的数据，并在图计算中的节点之间传递数据。一个`tensor`具有固定的类型、级别和大小，更加深入理解这些概念可参考[Rank, Shape, and Type](https://www.tensorflow.org/versions/r0.7/resources/dims_types.html)。\n\n### 变量(Variables) ###\n\n变量在图执行的过程中，保持着自己的状态信息。下面代码中的变量充当了一个简单的计数器角色：\n\n\t# Create a Variable, that will be initialized to the scalar value 0.\n\tstate = tf.Variable(0, name=\"counter\")\n\t\n\t# Create an Op to add one to `state`.\n\t\n\tone = tf.constant(1)\n\tnew_value = tf.add(state, one)\n\tupdate = tf.assign(state, new_value)\n\t\n\t# Variables must be initialized by running an `init` Op after having\n\t# launched the graph.  We first have to add the `init` Op to the graph.\n\tinit_op = tf.initialize_all_variables()\n\t\n\t# Launch the graph and run the ops.\n\twith tf.Session() as sess:\n\t  # Run the 'init' op\n\t  sess.run(init_op)\n\t  # Print the initial value of 'state'\n\t  print(sess.run(state))\n\t  # Run the op that updates 'state' and print 'state'.\n\t  for _ in range(3):\n\t    sess.run(update)\n\t    print(sess.run(state))\n\t\n\t# output:\n\t\n\t# 0\n\t# 1\n\t# 2\n\t# 3\n\n赋值函数`assign()`和`add()`函数类似，直到session的`run()`之后才会执行操作。与之类似的，一般我们会将神经网络模型中的参数表示为一系列的变量，在模型的训练过程中对变量进行更新操作。\n\n### 抓取(Fetches) ###\n\n为了抓取`ops`的输出，需要先执行`session`的`run`函数。然后，通过`print`函数打印状态信息。\n\n\tinput1 = tf.constant(3.0)\n\tinput2 = tf.constant(2.0)\n\tinput3 = tf.constant(5.0)\n\tintermed = tf.add(input2, input3)\n\tmul = tf.mul(input1, intermed)\n\t\n\twith tf.Session() as sess:\n\t  result = sess.run([mul, intermed])\n\t  print(result)\n\t\n\t# output:\n\t# [array([ 21.], dtype=float32), array([ 7.], dtype=float32)]\n\n所有tensors的输出都是一次性 [连贯] 执行的。\n\n### 填充(Feeds) ###\n\nTensorFlow也提供这样的机制：先创建特定数据类型的占位符(placeholder)，之后再进行数据的填充。例如下面的程序：\n\n\tinput1 = tf.placeholder(tf.float32)\n\tinput2 = tf.placeholder(tf.float32)\n\toutput = tf.mul(input1, input2)\n\t\n\twith tf.Session() as sess:\n\t  print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))\n\t\n\t# output:\n\t# [array([ 14.], dtype=float32)]\n\n如果不对`placeholder()`的变量进行数据填充，将会引发错误，更多的例子可参考[MNIST fully-connected feed tutorial (source code)](https://www.tensorflow.org/versions/r0.7/tutorials/mnist/tf/index.html)。\n\n\n## 示例：曲线拟合 ##\n\n下面是一段使用Python写的，曲线拟合计算。官网将此作为刚开始介绍的示例程序。\n\n\t# 简化调用库名\n\timport tensorflow as tf\n\timport numpy as np\n\t\n\t# 模拟生成100对数据对, 对应的函数为y = x * 0.1 + 0.3\n\tx_data = np.random.rand(100).astype(\"float32\")\n\ty_data = x_data * 0.1 + 0.3\n\t\n\t# 指定w和b变量的取值范围（注意我们要利用TensorFlow来得到w和b的值）\n\tW = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n\tb = tf.Variable(tf.zeros([1]))\n\ty = W * x_data + b\n\t\n\t# 最小化均方误差\n\tloss = tf.reduce_mean(tf.square(y - y_data))\n\toptimizer = tf.train.GradientDescentOptimizer(0.5)\n\ttrain = optimizer.minimize(loss)\n\t\n\t# 初始化TensorFlow参数\n\tinit = tf.initialize_all_variables()\n\t\n\t# 运行数据流图（注意在这一步才开始执行计算过程）\n\tsess = tf.Session()\n\tsess.run(init)\n\t\n\t# 观察多次迭代计算时，w和b的拟合值\n\tfor step in xrange(201):\n\t    sess.run(train)\n\t    if step % 20 == 0:\n\t        print(step, sess.run(W), sess.run(b))\n\t\n\t# 最好的情况是w和b分别接近甚至等于0.1和0.3\n\n\n## MNIST手写体识别任务 ##\n\n下面我们介绍一个神经网络中的经典示例，MNIST手写体识别。这个任务相当于是机器学习中的HelloWorld程序。\n\n### MNIST数据集介绍 ###\n\nMNIST是一个简单的图片数据集（[数据集下载地址](http://yann.lecun.com/exdb/mnist/)），包含了大量的数字手写体图片。下面是一些示例图片：\n\n![MNIST](http://i.imgur.com/SQTMzsC.png)\n\nMNIST数据集是含标注信息的，以上图片分别代表5, 0, 4和1。\n\n由于MNIST数据集是TensorFlow的示例数据，所以我们不必下载。只需要下面两行代码，即可实现数据集的读取工作：\n\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\tmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\t\n\nMNIST数据集一共包含三个部分：训练数据集(55,000份，mnist.train)、测试数据集(10,000份，mnist.test)和验证数据集(5,000份，mnist.validation)。一般来说，训练数据集是用来训练模型，验证数据集可以检验所训练出来的模型的正确性和是否过拟合，测试集是不可见的（相当于一个黑盒），但我们最终的目的是使得所训练出来的模型在测试集上的效果（这里是准确性）达到最佳。\n\nMNIST中的一个数据样本包含两块：手写体图片和对于的label。这里我们用`xs`和`ys`分别代表图片和对应的label，训练数据集和测试数据集都有xs和ys，我们使用 mnist.train.images 和 mnist.train.labels 表示训练数据集中图片数据和对于的label数据。\n\n一张图片是一个28*28的像素点矩阵，我们可以用一个同大小的二维整数矩阵来表示。如下：\n\n![](http://i.imgur.com/QoBA21J.png)\n\n但是，这里我们可以先简单地使用一个长度为28 * 28 = 784的一维数组来表示图像，因为下面仅仅使用softmax regression来对图片进行识别分类（尽管这样做会损失图片的二维空间信息，所以实际上最好的计算机视觉算法是会利用图片的二维信息的）。\n\n所以MNIST的训练数据集可以是一个形状为55000 * 784位的`tensor`，也就是一个多维数组，第一维表示图片的索引，第二维表示图片中像素的索引（\"tensor\"中的像素值在0到1之间）。如下图：\n\n![](http://i.imgur.com/rnNXzOC.png)\n\nMNIST中的数字手写体图片的label值在1到9之间，是图片所表示的真实数字。这里用One-hot vector来表述label值，vector的长度为label值的数目，vector中有且只有一位为1，其他为0.为了方便，我们表示某个数字时在vector中所对应的索引位置设置1，其他位置元素为0. 例如用[0,0,0,1,0,0,0,0,0,0]来表示`3`。所以，mnist.train.labels是一个55000 * 10的二维数组。如下：\n\n![](http://i.imgur.com/8X0IbcY.png)\n\n以上是MNIST数据集的描述及TensorFlow中表示。下面介绍Softmax Regression模型。\n\n### Softmax Regression模型 ###\n\n数字手写体图片的识别，实际上可以转化成一个概率问题，如果我们知道一张图片表示`9`的概率为80%，而剩下的20%概率分布在`8`，`6`和其他数字上，那么从概率的角度上，我们可以大致推断该图片表示的是9.\n\nSoftmax Regression是一个简单的模型，很适合用来处理得到一个待分类对象在多个类别上的概率分布。所以，这个模型通常是很多高级模型的最后一步。\n\nSoftmax Regression大致分为两步（暂时不知道如何合理翻译，转原话）：\n\n**Step 1**: add up the evidence of our input being in certain classes;\n**Step 2**: convert that evidence into probabilities.\n\n为了利用图片中各个像素点的信息，我们将图片中的各个像素点的值与一定的权值相乘并累加，权值的正负是有意义的，如果是正的，那么表示对应像素值（不为0的话）对表示该数字类别是积极的；否则，对应像素值(不为0的话)对表示该数字类别是起负面作用的。下面是一个直观的例子，图片中蓝色表示正值，红色表示负值（蓝色区域的形状趋向于数字形状）：\n\n![](http://i.imgur.com/Zff5Y7Q.png)\n\n最后，我们在一个图片类别的evidence(不知如何翻译..)中加入偏置(bias)，加入偏置的目的是加入一些与输入独立无关的信息。所以图片类别的evidence可表示为\n\n$$ evidence\\_{i}=\\sum \\_{j}W\\_{ij}x\\_{j}+b\\_{i} $$\n\n其中，\\\\( W\\_i \\\\) 和 \\\\( b\\_i \\\\) 分别为类别 \\\\( i \\\\) 的权值和偏置，\\\\( j \\\\) 是输入图片 \\\\( x \\\\) 的像素索引。然后，我们将得到的evidence值通过一个\"softmax\"函数转化为概率值 \\\\( y \\\\) :\n\n$$ y = softmax(evidence) $$\n\n这里softmax函数的作用相当于是一个转换函数，它的作用是将原始的线性函数输出结果以某种方式转换为我们需要的值，这里我们需要0-9十个类别上的概率分布。softmax函数的定义如下：\n\n$$ softmax(x) = normalize(exp(x)) $$\n\n具体计算方式如下\n\n$$ softmax(x)\\_{i} = \\dfrac {exp\\left( x\\_{i}\\right) } {\\Sigma \\_{j}exp\\left( x\\_{j}\\right) } $$\n\n这里的softmax函数能够得到类别上的概率值分布，并保证所有类别上的概率值之和为1. 下面的图示将有助于你理解softmax函数的计算过程：\n\n![](http://i.imgur.com/sqlI5oC.png)\n\n如果我们将这个过程公式化，将得到\n\n![](http://i.imgur.com/ANwDWKW.png)\n\n实际的计算中，我们通常采用矢量计算的方式，如下\n\n![](http://i.imgur.com/f0c2kWB.png)\n\n也可以简化成\n\n$$ y = softmax( Wx + b ) $$\n\n### Softmax Regression的程序实现 ###\n\n为了在Python中进行科学计算工作，我们常常使用一些独立库函数包，例如NumPy来实现复杂的矩阵计算。但是由于Python的运行效率并不够快，所以常常用一些更加高效的语言来实现。但是，这样做会带来语言转换（例如转换回python操作）的开销。TensorFlow在这方面做了一些优化，可以对你所描述的一系列的交互计算的流程完全独立于Python之外，从而避免了语言切换的开销。\n\n为了使用TensorFlow，我们需要引用该库函数\n\n\timport tensorflow as tf\n\n我们利用一些符号变量来描述交互计算的过程，创建如下\n\n\tx = tf.placeholder(tf.float32, [None, 784])\n\n这里的 \\\\( x \\\\) 不是一个特定的值，而是一个占位符，即需要时指定。如前所述，我们用一个1 * 784维的向量来表示一张MNIST中的图片。我们用[None, 784]这样一个二维的tensor来表示整个MNIST数据集，其中`None`表示可以为任意值。\n\n我们使用`Variable`(变量)来表示模型中的权值和偏置，这些参数是可变的。如下，\n\n\tW = tf.Variable(tf.zeros([784, 10]))\n\tb = tf.Variable(tf.zeros([10]))\n\n这里的W和b均被初始化为0值矩阵。W的维数为784 * 10，是因为我们需要将一个784维的像素值经过相应的权值之乘转化为10个类别上的evidence值；b是十个类别上累加的偏置值。\n\n**实现softmax regression模型仅需要一行代码**，如下\n  \n\ty = tf.nn.softmax(tf.matmul(x, W) + b)\n\n其中，`matmul`函数实现了 x 和 W 的乘积，这里 x 为二维矩阵，所以放在前面。可以看出，在TensorFlow中实现softmax regression模型是很简单的。\n\n### 模型的训练 ###\n\n在机器学习中，通常需要选择一个代价函数（或者损失函数），来指示训练模型的好坏。这里，我们使用交叉熵函数（cross-entropy）作为代价函数，交叉熵是一个源于信息论中信息压缩领域的概念，但是现在已经应用在多个领域。它的定义如下：\n\n$$ H\\_{y'}\\left( y\\right) = -\\sum \\_{i}y\\_{i}'\\log \\left( y\\_{i}\\right) $$\n\n这里 \\\\( y \\\\) 是所预测的概率分布，而 \\\\( y' \\\\) 是真实的分布(one-hot vector表示的图片label)。直观上，交叉熵函数的输出值表示了预测的概率分布与真实的分布的符合程度。更加深入地理解交叉熵函数，可参考[这篇博文](http://colah.github.io/posts/2015-09-Visual-Information/)。\n\n为了实现交叉熵函数，我们需要先设置一个占位符在存放图片的正确label值，\n\n\ty_ = tf.placeholder(tf.float32, [None, 10])\n\n然后得到交叉熵，即\\\\( -\\sum y'\\log \\left( y\\right) \\\\)：\n\n\tcross_entropy = -tf.reduce_sum(y_*tf.log(y))\n\n注意，以上的交叉熵不是局限于一张图片，而是整个可用的数据集。\n\n接下来我们以代价函数最小化为目标，来训练模型以得到相应的参数值(即权值和偏置)。TensorFlow知道你的计算过程，它会自动利用[后向传播算法](http://colah.github.io/posts/2015-08-Backprop/)来得到相应的参数变化，对代价函数最小化的影响作用。然后，你可以选择一个优化算法来决定如何最小化代价函数。如下，\n\n\ttrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n\n在这里，我们使用了一个学习率为0.01的梯度下降算法来最小化代价函数。梯度下降是一个简单的计算方式，即使得变量值朝着减小代价函数值的方向变化。TensorFlow也提供了许多[其他的优化算法](https://www.tensorflow.org/versions/master/api_docs/python/train.html#optimizers)，仅需要一行代码即可实现调用。\n\nTensorFlow提供了以上简单抽象的函数调用功能，你不需要关心其底层实现，可以更加专心于整个计算流程。在模型训练之前，还需要对所有的参数进行初始化：\n\n\tinit = tf.initialize_all_variables()\n\n我们可以在一个Session里面运行模型，并且进行初始化：\n\n\tsess = tf.Session()\n\tsess.run(init)\t\n\n接下来，进行模型的训练\n\n\tfor i in range(1000):\n\t  batch_xs, batch_ys = mnist.train.next_batch(100)\n\t  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\n每一次的循环中，我们取训练数据中的100个随机数据，这种操作成为批处理(batch)。然后，每次运行train_step时，将之前所选择的数据，填充至所设置的占位符中，作为模型的输入。\n\n以上过程成为**随机梯度下降**，在这里使用它是非常合适的。因为它既能保证运行效率，也能一定程度上保证程序运行的正确性。（理论上，我们应该在每一次循环过程中，利用所有的训练数据来得到正确的梯度下降方向，但这样将非常耗时）。\n\n### 模型的评价 ###\n\n怎样评价所训练出来的模型？显然，我们可以用图片预测类别的准确率。\n\n首先，利用`tf.argmax()`函数来得到预测和实际的图片label值，再用一个`tf.equal()`函数来判断预测值和真实值是否一致。如下：\n\n\tcorrect_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n\ncorrect_prediction是一个布尔值的列表，例如 [True, False, True, True]。可以使用`tf.cast()`函数将其转换为[1, 0, 1, 1]，以方便准确率的计算（以上的是准确率为0.75）。\n\n\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n最后，我们来获取模型在测试集上的准确率，\n\n\tprint(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n\nSoftmax regression模型由于模型较简单，所以在测试集上的准确率在91%左右，这个结果并不算太好。通过一些简单的优化，准确率可以达到97%，目前最好的模型的准确率为99.7%。（[**这里**](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html)有众多模型在MNIST数据集上的运行结果）。\n\n### 完整代码及运行结果 ###\n\n利用Softmax模型实现手写体识别的完整代码如下：\n\n\t__author__ = 'chapter'\n\t\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\tmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\tprint(\"Download Done!\")\n\t\n\tx = tf.placeholder(tf.float32, [None, 784])\n\t\n\t# paras\n\tW = tf.Variable(tf.zeros([784, 10]))\n\tb = tf.Variable(tf.zeros([10]))\n\t\n\ty = tf.nn.softmax(tf.matmul(x, W) + b)\n\ty_ = tf.placeholder(tf.float32, [None, 10])\n\t\n\t# loss func\n\tcross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n\t\n\ttrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n\t\n\t# init\n\tinit = tf.initialize_all_variables()\n\t\n\tsess = tf.Session()\n\tsess.run(init)\n\t\n\t# train\n\tfor i in range(1000):\n\t    batch_xs, batch_ys = mnist.train.next_batch(100)\n\t    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n\t\n\tcorrect_prediction = tf.equal(tf.arg_max(y, 1), tf.arg_max(y_, 1))\n\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\t\n\tprint(\"Accuarcy on Test-dataset: \", sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n\n\n运行结果如下图：\n\n![](http://i.imgur.com/7lEZf7M.png)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/tensorflow-learning-notes.html\n\n**参考资料**\n\n[TensorFlow官方帮助文档](https://www.tensorflow.org/versions/master/get_started/index.html)\n\n\n\n\n\n\n\n\n\n\n","slug":"tensorflow-learning-notes","published":1,"updated":"2016-03-21T01:48:29.695Z","_id":"cinjqrkng0004nfq6w9qo4tag","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"TensorFlow学习笔记3：词向量","date":"2016-03-16T13:24:38.000Z","_content":"\n[**上篇博文**](http://www.jeyzhang.com/tensorflow-learning-notes-2.html)讲了如何构建一个简单的CNN模型，并运行在MNIST数据集上。下面讲述一下如何在TensorFlow中生成词向量(Word Embedding)，使用的模型来自[Mikolov et al](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)。\n\n本文的目录如下：\n\n- 解释使用连续词向量的原因；\n- 词向量模型的原理及训练过程；\n- 在TensorFlow中实现模型的简单版本，并给出优化的方法；\n\n\nTensorFlow实现了两个版本的模型：[简单版](https://www.tensorflow.org/code/tensorflow/examples/tutorials/word2vec/word2vec_basic.py)和[正式版](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py)。如果想看源码的，可以直接下载。\n\n----------\n\n### 为什么要使用Word Embedding ###\n\n在信号处理领域，图像和音频信号的输入往往是表示成高维度、密集的向量形式，在图像和音频的应用系统中，如何对输入信息进行编码(Encoding)显得非常重要和关键，这将直接决定了系统的质量。然而，在自然语言处理领域中，传统的做法是将词表示成离散的符号，例如将 [cat] 表示为 [Id537]，而 [dog] 表示为 [Id143]。**这样做的缺点在于，没有提供足够的信息来体现词语之间的某种关联**，例如尽管cat和dog不是同一个词，但是却应该有着某种的联系（如都是属于动物种类）。由于这种一元表示法(One-hot Representation)使得词向量过于稀疏，所以往往需要大量的语料数据才能训练出一个令人满意的模型。而Word Embedding技术则可以解决上述传统方法带来的问题。\n\n![](http://i.imgur.com/dHTf4Gq.png)\n\n**向量空间模型(Vector space models, VSMs)**将词语表示为一个连续的词向量，并且语义接近的词语对应的词向量在空间上也是接近的。VSMs在NLP中拥有很长的历史，但是所有的方法在某种程度上都是基于一种**[分布式假说](https://en.wikipedia.org/wiki/Distributional_semantics#Distributional_Hypothesis)**，该假说的思想是**如果两个词的上下文(context)相同，那么这两个词所表达的语义也是一样的**；换言之，两个词的语义是否相同或相似，取决于两个词的上下文内容，上下文相同表示两个词是可以等价替换的。\n\n基于分布式假说理论的词向量生成方法主要分两大类：**计数法**(count-based methods, e.g. [Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis))和**预测法**(predictive methods, e.g. [neural probabilistic language models](http://www.scholarpedia.org/article/Neural_net_language_models))。[Baroni等人](http://clic.cimec.unitn.it/marco/publications/acl2014/baroni-etal-countpredict-acl2014.pdf)详细论述了这两种方法的区别，简而言之，计数法是在大型语料中统计词语及邻近的词的共现频率，然后将之为每个词都映射为一个稠密的向量表示；预测法是直接利用词语的邻近词信息来得到预测词的词向量（词向量通常作为模型的训练参数）。\n\n**`Wrod2vec`**是一个典型的预测模型，用于高效地学习Word Embedding。实现的模型有两种：**连续词袋模型(CBOW)**和**Skip-Gram模型**。算法上这两个模型是相似的，只不过CBOW是从输入的上下文信息来预测目标词(例如利用 [the cat sits on the] 来预测 [mat] )；而skip-gram模型则是相反的，从目标词来预测上下文信息。一般而言，这种方式上的区别使得CBOW模型更适合应用在小规模的数据集上，能够对很多的分布式信息进行平滑处理；而Skip-Gram模型则比较适合用于大规模的数据集上。\n\n下面重点将介绍Skip-Gram模型。\n\n### 噪声-对比(Noise-Contrastive)训练 ###\n\n基于神经网络的概率语言模型通常都是使用**[最大似然估计](https://en.wikipedia.org/wiki/Maximum_likelihood)**的方法进行训练的，通过Softmax函数得到在前面出现的词语 \\\\( h \\\\) (`history`)的情况下，目标词 \\\\( w\\_{t} \\\\) (`target`)出现的最大概率，数学表达式如下：\n\n![](http://i.imgur.com/vpOKwSG.png)\n\n其中，\\\\( score(w\\_t, h) \\\\) 为词 \\\\(w\\_t\\\\) 和上下文 \\\\(h\\\\) 的 [兼容程度]。上式的对数形式如下：\n\n![](http://i.imgur.com/jG5Rppa.png)\n\n理论上可以根据这个来建立一个合理的模型，但是现实中目标函数的计算代价非常昂贵，这是因为在训练过程中的每一步，我们都需要计算词库 \\\\(w'\\\\) 中其他词在当前的上下文环境下出现的概率值，这导致计算量十分巨大。\n\n![](http://i.imgur.com/Ck90mom.png)\n\n然而，对于word2vec中的特征学习，可以不需要一个完整的概率模型。CBOW和Skip-Gram模型在输出端使用的是一个二分类器(即Logistic Regression)，来区分目标词和词库中其他的 \\\\(k\\\\) 个词。下面是一个CBOW模型的图示，对于Skip-Gram模型输入输出是倒置的。\n\n![](http://i.imgur.com/KnqFhUD.png)\n\n此时，最大化的目标函数如下：\n\n![](http://i.imgur.com/g4PPKUW.png)\n\n其中，\\\\( Q\\_\\theta(D=1 | w, h) \\\\) 为二元逻辑回归的概率，具体为在数据集 \\\\(D\\\\) 中、输入的embedding vector \\\\( \\theta \\\\)、上下文为 \\\\( h \\\\) 的情况下词语 \\\\(w\\\\) 出现的概率；公式后半部分为 \\\\(k\\\\) 个从 [噪声数据集] 中随机选择 \\\\(k\\\\) 个对立的词语出现概率(log形式)的期望值（即为[Monte Carlo average](https://en.wikipedia.org/wiki/Monte_Carlo_integration)）。\n\n可以看出，目标函数的意义是显然的，即尽可能的 [分配(assign)] 高概率给真实的目标词，而低概率给其他 \\\\( k \\\\) 个 [噪声词]，这种技术称为**[负采样(Negative Sampling)](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)**。同时，该目标函数具有很好的数学意义：**即在条件限制(训练时间)的情况下尽可能的逼近原有的Softmax函数（选择 \\\\( k \\\\) 个 [噪声点] 作为整个 [噪声数据] 的代表）**，这样做无疑能够大大提升模型训练的速度。实际中我们使用的是类似的[噪声对比估计损失函数(noise-contrastive estimation (NCE))](http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf)，在TensorFlow中对应的实现函数为`tf.nn.nce_loss()`。\n\n下面看看具体是如何训练Skip-Gram模型的。\n\n### Skip-Gram模型 ###\n\n举个例子，假设现在的数据集如下：\n\n\tthe quick brown fox jumped over the lazy dog\n\n这个数据集中包含了词语及其上下文信息。值得说明的是，**上下文信息(Context)**是一个比较宽泛的概念，有多种不同的理解：例如，词语周边的句法结构，词语的左边部分的若干个词语信息，对应的右半部分等。这里，我们使用最原始和基本的定义，即认为**词语左右相邻的若干个词汇是该词对应的上下文信息**。例如，取左右的词窗口为1，下面是数据集中的**`(上下文信息，对应的词)`**的pairs：\n\n\t([the, brown], quick), ([quick, fox], brown), ([brown, jumped], fox), ...\n\nSkip-Gram模型是通过输入的目标词来预测其对应的上下文信息，所以目标是通过[quick]来预测[the]和[brown]，通过[brown]来预测[quick]和[fox]... 将上面的pair转换为**`(input, output)`**的形式如下：\n\n\t(quick, the), (quick, brown), (brown, quick), (brown, fox), ...\n\n目标函数定义如上，使用[随机梯度下降算法(SGD)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)来进行最优化求解，并且使用mini-batch方法 (通常batch_size在16到512之间)。\n\n下面将详细剖析一下训练过程。假设在训练的第 \\\\(t\\\\) 步，目标是得到上面第一个实例输入 [quick] 的输出预测；我们选择`num_noise`个 [噪声点数据]，简单起见，这里`num_noise`为1，假设选择 [sheep] 作为噪声对比词。那么，此时的目标函数值如下：\n\n![](http://i.imgur.com/tmgHXZZ.png)\n\n目标是**更新embedding参数 \\\\(\\theta\\\\) 以增大目标函数值**，更新的方式是计算损失函数对参数 \\\\(\\theta\\\\) 的导数，即 \\\\( \\frac{\\partial}{\\partial \\theta} J\\_\\text{NEG} \\\\) (TensorFlow中有相应的函数以方便计算)，然后使得参数 \\\\(\\theta\\\\) 朝梯度方向进行调整。当这个过程在训练数据集上执行多次后，产生的效果是使得输入的embedding vector的值发生改变，使得模型最终能够很好地区别目标词和 [噪声词]。\n\n我们可以将学到的词向量进行降维(如[t-SNE降维技术](\\frac{\\partial}{\\partial \\theta} J_\\text{NEG}))和可视化，通过可视化发现**连续的词向量能够捕捉到更多的语义和关联信息**；有趣的是，在降维空间中某些特定的方向表征着特定的语义信息，例如下图中的[man->women]，[king->queen]方向表示性别关系(出自[Mikolov et al., 2013](http://www.aclweb.org/anthology/N13-1090))。\n\n![](http://i.imgur.com/vM1dtFq.png)\n\n这也证实了连续词向量的作用，目前有非常多NLP中的任务(例如词性标注、命名实体识别等)都是使用连续词向量作为特征输入（更多可参考[Collobert et al., 2011](http://arxiv.org/abs/1103.0398)，[Turian et al., 2010](http://www.aclweb.org/anthology/P10-1040)）。\n\n下面看看具体在TensorFlow中，是如何实现模型的创建和训练的。\n\n### 构建模型 ###\n\n首先，我们要定义一下**词嵌入矩阵(Embedding Matrix)**，并随机初始化。\n\n\tembeddings = tf.Variable(\n\ttf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n\n噪声-对比估计的损失函数在输出的逻辑回归模型中定义，为此，需要定义词库中每个词的权值和偏置参数(称为输出层权值参数)，如下：\n\n\tnce_weights = tf.Variable(\n\t  tf.truncated_normal([vocabulary_size, embedding_size],\n\t\tstddev=1.0 / math.sqrt(embedding_size)))\n\tnce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n\n现在我们有了这些模型参数，接下来需要定义Skip-Gram模型。简单起见，假设我们已经将语料库中的词[**整数化**]，即每个词被表示为一个整数(具体见[tensorflow/examples/tutorials/word2vec/word2vec_basic.py](https://www.tensorflow.org/code/tensorflow/examples/tutorials/word2vec/word2vec_basic.py))。Skip-Gram模型有两种输入，都是整数形式表示：一种是批量的上下文词汇，一种是目标词。我们先为这些输入创建占位符(placeholder)，之后再进行数据的填充。\n\n\t# Placeholders for inputs\n\ttrain_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n\ttrain_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n\n我们还需要能够查找(look up)batch中的输入词对应的vector，如下：\n\n\tembed = tf.nn.embedding_lookup(embeddings, train_inputs)\n\n现在，我们有了每个词对应的embedding，接下来使用噪声-对比策略来预测目标词：\n\n\t# Compute the NCE loss, using a sample of the negative labels each time.\n\tloss = tf.reduce_mean(\n\t  tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,\n\t                 num_sampled, vocabulary_size))\n\n现在，我们有了损失函数节点(loss node)，还需要利用随机梯度下降来进行优化，定义如下的优化器：\n\n\t# We use the SGD optimizer.\n\toptimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(loss)\n\n### 模型的训练 ###\n\n模型的训练方式很简单，只需要迭代地通过`feed_dict`进行训练数据的填充，并启动一个session。\n\n\tfor inputs, labels in generate_batch(...):\n\t  feed_dict = {training_inputs: inputs, training_labels: labels}\n\t  _, cur_loss = session.run([optimizer, loss], feed_dict=feed_dict)\n\n完整的示例代码请参考[tensorflow/examples/tutorials/word2vec/word2vec_basic.py](https://www.tensorflow.org/code/tensorflow/examples/tutorials/word2vec/word2vec_basic.py)。\n\n### Embedding的可视化 ###\n\n模型训练结束后，我们利用`t-SNE技术`实现学习到的embedding可视化，如下图所示：\n\n![](http://i.imgur.com/z2VpgFz.png)\n\n正如我们期望的那样，语义相似的词语会聚集在一起。关于word2vec更加高级的实现版本，可参考[tensorflow/models/embedding/word2vec.py](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py)。\n\n### Embedding的评价：类比推理(Analogical Reasoning)###\n\nEmbedding在许多的NLP任务中都很有效果，那么如何评价Embedding的效果呢？一种简单的方式是，直接用来预测句法和语义的关联性，例如预测**`king is to queen as father is to ?`**，这称作**`Analogical Reasoning`**(By [Mikolov and colleagues](http://msr-waypoint.com/en-us/um/people/gzweig/Pubs/NAACL2013Regularities.pdf), 评价数据集可在[这里](https://www.google.com/url?q=https://word2vec.googlecode.com/svn/trunk/questions-words.txt&usg=AFQjCNHs2OomcnDRRaht8ih-rL2oHnOSwQ)下载)。\n\n具体如何进行评价的，可以参考[正式word2vec版本](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py)中的`build_eval_graph()`和`eval()`函数。\n\n评价任务的准确性依赖于模型的超参数们，为了达到最佳的效果，往往需要将评价任务建立在一个巨大的数据集上，还可能需要使用一些trick，例如数据抽样、适当的fine tuning等。\n\n### 进一步的优化 ###\n\n以上的Vanilla版本展示了TensorFlow的简单易用。例如，只需要调用`tf.nn.nce_loss()`就可以替换`tf.nn.sampled_softmax_loss()`。如果你有关于损失函数的新想法，也可以自己在TensorFlow中手写一个，然后使用优化器计算导数并作优化。TensorFlow的简单易用，可以帮助你快速验证自己的想法。\n\n一旦你有了一个令人满意的模型结构，你可以针对它进行优化使其更加高效。例如，原始版本中有个不足之处是，数据读取和填充是用Python实现的，因此会相对低效。你可以自己实现一个reader，参考[数据格式要求](https://www.tensorflow.org/versions/r0.7/how_tos/new_data_formats/index.html)。对于Skip-Gram模型，我们在[这个版本](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py)中自定义了reader，可供参考。\n\n如果你的模型在I/O上足够好了，但仍然想要提升效率，你可以自己编写TensorFlow Ops（[参考这里](https://www.tensorflow.org/versions/r0.7/how_tos/adding_an_op/index.html)）.[优化版本](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec_optimized.py)中提供了示例。\n\n### 总结 ###\n\n这篇博文介绍了word2vec模型，一个用来高效学习出word embedding的模型。我们解释了为什么word embedding是有效的，讨论了如何更加高效地训练模型以及如何在TensorFlow中去实现。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/tensorflow-learning-notes-3.html\n\n**参考资料**\n\n[TensorFlow: Vector Representation of Words](https://www.tensorflow.org/versions/r0.7/tutorials/word2vec/index.html)","source":"_posts/tensorflow-learning-notes-3.md","raw":"title: TensorFlow学习笔记3：词向量\ndate: 2016-03-16 21:24:38\ntags: [TensorFlow, Machine Learning, Deep Learning, Artificial Intelligence]\ncategories: Machine Learning\n---\n\n[**上篇博文**](http://www.jeyzhang.com/tensorflow-learning-notes-2.html)讲了如何构建一个简单的CNN模型，并运行在MNIST数据集上。下面讲述一下如何在TensorFlow中生成词向量(Word Embedding)，使用的模型来自[Mikolov et al](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)。\n\n本文的目录如下：\n\n- 解释使用连续词向量的原因；\n- 词向量模型的原理及训练过程；\n- 在TensorFlow中实现模型的简单版本，并给出优化的方法；\n\n\nTensorFlow实现了两个版本的模型：[简单版](https://www.tensorflow.org/code/tensorflow/examples/tutorials/word2vec/word2vec_basic.py)和[正式版](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py)。如果想看源码的，可以直接下载。\n\n----------\n\n### 为什么要使用Word Embedding ###\n\n在信号处理领域，图像和音频信号的输入往往是表示成高维度、密集的向量形式，在图像和音频的应用系统中，如何对输入信息进行编码(Encoding)显得非常重要和关键，这将直接决定了系统的质量。然而，在自然语言处理领域中，传统的做法是将词表示成离散的符号，例如将 [cat] 表示为 [Id537]，而 [dog] 表示为 [Id143]。**这样做的缺点在于，没有提供足够的信息来体现词语之间的某种关联**，例如尽管cat和dog不是同一个词，但是却应该有着某种的联系（如都是属于动物种类）。由于这种一元表示法(One-hot Representation)使得词向量过于稀疏，所以往往需要大量的语料数据才能训练出一个令人满意的模型。而Word Embedding技术则可以解决上述传统方法带来的问题。\n\n![](http://i.imgur.com/dHTf4Gq.png)\n\n**向量空间模型(Vector space models, VSMs)**将词语表示为一个连续的词向量，并且语义接近的词语对应的词向量在空间上也是接近的。VSMs在NLP中拥有很长的历史，但是所有的方法在某种程度上都是基于一种**[分布式假说](https://en.wikipedia.org/wiki/Distributional_semantics#Distributional_Hypothesis)**，该假说的思想是**如果两个词的上下文(context)相同，那么这两个词所表达的语义也是一样的**；换言之，两个词的语义是否相同或相似，取决于两个词的上下文内容，上下文相同表示两个词是可以等价替换的。\n\n基于分布式假说理论的词向量生成方法主要分两大类：**计数法**(count-based methods, e.g. [Latent Semantic Analysis](https://en.wikipedia.org/wiki/Latent_semantic_analysis))和**预测法**(predictive methods, e.g. [neural probabilistic language models](http://www.scholarpedia.org/article/Neural_net_language_models))。[Baroni等人](http://clic.cimec.unitn.it/marco/publications/acl2014/baroni-etal-countpredict-acl2014.pdf)详细论述了这两种方法的区别，简而言之，计数法是在大型语料中统计词语及邻近的词的共现频率，然后将之为每个词都映射为一个稠密的向量表示；预测法是直接利用词语的邻近词信息来得到预测词的词向量（词向量通常作为模型的训练参数）。\n\n**`Wrod2vec`**是一个典型的预测模型，用于高效地学习Word Embedding。实现的模型有两种：**连续词袋模型(CBOW)**和**Skip-Gram模型**。算法上这两个模型是相似的，只不过CBOW是从输入的上下文信息来预测目标词(例如利用 [the cat sits on the] 来预测 [mat] )；而skip-gram模型则是相反的，从目标词来预测上下文信息。一般而言，这种方式上的区别使得CBOW模型更适合应用在小规模的数据集上，能够对很多的分布式信息进行平滑处理；而Skip-Gram模型则比较适合用于大规模的数据集上。\n\n下面重点将介绍Skip-Gram模型。\n\n### 噪声-对比(Noise-Contrastive)训练 ###\n\n基于神经网络的概率语言模型通常都是使用**[最大似然估计](https://en.wikipedia.org/wiki/Maximum_likelihood)**的方法进行训练的，通过Softmax函数得到在前面出现的词语 \\\\( h \\\\) (`history`)的情况下，目标词 \\\\( w\\_{t} \\\\) (`target`)出现的最大概率，数学表达式如下：\n\n![](http://i.imgur.com/vpOKwSG.png)\n\n其中，\\\\( score(w\\_t, h) \\\\) 为词 \\\\(w\\_t\\\\) 和上下文 \\\\(h\\\\) 的 [兼容程度]。上式的对数形式如下：\n\n![](http://i.imgur.com/jG5Rppa.png)\n\n理论上可以根据这个来建立一个合理的模型，但是现实中目标函数的计算代价非常昂贵，这是因为在训练过程中的每一步，我们都需要计算词库 \\\\(w'\\\\) 中其他词在当前的上下文环境下出现的概率值，这导致计算量十分巨大。\n\n![](http://i.imgur.com/Ck90mom.png)\n\n然而，对于word2vec中的特征学习，可以不需要一个完整的概率模型。CBOW和Skip-Gram模型在输出端使用的是一个二分类器(即Logistic Regression)，来区分目标词和词库中其他的 \\\\(k\\\\) 个词。下面是一个CBOW模型的图示，对于Skip-Gram模型输入输出是倒置的。\n\n![](http://i.imgur.com/KnqFhUD.png)\n\n此时，最大化的目标函数如下：\n\n![](http://i.imgur.com/g4PPKUW.png)\n\n其中，\\\\( Q\\_\\theta(D=1 | w, h) \\\\) 为二元逻辑回归的概率，具体为在数据集 \\\\(D\\\\) 中、输入的embedding vector \\\\( \\theta \\\\)、上下文为 \\\\( h \\\\) 的情况下词语 \\\\(w\\\\) 出现的概率；公式后半部分为 \\\\(k\\\\) 个从 [噪声数据集] 中随机选择 \\\\(k\\\\) 个对立的词语出现概率(log形式)的期望值（即为[Monte Carlo average](https://en.wikipedia.org/wiki/Monte_Carlo_integration)）。\n\n可以看出，目标函数的意义是显然的，即尽可能的 [分配(assign)] 高概率给真实的目标词，而低概率给其他 \\\\( k \\\\) 个 [噪声词]，这种技术称为**[负采样(Negative Sampling)](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)**。同时，该目标函数具有很好的数学意义：**即在条件限制(训练时间)的情况下尽可能的逼近原有的Softmax函数（选择 \\\\( k \\\\) 个 [噪声点] 作为整个 [噪声数据] 的代表）**，这样做无疑能够大大提升模型训练的速度。实际中我们使用的是类似的[噪声对比估计损失函数(noise-contrastive estimation (NCE))](http://papers.nips.cc/paper/5165-learning-word-embeddings-efficiently-with-noise-contrastive-estimation.pdf)，在TensorFlow中对应的实现函数为`tf.nn.nce_loss()`。\n\n下面看看具体是如何训练Skip-Gram模型的。\n\n### Skip-Gram模型 ###\n\n举个例子，假设现在的数据集如下：\n\n\tthe quick brown fox jumped over the lazy dog\n\n这个数据集中包含了词语及其上下文信息。值得说明的是，**上下文信息(Context)**是一个比较宽泛的概念，有多种不同的理解：例如，词语周边的句法结构，词语的左边部分的若干个词语信息，对应的右半部分等。这里，我们使用最原始和基本的定义，即认为**词语左右相邻的若干个词汇是该词对应的上下文信息**。例如，取左右的词窗口为1，下面是数据集中的**`(上下文信息，对应的词)`**的pairs：\n\n\t([the, brown], quick), ([quick, fox], brown), ([brown, jumped], fox), ...\n\nSkip-Gram模型是通过输入的目标词来预测其对应的上下文信息，所以目标是通过[quick]来预测[the]和[brown]，通过[brown]来预测[quick]和[fox]... 将上面的pair转换为**`(input, output)`**的形式如下：\n\n\t(quick, the), (quick, brown), (brown, quick), (brown, fox), ...\n\n目标函数定义如上，使用[随机梯度下降算法(SGD)](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)来进行最优化求解，并且使用mini-batch方法 (通常batch_size在16到512之间)。\n\n下面将详细剖析一下训练过程。假设在训练的第 \\\\(t\\\\) 步，目标是得到上面第一个实例输入 [quick] 的输出预测；我们选择`num_noise`个 [噪声点数据]，简单起见，这里`num_noise`为1，假设选择 [sheep] 作为噪声对比词。那么，此时的目标函数值如下：\n\n![](http://i.imgur.com/tmgHXZZ.png)\n\n目标是**更新embedding参数 \\\\(\\theta\\\\) 以增大目标函数值**，更新的方式是计算损失函数对参数 \\\\(\\theta\\\\) 的导数，即 \\\\( \\frac{\\partial}{\\partial \\theta} J\\_\\text{NEG} \\\\) (TensorFlow中有相应的函数以方便计算)，然后使得参数 \\\\(\\theta\\\\) 朝梯度方向进行调整。当这个过程在训练数据集上执行多次后，产生的效果是使得输入的embedding vector的值发生改变，使得模型最终能够很好地区别目标词和 [噪声词]。\n\n我们可以将学到的词向量进行降维(如[t-SNE降维技术](\\frac{\\partial}{\\partial \\theta} J_\\text{NEG}))和可视化，通过可视化发现**连续的词向量能够捕捉到更多的语义和关联信息**；有趣的是，在降维空间中某些特定的方向表征着特定的语义信息，例如下图中的[man->women]，[king->queen]方向表示性别关系(出自[Mikolov et al., 2013](http://www.aclweb.org/anthology/N13-1090))。\n\n![](http://i.imgur.com/vM1dtFq.png)\n\n这也证实了连续词向量的作用，目前有非常多NLP中的任务(例如词性标注、命名实体识别等)都是使用连续词向量作为特征输入（更多可参考[Collobert et al., 2011](http://arxiv.org/abs/1103.0398)，[Turian et al., 2010](http://www.aclweb.org/anthology/P10-1040)）。\n\n下面看看具体在TensorFlow中，是如何实现模型的创建和训练的。\n\n### 构建模型 ###\n\n首先，我们要定义一下**词嵌入矩阵(Embedding Matrix)**，并随机初始化。\n\n\tembeddings = tf.Variable(\n\ttf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n\n噪声-对比估计的损失函数在输出的逻辑回归模型中定义，为此，需要定义词库中每个词的权值和偏置参数(称为输出层权值参数)，如下：\n\n\tnce_weights = tf.Variable(\n\t  tf.truncated_normal([vocabulary_size, embedding_size],\n\t\tstddev=1.0 / math.sqrt(embedding_size)))\n\tnce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n\n现在我们有了这些模型参数，接下来需要定义Skip-Gram模型。简单起见，假设我们已经将语料库中的词[**整数化**]，即每个词被表示为一个整数(具体见[tensorflow/examples/tutorials/word2vec/word2vec_basic.py](https://www.tensorflow.org/code/tensorflow/examples/tutorials/word2vec/word2vec_basic.py))。Skip-Gram模型有两种输入，都是整数形式表示：一种是批量的上下文词汇，一种是目标词。我们先为这些输入创建占位符(placeholder)，之后再进行数据的填充。\n\n\t# Placeholders for inputs\n\ttrain_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n\ttrain_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n\n我们还需要能够查找(look up)batch中的输入词对应的vector，如下：\n\n\tembed = tf.nn.embedding_lookup(embeddings, train_inputs)\n\n现在，我们有了每个词对应的embedding，接下来使用噪声-对比策略来预测目标词：\n\n\t# Compute the NCE loss, using a sample of the negative labels each time.\n\tloss = tf.reduce_mean(\n\t  tf.nn.nce_loss(nce_weights, nce_biases, embed, train_labels,\n\t                 num_sampled, vocabulary_size))\n\n现在，我们有了损失函数节点(loss node)，还需要利用随机梯度下降来进行优化，定义如下的优化器：\n\n\t# We use the SGD optimizer.\n\toptimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(loss)\n\n### 模型的训练 ###\n\n模型的训练方式很简单，只需要迭代地通过`feed_dict`进行训练数据的填充，并启动一个session。\n\n\tfor inputs, labels in generate_batch(...):\n\t  feed_dict = {training_inputs: inputs, training_labels: labels}\n\t  _, cur_loss = session.run([optimizer, loss], feed_dict=feed_dict)\n\n完整的示例代码请参考[tensorflow/examples/tutorials/word2vec/word2vec_basic.py](https://www.tensorflow.org/code/tensorflow/examples/tutorials/word2vec/word2vec_basic.py)。\n\n### Embedding的可视化 ###\n\n模型训练结束后，我们利用`t-SNE技术`实现学习到的embedding可视化，如下图所示：\n\n![](http://i.imgur.com/z2VpgFz.png)\n\n正如我们期望的那样，语义相似的词语会聚集在一起。关于word2vec更加高级的实现版本，可参考[tensorflow/models/embedding/word2vec.py](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py)。\n\n### Embedding的评价：类比推理(Analogical Reasoning)###\n\nEmbedding在许多的NLP任务中都很有效果，那么如何评价Embedding的效果呢？一种简单的方式是，直接用来预测句法和语义的关联性，例如预测**`king is to queen as father is to ?`**，这称作**`Analogical Reasoning`**(By [Mikolov and colleagues](http://msr-waypoint.com/en-us/um/people/gzweig/Pubs/NAACL2013Regularities.pdf), 评价数据集可在[这里](https://www.google.com/url?q=https://word2vec.googlecode.com/svn/trunk/questions-words.txt&usg=AFQjCNHs2OomcnDRRaht8ih-rL2oHnOSwQ)下载)。\n\n具体如何进行评价的，可以参考[正式word2vec版本](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py)中的`build_eval_graph()`和`eval()`函数。\n\n评价任务的准确性依赖于模型的超参数们，为了达到最佳的效果，往往需要将评价任务建立在一个巨大的数据集上，还可能需要使用一些trick，例如数据抽样、适当的fine tuning等。\n\n### 进一步的优化 ###\n\n以上的Vanilla版本展示了TensorFlow的简单易用。例如，只需要调用`tf.nn.nce_loss()`就可以替换`tf.nn.sampled_softmax_loss()`。如果你有关于损失函数的新想法，也可以自己在TensorFlow中手写一个，然后使用优化器计算导数并作优化。TensorFlow的简单易用，可以帮助你快速验证自己的想法。\n\n一旦你有了一个令人满意的模型结构，你可以针对它进行优化使其更加高效。例如，原始版本中有个不足之处是，数据读取和填充是用Python实现的，因此会相对低效。你可以自己实现一个reader，参考[数据格式要求](https://www.tensorflow.org/versions/r0.7/how_tos/new_data_formats/index.html)。对于Skip-Gram模型，我们在[这个版本](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec.py)中自定义了reader，可供参考。\n\n如果你的模型在I/O上足够好了，但仍然想要提升效率，你可以自己编写TensorFlow Ops（[参考这里](https://www.tensorflow.org/versions/r0.7/how_tos/adding_an_op/index.html)）.[优化版本](https://www.tensorflow.org/code/tensorflow/models/embedding/word2vec_optimized.py)中提供了示例。\n\n### 总结 ###\n\n这篇博文介绍了word2vec模型，一个用来高效学习出word embedding的模型。我们解释了为什么word embedding是有效的，讨论了如何更加高效地训练模型以及如何在TensorFlow中去实现。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/tensorflow-learning-notes-3.html\n\n**参考资料**\n\n[TensorFlow: Vector Representation of Words](https://www.tensorflow.org/versions/r0.7/tutorials/word2vec/index.html)","slug":"tensorflow-learning-notes-3","published":1,"updated":"2016-03-17T13:15:03.661Z","_id":"cinjqrkny000fnfq61fcpg4fs","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"TensorFlow学习笔记2：构建CNN模型","date":"2016-01-31T05:02:56.000Z","_content":"\n[**上篇博文**](http://www.jeyzhang.com/tensorflow-learning-notes.html)主要是TensorFlow的一个简单入门，并介绍了如何实现Softmax Regression模型，来对MNIST数据集中的数字手写体进行识别。\n\n然而，由于Softmax Regression模型相对简单，所以最终的识别准确率并不高。下面将针对MNIST数据集构建更加复杂精巧的模型，以进一步提高识别准确率。\n\n----------\n\n## 深度学习模型 ##\n\nTensorFlow很适合用来进行大规模的数值计算，其中也包括实现和训练深度神经网络模型。下面将介绍TensorFlow中模型的基本组成部分，同时将构建一个CNN模型来对MNIST数据集中的数字手写体进行识别。\n\n### 基本设置 ###\n\n在我们构建模型之前，我们首先加载MNIST数据集，然后开启一个TensorFlow会话(session)。\n\n### 加载MNIST数据集 ###\n\nTensorFlow中已经有相关脚本，来自动下载和加载MNIST数据集。（脚本会自动创建MNIST_data文件夹来存储数据集）。下面是脚本程序：\n\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\tmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\n这里`mnist`是一个轻量级的类文件，存储了NumPy格式的训练集、验证集和测试集，它同样提供了数据中mini-batch迭代的功能。\n\n### 开启TensorFlow会话 ###\n\nTensorFlow后台计算依赖于高效的C++，与后台的连接称为一个会话(session)。TensorFlow中的程序使用，通常都是先创建一个图(graph)，然后在一个会话(session)里运行它。\n\n这里我们使用了一个更为方便的类，`InteractiveSession `，这能让你在构建代码时更加灵活。`InteractiveSession `允许你做一些交互操作，通过创建一个计算流图([computation graph](https://www.tensorflow.org/versions/r0.7/get_started/basic_usage.html#the-computation-graph))来部分地运行图计算。当你在一些交互环境（例如IPython）中使用时将更加方便。如果你不是使用`InteractiveSession `，那么你要在启动一个会话和运行图计算前，创建一个整体的计算流图。\n\n下面是如何创建一个`InteractiveSession `：\n\n\timport tensorflow as tf\n\tsess = tf.InteractiveSession()\n\n### 计算流图(Computation Graph) ###\n\n为了在Python中实现高效的数值运算，通常会使用一些Python以外的库函数，如NumPy。但是，这样做会造成转换Python操作的开销，尤其是在GPUs和分布式计算的环境下。TensorFlow在这一方面（指转化操作）做了优化，它让我们能够在Python之外描述一个包含各种交互计算操作的整体流图，而不是每次都独立地在Python之外运行一个单独的计算，避免了许多的转换开销。这样的优化方法同样用在了`Theano`和`Torch`上。\n\n所以，以上这样的Python代码的作用是简历一个完整的计算流图，然后指定图中的哪些部分需要运行。关于计算流图的更多具体使用见[这里](https://www.tensorflow.org/versions/r0.7/get_started/basic_usage.html#the-computation-graph)。\n\n### Softmax Regression模型 ###\n\n见[**上篇博文**](http://www.jeyzhang.com/tensorflow-learning-notes.html)。\n\n### CNN模型 ###\n\nSoftmax Regression模型在MNIST数据集上91%的准确率，其实还是比较低的。下面我们将使用一个更加精巧的模型，一个简单的卷积神经网络模型(CNN)。这个模型能够达到99.2%的准确率，尽管这不是最高的，但已经足够接受了。\n\n#### 权值初始化 ####\n\n为了建立模型，我们需要先创建一些权值(w)和偏置(b)等参数，这些参数的初始化过程中需要加入一小部分的`噪声`以破坏参数整体的对称性，同时避免梯度为0.由于我们使用`ReLU`激活函数（[**详细介绍**](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))），所以我们通常将这些参数初始化为很小的正值。为了避免重复的初始化操作，我们可以创建下面两个函数：\n\n\tdef weight_variable(shape):\n\t  initial = tf.truncated_normal(shape, stddev=0.1)\n\t  return tf.Variable(initial)\n\t\n\tdef bias_variable(shape):\n\t  initial = tf.constant(0.1, shape=shape)\n\t  return tf.Variable(initial)\n\n#### 卷积(Convolution)和池化(Pooling) ####\n\nTensorFlow同样提供了方便的卷积和池化计算。怎样处理边界元素？怎样设置卷积窗口大小？在这个例子中，我们始终使用`vanilla`版本。这里的卷积操作仅使用了滑动步长为1的窗口，使用0进行填充，所以输出规模和输入的一致；而池化操作是在2 * 2的窗口内采用最大池化技术(max-pooling)。为了使代码简洁，同样将这些操作抽象为函数形式：\n\n\tdef conv2d(x, W):\n\t  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\t\n\tdef max_pool_2x2(x):\n\t  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n\t                        strides=[1, 2, 2, 1], padding='SAME')\n\n其中，`padding='SAME'`表示通过填充0，使得输入和输出的形状一致。\n\n#### 第一层：卷积层 ####\n\n第一层是卷积层，卷积层将要计算出32个特征映射(feature map)，对每个5 * 5的patch。它的权值tensor的大小为[5, 5, 1, 32]. 前两维是patch的大小，第三维时输入通道的数目，最后一维是输出通道的数目。我们对每个输出通道加上了偏置(bias)。\n\n\tW_conv1 = weight_variable([5, 5, 1, 32])\n\tb_conv1 = bias_variable([32])\n\n为了使得图片与计算层匹配，我们首先`reshape`输入图像`x`为4维的tensor，第2、3维对应图片的宽和高，最后一维对应颜色通道的数目。（**？第1维为什么是-1？**）\n\n\tx_image = tf.reshape(x, [-1,28,28,1])\n\n然后，使用`weight tensor`对`x_image`进行卷积计算，加上`bias`，再应用到一个`ReLU`激活函数，最终采用最大池化。\n\n\th_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n\th_pool1 = max_pool_2x2(h_conv1)\n\n#### 第二层：卷积层 ####\n\n为了使得网络有足够深度，我们重复堆积一些相同类型的层。第二层将会有64个特征，对应每个5 * 5的patch。\n\n\tW_conv2 = weight_variable([5, 5, 32, 64])\n\tb_conv2 = bias_variable([64])\n\t\n\th_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n\th_pool2 = max_pool_2x2(h_conv2)\n\n#### 全连接层 ####\n\n到目前为止，图像的尺寸被缩减为7 * 7，我们最后加入一个神经元数目为1024的全连接层来处理所有的图像上。接着，将最后的pooling层的输出reshape为一个一维向量，与权值相乘，加上偏置，再通过一个`ReLu`函数。\n\n\tW_fc1 = weight_variable([7 * 7 * 64, 1024])\n\tb_fc1 = bias_variable([1024])\n\t\n\th_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n\th_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n整个CNN的网络结构如下图：\n\n![](http://i.imgur.com/nfd2j9s.jpg)\n\n#### Dropout ####\n\n为了减少过拟合程度，在输出层之前应用`dropout`技术（即丢弃某些神经元的输出结果）。我们创建一个`placeholder`来表示一个神经元的输出在`dropout`时不被丢弃的概率。`Dropout`能够在训练过程中使用，而在测试过程中不使用。TensorFlow中的`tf.nn.dropout`操作能够利用`mask`技术处理各种规模的神经元输出。\n\n\tkeep_prob = tf.placeholder(tf.float32)\n\th_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n#### 输出层 ####\n\n最终，我们用一个`softmax`层，得到类别上的概率分布。（与之前的`Softmax Regression`模型相同）。\n\n\tW_fc2 = weight_variable([1024, 10])\n\tb_fc2 = bias_variable([10])\n\t\n\ty_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n\n#### 模型训练和测试 ####\n\n为了测试模型的性能，需要先对模型进行训练，然后应用在测试集上。和之前`Softmax Regression`模型中的训练、测试过程类似。区别在于：\n\n1. 用更复杂的`ADAM`最优化方法代替了之前的梯度下降；\n2. 增了额外的参数`keep_prob`在`feed_dict`中，以控制`dropout`的几率；\n3. 在训练过程中，增加了log输出功能（每100次迭代输出一次）。\n\n下面是程序：\n\n\tcross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n\ttrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\tcorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\tsess.run(tf.initialize_all_variables())\n\tfor i in range(20000):\n\t  batch = mnist.train.next_batch(50)\n\t  if i%100 == 0:\n\t    train_accuracy = accuracy.eval(feed_dict={\n\t        x:batch[0], y_: batch[1], keep_prob: 1.0})\n\t    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n\t  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\t\n\tprint(\"test accuracy %g\"%accuracy.eval(feed_dict={\n\t    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\n最终，模型在测试集上的准确率大概为99.2%，性能上要优于之前的`Softmax Regression`模型。\n\n#### 完整代码及运行结果 ####\n\n利用CNN模型实现手写体识别的完整代码如下：\n\n\t__author__ = 'chapter'\n\t\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\tdef weight_varible(shape):\n\t    initial = tf.truncated_normal(shape, stddev=0.1)\n\t    return tf.Variable(initial)\n\t\n\tdef bias_variable(shape):\n\t    initial = tf.constant(0.1, shape=shape)\n\t    return tf.Variable(initial)\n\t\n\tdef conv2d(x, W):\n\t    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\t\n\tdef max_pool_2x2(x):\n\t    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\t\n\t\n\tmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\tprint(\"Download Done!\")\n\t\n\tsess = tf.InteractiveSession()\n\t\n\t# paras\n\tW_conv1 = weight_varible([5, 5, 1, 32])\n\tb_conv1 = bias_variable([32])\n\t\n\t# conv layer-1\n\tx = tf.placeholder(tf.float32, [None, 784])\n\tx_image = tf.reshape(x, [-1, 28, 28, 1])\n\t\n\th_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n\th_pool1 = max_pool_2x2(h_conv1)\n\t\n\t# conv layer-2\n\tW_conv2 = weight_varible([5, 5, 32, 64])\n\tb_conv2 = bias_variable([64])\n\t\n\th_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n\th_pool2 = max_pool_2x2(h_conv2)\n\t\n\t# full connection\n\tW_fc1 = weight_varible([7 * 7 * 64, 1024])\n\tb_fc1 = bias_variable([1024])\n\t\n\th_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n\th_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\t\n\t# dropout\n\tkeep_prob = tf.placeholder(tf.float32)\n\th_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\t\n\t# output layer: softmax\n\tW_fc2 = weight_varible([1024, 10])\n\tb_fc2 = bias_variable([10])\n\t\n\ty_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n\ty_ = tf.placeholder(tf.float32, [None, 10])\n\t\n\t# model training\n\tcross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n\ttrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\t\n\tcorrect_prediction = tf.equal(tf.arg_max(y_conv, 1), tf.arg_max(y_, 1))\n\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\t\n\tsess.run(tf.initialize_all_variables())\n\t\n\tfor i in range(20000):\n\t    batch = mnist.train.next_batch(50)\n\t\n\t    if i % 100 == 0:\n\t        train_accuacy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n\t        print(\"step %d, training accuracy %g\"%(i, train_accuacy))\n\t    train_step.run(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 0.5})\n\t\n\t# accuacy on test\n\tprint(\"test accuracy %g\"%(accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0})))\n\n运行结果如下图：\n\n![](http://i.imgur.com/KIep4sT.png)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/tensorflow-learning-notes-2.html\n\n**参考资料**\n\n[TensorFlow: Deep MNIST for Experts](https://www.tensorflow.org/versions/r0.7/tutorials/mnist/pros/index.html#deep-mnist-for-experts)","source":"_posts/tensorflow-learning-notes-2.md","raw":"title: TensorFlow学习笔记2：构建CNN模型\ndate: 2016-01-31 13:02:56\ntags: [TensorFlow, Machine Learning, Deep Learning, Artificial Intelligence]\ncategories: Machine Learning\n---\n\n[**上篇博文**](http://www.jeyzhang.com/tensorflow-learning-notes.html)主要是TensorFlow的一个简单入门，并介绍了如何实现Softmax Regression模型，来对MNIST数据集中的数字手写体进行识别。\n\n然而，由于Softmax Regression模型相对简单，所以最终的识别准确率并不高。下面将针对MNIST数据集构建更加复杂精巧的模型，以进一步提高识别准确率。\n\n----------\n\n## 深度学习模型 ##\n\nTensorFlow很适合用来进行大规模的数值计算，其中也包括实现和训练深度神经网络模型。下面将介绍TensorFlow中模型的基本组成部分，同时将构建一个CNN模型来对MNIST数据集中的数字手写体进行识别。\n\n### 基本设置 ###\n\n在我们构建模型之前，我们首先加载MNIST数据集，然后开启一个TensorFlow会话(session)。\n\n### 加载MNIST数据集 ###\n\nTensorFlow中已经有相关脚本，来自动下载和加载MNIST数据集。（脚本会自动创建MNIST_data文件夹来存储数据集）。下面是脚本程序：\n\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\tmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n\n这里`mnist`是一个轻量级的类文件，存储了NumPy格式的训练集、验证集和测试集，它同样提供了数据中mini-batch迭代的功能。\n\n### 开启TensorFlow会话 ###\n\nTensorFlow后台计算依赖于高效的C++，与后台的连接称为一个会话(session)。TensorFlow中的程序使用，通常都是先创建一个图(graph)，然后在一个会话(session)里运行它。\n\n这里我们使用了一个更为方便的类，`InteractiveSession `，这能让你在构建代码时更加灵活。`InteractiveSession `允许你做一些交互操作，通过创建一个计算流图([computation graph](https://www.tensorflow.org/versions/r0.7/get_started/basic_usage.html#the-computation-graph))来部分地运行图计算。当你在一些交互环境（例如IPython）中使用时将更加方便。如果你不是使用`InteractiveSession `，那么你要在启动一个会话和运行图计算前，创建一个整体的计算流图。\n\n下面是如何创建一个`InteractiveSession `：\n\n\timport tensorflow as tf\n\tsess = tf.InteractiveSession()\n\n### 计算流图(Computation Graph) ###\n\n为了在Python中实现高效的数值运算，通常会使用一些Python以外的库函数，如NumPy。但是，这样做会造成转换Python操作的开销，尤其是在GPUs和分布式计算的环境下。TensorFlow在这一方面（指转化操作）做了优化，它让我们能够在Python之外描述一个包含各种交互计算操作的整体流图，而不是每次都独立地在Python之外运行一个单独的计算，避免了许多的转换开销。这样的优化方法同样用在了`Theano`和`Torch`上。\n\n所以，以上这样的Python代码的作用是简历一个完整的计算流图，然后指定图中的哪些部分需要运行。关于计算流图的更多具体使用见[这里](https://www.tensorflow.org/versions/r0.7/get_started/basic_usage.html#the-computation-graph)。\n\n### Softmax Regression模型 ###\n\n见[**上篇博文**](http://www.jeyzhang.com/tensorflow-learning-notes.html)。\n\n### CNN模型 ###\n\nSoftmax Regression模型在MNIST数据集上91%的准确率，其实还是比较低的。下面我们将使用一个更加精巧的模型，一个简单的卷积神经网络模型(CNN)。这个模型能够达到99.2%的准确率，尽管这不是最高的，但已经足够接受了。\n\n#### 权值初始化 ####\n\n为了建立模型，我们需要先创建一些权值(w)和偏置(b)等参数，这些参数的初始化过程中需要加入一小部分的`噪声`以破坏参数整体的对称性，同时避免梯度为0.由于我们使用`ReLU`激活函数（[**详细介绍**](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))），所以我们通常将这些参数初始化为很小的正值。为了避免重复的初始化操作，我们可以创建下面两个函数：\n\n\tdef weight_variable(shape):\n\t  initial = tf.truncated_normal(shape, stddev=0.1)\n\t  return tf.Variable(initial)\n\t\n\tdef bias_variable(shape):\n\t  initial = tf.constant(0.1, shape=shape)\n\t  return tf.Variable(initial)\n\n#### 卷积(Convolution)和池化(Pooling) ####\n\nTensorFlow同样提供了方便的卷积和池化计算。怎样处理边界元素？怎样设置卷积窗口大小？在这个例子中，我们始终使用`vanilla`版本。这里的卷积操作仅使用了滑动步长为1的窗口，使用0进行填充，所以输出规模和输入的一致；而池化操作是在2 * 2的窗口内采用最大池化技术(max-pooling)。为了使代码简洁，同样将这些操作抽象为函数形式：\n\n\tdef conv2d(x, W):\n\t  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\t\n\tdef max_pool_2x2(x):\n\t  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n\t                        strides=[1, 2, 2, 1], padding='SAME')\n\n其中，`padding='SAME'`表示通过填充0，使得输入和输出的形状一致。\n\n#### 第一层：卷积层 ####\n\n第一层是卷积层，卷积层将要计算出32个特征映射(feature map)，对每个5 * 5的patch。它的权值tensor的大小为[5, 5, 1, 32]. 前两维是patch的大小，第三维时输入通道的数目，最后一维是输出通道的数目。我们对每个输出通道加上了偏置(bias)。\n\n\tW_conv1 = weight_variable([5, 5, 1, 32])\n\tb_conv1 = bias_variable([32])\n\n为了使得图片与计算层匹配，我们首先`reshape`输入图像`x`为4维的tensor，第2、3维对应图片的宽和高，最后一维对应颜色通道的数目。（**？第1维为什么是-1？**）\n\n\tx_image = tf.reshape(x, [-1,28,28,1])\n\n然后，使用`weight tensor`对`x_image`进行卷积计算，加上`bias`，再应用到一个`ReLU`激活函数，最终采用最大池化。\n\n\th_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n\th_pool1 = max_pool_2x2(h_conv1)\n\n#### 第二层：卷积层 ####\n\n为了使得网络有足够深度，我们重复堆积一些相同类型的层。第二层将会有64个特征，对应每个5 * 5的patch。\n\n\tW_conv2 = weight_variable([5, 5, 32, 64])\n\tb_conv2 = bias_variable([64])\n\t\n\th_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n\th_pool2 = max_pool_2x2(h_conv2)\n\n#### 全连接层 ####\n\n到目前为止，图像的尺寸被缩减为7 * 7，我们最后加入一个神经元数目为1024的全连接层来处理所有的图像上。接着，将最后的pooling层的输出reshape为一个一维向量，与权值相乘，加上偏置，再通过一个`ReLu`函数。\n\n\tW_fc1 = weight_variable([7 * 7 * 64, 1024])\n\tb_fc1 = bias_variable([1024])\n\t\n\th_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n\th_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n整个CNN的网络结构如下图：\n\n![](http://i.imgur.com/nfd2j9s.jpg)\n\n#### Dropout ####\n\n为了减少过拟合程度，在输出层之前应用`dropout`技术（即丢弃某些神经元的输出结果）。我们创建一个`placeholder`来表示一个神经元的输出在`dropout`时不被丢弃的概率。`Dropout`能够在训练过程中使用，而在测试过程中不使用。TensorFlow中的`tf.nn.dropout`操作能够利用`mask`技术处理各种规模的神经元输出。\n\n\tkeep_prob = tf.placeholder(tf.float32)\n\th_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n#### 输出层 ####\n\n最终，我们用一个`softmax`层，得到类别上的概率分布。（与之前的`Softmax Regression`模型相同）。\n\n\tW_fc2 = weight_variable([1024, 10])\n\tb_fc2 = bias_variable([10])\n\t\n\ty_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n\n#### 模型训练和测试 ####\n\n为了测试模型的性能，需要先对模型进行训练，然后应用在测试集上。和之前`Softmax Regression`模型中的训练、测试过程类似。区别在于：\n\n1. 用更复杂的`ADAM`最优化方法代替了之前的梯度下降；\n2. 增了额外的参数`keep_prob`在`feed_dict`中，以控制`dropout`的几率；\n3. 在训练过程中，增加了log输出功能（每100次迭代输出一次）。\n\n下面是程序：\n\n\tcross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n\ttrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\tcorrect_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\tsess.run(tf.initialize_all_variables())\n\tfor i in range(20000):\n\t  batch = mnist.train.next_batch(50)\n\t  if i%100 == 0:\n\t    train_accuracy = accuracy.eval(feed_dict={\n\t        x:batch[0], y_: batch[1], keep_prob: 1.0})\n\t    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n\t  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n\t\n\tprint(\"test accuracy %g\"%accuracy.eval(feed_dict={\n\t    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n\n最终，模型在测试集上的准确率大概为99.2%，性能上要优于之前的`Softmax Regression`模型。\n\n#### 完整代码及运行结果 ####\n\n利用CNN模型实现手写体识别的完整代码如下：\n\n\t__author__ = 'chapter'\n\t\n\timport tensorflow as tf\n\tfrom tensorflow.examples.tutorials.mnist import input_data\n\t\n\tdef weight_varible(shape):\n\t    initial = tf.truncated_normal(shape, stddev=0.1)\n\t    return tf.Variable(initial)\n\t\n\tdef bias_variable(shape):\n\t    initial = tf.constant(0.1, shape=shape)\n\t    return tf.Variable(initial)\n\t\n\tdef conv2d(x, W):\n\t    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\t\n\tdef max_pool_2x2(x):\n\t    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n\t\n\t\n\tmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\tprint(\"Download Done!\")\n\t\n\tsess = tf.InteractiveSession()\n\t\n\t# paras\n\tW_conv1 = weight_varible([5, 5, 1, 32])\n\tb_conv1 = bias_variable([32])\n\t\n\t# conv layer-1\n\tx = tf.placeholder(tf.float32, [None, 784])\n\tx_image = tf.reshape(x, [-1, 28, 28, 1])\n\t\n\th_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n\th_pool1 = max_pool_2x2(h_conv1)\n\t\n\t# conv layer-2\n\tW_conv2 = weight_varible([5, 5, 32, 64])\n\tb_conv2 = bias_variable([64])\n\t\n\th_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n\th_pool2 = max_pool_2x2(h_conv2)\n\t\n\t# full connection\n\tW_fc1 = weight_varible([7 * 7 * 64, 1024])\n\tb_fc1 = bias_variable([1024])\n\t\n\th_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n\th_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\t\n\t# dropout\n\tkeep_prob = tf.placeholder(tf.float32)\n\th_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\t\n\t# output layer: softmax\n\tW_fc2 = weight_varible([1024, 10])\n\tb_fc2 = bias_variable([10])\n\t\n\ty_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n\ty_ = tf.placeholder(tf.float32, [None, 10])\n\t\n\t# model training\n\tcross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n\ttrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\t\n\tcorrect_prediction = tf.equal(tf.arg_max(y_conv, 1), tf.arg_max(y_, 1))\n\taccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\t\n\tsess.run(tf.initialize_all_variables())\n\t\n\tfor i in range(20000):\n\t    batch = mnist.train.next_batch(50)\n\t\n\t    if i % 100 == 0:\n\t        train_accuacy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n\t        print(\"step %d, training accuracy %g\"%(i, train_accuacy))\n\t    train_step.run(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 0.5})\n\t\n\t# accuacy on test\n\tprint(\"test accuracy %g\"%(accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0})))\n\n运行结果如下图：\n\n![](http://i.imgur.com/KIep4sT.png)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/tensorflow-learning-notes-2.html\n\n**参考资料**\n\n[TensorFlow: Deep MNIST for Experts](https://www.tensorflow.org/versions/r0.7/tutorials/mnist/pros/index.html#deep-mnist-for-experts)","slug":"tensorflow-learning-notes-2","published":1,"updated":"2016-05-08T11:29:36.750Z","_id":"cinjqrko4000lnfq6crlz8gln","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"whoosh+jieba：python下实现中文全文检索","date":"2016-04-28T03:14:53.000Z","_content":"\n## 需要安装 ##\n\n* python 2.xx\n* whoosh\n* jieba\n\nwhoosh和jieba的安装使用`pip install`即可。\n\n## 快速入门 ##\n\n下面的代码实现了简单的中文检索\n\n    # coding=utf-8\n    import os\n    from whoosh.index import create_in\n    from whoosh.fields import *\n    from jieba.analyse import ChineseAnalyzer\n    import json\n\n    # 使用结巴中文分词\n    analyzer = ChineseAnalyzer()\n\n    # 创建schema, stored为True表示能够被检索\n    schema = Schema(title=TEXT(stored=True, analyzer=analyzer), path=ID(stored=False),\n                    content=TEXT(stored=True, analyzer=analyzer))\n\n    # 存储schema信息至'indexdir'目录下\n    indexdir = 'indexdir/'\n    if not os.path.exists(indexdir):\n        os.mkdir(indexdir)\n    ix = create_in(indexdir, schema)\n\n    # 按照schema定义信息，增加需要建立索引的文档\n    # 注意：字符串格式需要为unicode格式\n    writer = ix.writer()\n    writer.add_document(title=u\"第一篇文档\", path=u\"/a\",\n                        content=u\"这是我们增加的第一篇文档\")\n    writer.add_document(title=u\"第二篇文档\", path=u\"/b\",\n                        content=u\"第二篇文档也很interesting！\")\n    writer.commit()\n\n    # 创建一个检索器\n    searcher = ix.searcher()\n\n    # 检索标题中出现'文档'的文档\n    results = searcher.find(\"title\", u\"文档\")\n\n    # 检索出来的第一个结果，数据格式为dict{'title':.., 'content':...}\n    firstdoc = results[0].fields()\n\n    # python2中，需要使用json来打印包含unicode的dict内容\n    jsondoc = json.dumps(firstdoc, ensure_ascii=False)\n\n    print jsondoc  # 打印出检索出的文档全部内容\n    print results[0].highlights(\"title\")  # 高亮标题中的检索词\n    print results[0].score  # bm25分数","source":"_posts/realization-of-full-chinese-text-search-using-whoosh-and-jieba.md","raw":"title: whoosh+jieba：python下实现中文全文检索\ndate: 2016-04-28 11:14:53\ntags: [Python, Whoosh, Jieba, Search Engine]\ncategories: Python\n---\n\n## 需要安装 ##\n\n* python 2.xx\n* whoosh\n* jieba\n\nwhoosh和jieba的安装使用`pip install`即可。\n\n## 快速入门 ##\n\n下面的代码实现了简单的中文检索\n\n    # coding=utf-8\n    import os\n    from whoosh.index import create_in\n    from whoosh.fields import *\n    from jieba.analyse import ChineseAnalyzer\n    import json\n\n    # 使用结巴中文分词\n    analyzer = ChineseAnalyzer()\n\n    # 创建schema, stored为True表示能够被检索\n    schema = Schema(title=TEXT(stored=True, analyzer=analyzer), path=ID(stored=False),\n                    content=TEXT(stored=True, analyzer=analyzer))\n\n    # 存储schema信息至'indexdir'目录下\n    indexdir = 'indexdir/'\n    if not os.path.exists(indexdir):\n        os.mkdir(indexdir)\n    ix = create_in(indexdir, schema)\n\n    # 按照schema定义信息，增加需要建立索引的文档\n    # 注意：字符串格式需要为unicode格式\n    writer = ix.writer()\n    writer.add_document(title=u\"第一篇文档\", path=u\"/a\",\n                        content=u\"这是我们增加的第一篇文档\")\n    writer.add_document(title=u\"第二篇文档\", path=u\"/b\",\n                        content=u\"第二篇文档也很interesting！\")\n    writer.commit()\n\n    # 创建一个检索器\n    searcher = ix.searcher()\n\n    # 检索标题中出现'文档'的文档\n    results = searcher.find(\"title\", u\"文档\")\n\n    # 检索出来的第一个结果，数据格式为dict{'title':.., 'content':...}\n    firstdoc = results[0].fields()\n\n    # python2中，需要使用json来打印包含unicode的dict内容\n    jsondoc = json.dumps(firstdoc, ensure_ascii=False)\n\n    print jsondoc  # 打印出检索出的文档全部内容\n    print results[0].highlights(\"title\")  # 高亮标题中的检索词\n    print results[0].score  # bm25分数","slug":"realization-of-full-chinese-text-search-using-whoosh-and-jieba","published":1,"updated":"2016-05-08T11:29:56.181Z","_id":"cinjqrko9000rnfq6d7zjw8fd","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"python学习笔记与常见问题","date":"2016-04-27T09:22:49.000Z","_content":"\n## **列表** ##\n\n### 使用lambda函数实现列表操作\n\n实现两个list的元素对应相乘，返回同等大小的list结果。\n\n\tlist1 = [...]\n    list2 = [...]\n    multiply_list = map(lambda (a, b): a * b, zip(list1, list2))\n\n### 列表的类型转换 ###\n\n例如，经常遇到需要将元素类型为`int`的列表，转为元素类型为`str`的列表，可以方便的使用`join`等函数进行格式化处理。使用`map`函数将很简单：\n\n\tint_list = [1, 2, 3]\n    str_list = map(str, int_list) # str_list = ['1', '2', '3']\n    # 类似的还有：\n    map(int, list) # list中的元素均转为int类型\n    map(float, list) # list中的元素均转为float类型\n\n## **字符串及编码** ##\n\n### python2中unicode编码下中文显示问题\n\n使用`json`对对象进行包装，再打印或者写入文件，如下\n\n![](http://imgur.com/F7w50wW.png)\n\n写入文件时，需要转化为`UTF-8`编码，如下\n\n\tjsond = json.dumps(**, ensure_ascii=False)\n    f.write(jsond.encode('utf-8'))\n    ...\n\n在python3中打印unicode编码字符串很简单，使用**`pprint`**；python2中也可以使用**`pprint`**，具体做法见[**这里**](https://www.quora.com/How-do-you-print-a-python-unicode-data-structure)。\n\n\n\n\n\n\n","source":"_posts/python-learning-notes-and-common-problems.md","raw":"title: python学习笔记与常见问题\ndate: 2016-04-27 17:22:49\ntags: [Python]\ncategories: Python\n---\n\n## **列表** ##\n\n### 使用lambda函数实现列表操作\n\n实现两个list的元素对应相乘，返回同等大小的list结果。\n\n\tlist1 = [...]\n    list2 = [...]\n    multiply_list = map(lambda (a, b): a * b, zip(list1, list2))\n\n### 列表的类型转换 ###\n\n例如，经常遇到需要将元素类型为`int`的列表，转为元素类型为`str`的列表，可以方便的使用`join`等函数进行格式化处理。使用`map`函数将很简单：\n\n\tint_list = [1, 2, 3]\n    str_list = map(str, int_list) # str_list = ['1', '2', '3']\n    # 类似的还有：\n    map(int, list) # list中的元素均转为int类型\n    map(float, list) # list中的元素均转为float类型\n\n## **字符串及编码** ##\n\n### python2中unicode编码下中文显示问题\n\n使用`json`对对象进行包装，再打印或者写入文件，如下\n\n![](http://imgur.com/F7w50wW.png)\n\n写入文件时，需要转化为`UTF-8`编码，如下\n\n\tjsond = json.dumps(**, ensure_ascii=False)\n    f.write(jsond.encode('utf-8'))\n    ...\n\n在python3中打印unicode编码字符串很简单，使用**`pprint`**；python2中也可以使用**`pprint`**，具体做法见[**这里**](https://www.quora.com/How-do-you-print-a-python-unicode-data-structure)。\n\n\n\n\n\n\n","slug":"python-learning-notes-and-common-problems","published":1,"updated":"2016-05-08T11:29:56.174Z","_id":"cinjqrkoe0010nfq6wf05dnk0","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"TensorFlow中遇到的问题及解决方法","date":"2016-03-25T14:36:46.000Z","_content":"\n本文记录一下自己在使用TensorFlow的过程中，遇到的较为困扰的问题及最终的解决方法。\n\n----------\n\n### Q1. 如何查看TensorFlow中Tensor, Variable, Constant的值？ ###\n\nTensorFlow中的许多方法返回的都是一个Tensor对象。在Debug的过程中，我们发现只能看到Tensor对象的一些属性信息，无法查看Tensor具体的输出值；而对于Variable和Constant，我们很容易对其进行创建操作，但是如何得到它们的值呢？\n\n假设`ts`是我们想要查看的对象(Variable / Constant / 0输入的Tensor)，运行\n\n\tts_res = sess.run(ts)\n\tprint(ts_res)\n\n其中，`sess`为之前创建或默认的`session`. 运行后将得到一个`narray`格式的`ts_res`对象，通过`print`函数我们可以很方便的查看其中的内容。\n\n但是，如果`ts`是一个有输入要求的Tensor，需要在查看其输出值前，填充(feed)输入数据。如下（假设ts只有一种输入）：\n\n\tinput = ××××××  # the input data need to feed\n\tts_res = sess.run(ts, feed_dict=input)\n\tprint(ts_res)\n\n其他要求多种输入的Tensor类似处理即可。\n\n### Q2. 模型训练完成后，如何获取模型的参数？ ###\n\n模型训练完成后，通常会将模型参数存储于/checkpoint/×××.model文件(当然文件路径和文件名都可以更改，许多基于TensorFlow的开源包习惯将模型参数存储为model或者model.ckpt文件)。那么，在模型训练完成后，如何得到这些模型参数呢？\n\n需要以下两个步骤：\n\n**Step 1: 通过tf.train.Saver()恢复模型参数** \n\n运行\n\n\tsaver = tf.train.Saver()\n\n通过`saver`的`restore()`方法可以从本地的模型文件中恢复模型参数。大致做法如下：\n\n\t# your model's params\n\t# you don't have to initialize them\n\n\tx = tf.placeholder(tf.float32)\n\ty = tf.placeholder(tf.float32)\n\tW = tf.Variable(...)\n\tb = tf.Variable(...)\n\n\ty_ = tf.add(b, tf.matmul(x, w))\n\n\t# create the saver\n\n\tsaver = tf.train.Saver()\n\n\t# creat the session you used in the training processing\n\t# launch the model\n\n\twith tf.Session() as sess:\n\t  # Restore variables from disk.\n\t  saver.restore(sess, \"/your/path/model.ckpt\")\n\t  print(\"Model restored.\")\n\t  # Do some work with the model, such as do a prediction\n\t  pred = sess.run(y_, feed_dict={batch_x})\n\t  ...\n\n有关TensorFlow中变量的创建、存储及恢复操作，详细见[API文档](http://tensorflow.org/how_tos/variables/index.md).\n\n**Step 2: 通过tf.trainable\\_variables()得到训练参数**\n\ntf.trainable\\_variables()方法将返回模型中所有可训练的参数，详细见[API文档](https://www.tensorflow.org/versions/r0.7/api_docs/python/state_ops.html#trainable_variables)。类似于以下的变量参数不会被返回：\n\n\ttf_var = tf.Variable(0, name=\"××××××\", trainable=False)\n\n还可以通过`Variable`的`name`属性过滤出需要查看的参数，如下：\n\n\tvar = [v for v in t_vars if v.name == \"W\"]\n\n\n（不断更新中...）\n\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/problems-with-solution-in-tensorflow.html\n\n**参考资料**\n\n[Tensorflow: How to restore a previously saved model (python)](https://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python)\n\n[Get original value of Tensor in Tensorflow](https://stackoverflow.com/questions/34172622/get-original-value-of-tensor-in-tensorflow)\n\n[Get the value of some weights in a model trained by TensorFlow](https://stackoverflow.com/questions/36193553/get-the-value-of-some-weights-in-a-model-trained-by-tensorflow)\n\n\n","source":"_posts/problems-with-solution-in-tensorflow.md","raw":"title: TensorFlow中遇到的问题及解决方法\ndate: 2016-03-25 22:36:46\ntags: [TensorFlow, Machine Learning, Deep Learning, Artificial Intelligence]\ncategories: Machine Learning\n---\n\n本文记录一下自己在使用TensorFlow的过程中，遇到的较为困扰的问题及最终的解决方法。\n\n----------\n\n### Q1. 如何查看TensorFlow中Tensor, Variable, Constant的值？ ###\n\nTensorFlow中的许多方法返回的都是一个Tensor对象。在Debug的过程中，我们发现只能看到Tensor对象的一些属性信息，无法查看Tensor具体的输出值；而对于Variable和Constant，我们很容易对其进行创建操作，但是如何得到它们的值呢？\n\n假设`ts`是我们想要查看的对象(Variable / Constant / 0输入的Tensor)，运行\n\n\tts_res = sess.run(ts)\n\tprint(ts_res)\n\n其中，`sess`为之前创建或默认的`session`. 运行后将得到一个`narray`格式的`ts_res`对象，通过`print`函数我们可以很方便的查看其中的内容。\n\n但是，如果`ts`是一个有输入要求的Tensor，需要在查看其输出值前，填充(feed)输入数据。如下（假设ts只有一种输入）：\n\n\tinput = ××××××  # the input data need to feed\n\tts_res = sess.run(ts, feed_dict=input)\n\tprint(ts_res)\n\n其他要求多种输入的Tensor类似处理即可。\n\n### Q2. 模型训练完成后，如何获取模型的参数？ ###\n\n模型训练完成后，通常会将模型参数存储于/checkpoint/×××.model文件(当然文件路径和文件名都可以更改，许多基于TensorFlow的开源包习惯将模型参数存储为model或者model.ckpt文件)。那么，在模型训练完成后，如何得到这些模型参数呢？\n\n需要以下两个步骤：\n\n**Step 1: 通过tf.train.Saver()恢复模型参数** \n\n运行\n\n\tsaver = tf.train.Saver()\n\n通过`saver`的`restore()`方法可以从本地的模型文件中恢复模型参数。大致做法如下：\n\n\t# your model's params\n\t# you don't have to initialize them\n\n\tx = tf.placeholder(tf.float32)\n\ty = tf.placeholder(tf.float32)\n\tW = tf.Variable(...)\n\tb = tf.Variable(...)\n\n\ty_ = tf.add(b, tf.matmul(x, w))\n\n\t# create the saver\n\n\tsaver = tf.train.Saver()\n\n\t# creat the session you used in the training processing\n\t# launch the model\n\n\twith tf.Session() as sess:\n\t  # Restore variables from disk.\n\t  saver.restore(sess, \"/your/path/model.ckpt\")\n\t  print(\"Model restored.\")\n\t  # Do some work with the model, such as do a prediction\n\t  pred = sess.run(y_, feed_dict={batch_x})\n\t  ...\n\n有关TensorFlow中变量的创建、存储及恢复操作，详细见[API文档](http://tensorflow.org/how_tos/variables/index.md).\n\n**Step 2: 通过tf.trainable\\_variables()得到训练参数**\n\ntf.trainable\\_variables()方法将返回模型中所有可训练的参数，详细见[API文档](https://www.tensorflow.org/versions/r0.7/api_docs/python/state_ops.html#trainable_variables)。类似于以下的变量参数不会被返回：\n\n\ttf_var = tf.Variable(0, name=\"××××××\", trainable=False)\n\n还可以通过`Variable`的`name`属性过滤出需要查看的参数，如下：\n\n\tvar = [v for v in t_vars if v.name == \"W\"]\n\n\n（不断更新中...）\n\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/problems-with-solution-in-tensorflow.html\n\n**参考资料**\n\n[Tensorflow: How to restore a previously saved model (python)](https://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python)\n\n[Get original value of Tensor in Tensorflow](https://stackoverflow.com/questions/34172622/get-original-value-of-tensor-in-tensorflow)\n\n[Get the value of some weights in a model trained by TensorFlow](https://stackoverflow.com/questions/36193553/get-the-value-of-some-weights-in-a-model-trained-by-tensorflow)\n\n\n","slug":"problems-with-solution-in-tensorflow","published":1,"updated":"2016-03-26T09:28:31.290Z","_id":"cinjqrkoi0014nfq6kv333q81","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"NexT主题个性化设置","date":"2015-12-14T11:50:04.000Z","_content":"\n**提前说明**：\n\n假设网站的根目录为`D:/Hexo/`，也称为**站点目录**\n\n**站点配置文件** 是指网站目录下的`_config.yml`文件，即`D:/Hexo/_config.yml`\n\n**主题配置文件** 是指网站目录下对应的主题文件夹下的`_config.yml`文件，即`D:/Hexo/themes/next/_config.yml`.\n\n下面的功能设置完成后，记得\n\n\thexo g -d\n\n以完成网站的生成和部署。\n\n----------\n\n## 添加分类、标签云、关于等页面 ##\n\n以添加分类页面为例，\n\n在**站点目录**下，打开`git bash`，输入\n\n\thexo new page \"categories\"\n\n之后在站点目录下的source文件夹下，会新增一个`categories`的文件夹，里面有一个`index.md`文件，打开如下\n\n\ttitle: categories\n\tdate: 2015-12-04 15:37:22\n\ttype: \"categories\"\n\tcomments: false\n\t---\n\n其中，comments可以设置为false，含义是打开分类页面，评论插件不显示；如要显示则改为`true`。\n\ntags, about页面的创建类似，输入\n\n\thexo new page \"tags\"\n\thexo new page \"about\"\n\n## 添加站内搜索功能 ##\n\nNexT支持[Swiftype插件](https://swiftype.com/)以实现站内搜索功能。\n\n**Step 1**: 注册[Swiftype](https://swiftype.com/users/sign_up)\n\n**Step 2**: 创建一个新的搜索引擎 (点击`Create an engine`，按要求创建即可)\n\n**Step 3**: 点击新建的搜索引擎，按如下点击`INSTALL SEARCH`\n\n![](http://i.imgur.com/ZUvxhKH.png)\n\n然后复制下面蓝色底的字串\n\n![](http://i.imgur.com/6RfwX4n.png)\n\n**Step 4**: 编辑站点配置文件，添加如下内容\n\n\t# Swiftype Search Key\n\tswiftype_key: xxxxxxxxx(粘贴以上复制的内容)\n\n## 设置右侧栏头像 ##\n\n编辑站点配置文件，添加如下内容\n\n\tavatar: your avatar url\n\n其中，`your avatar url`可以是\n(1) 完整的互联网URL，你可以先将设置的头像图片放到图床上；\n(2) 本地地址：如`/upload/image/avatar.png` (你需要将`avatar.png`文件放在`/站点目录/source/upload/image/`里面)。\n\n## 设置favicon图标 ##\n\n**Step 1**:\n首先要有一个常见格式名(如`.jpg`, `.png`等)的图片作为备选favicon，选择一个favicon制作网站完成制作，例如[比特虫](http://www.bitbug.net/)是一个免费的在线制作ico图标网站。\n\n**Step 2**:\n将`favicon.ico`文件放在网站根目录下的source文件夹内即可。刷新网站，就可以看到效果了。\n\n## 添加社交链接 ##\n\n编辑站点配置文件，添加\n\n\tsocial:\n\t  github: https://github.com/your-user-name\n\t  twitter: https://twitter.com/your-user-name\n\t  weibo: http://weibo.com/your-user-name\n\t  douban: http://douban.com/people/your-user-name\n\t  zhihu: http://www.zhihu.com/people/your-user-name\n\t  # 等等\n\n可根据自身需要自行删减。\n\n## 添加友情链接 ##\n\n以添加github官网(`https://www.github.com`)为友情链接为例\n\n编辑站点配置文件，添加如下内容\n\n\t# title\n\tlinks_title: Links\n\t# links\n\tlinks:\n\t  Github: https://www.github.com\n\n其中，links_title为友情链接的名称。\n\n## 添加评论区 ##\n\n支持Disqus和多说两种评论样式。建议中文网站选择多说，英文网站选择`Disqus`。下面以Disqus为例说明。\n\n**Step 1**: 注册[Disqus](https://disqus.com/)\n\n**Step 2**: 登陆后进入到`Settings`，点击`Add Disqus To Site`，然后点击页面的右上角的`Install on Your Site`\n\n**Step 3**: 复制你的shortname\n\n![](http://i.imgur.com/1LZfdm5.png)\n\n**Step 4**: 编辑站点配置文件，添加\n\n\tdisqus_shortname: your disqus shortname\n\n这样你的所有文章及页面下面，会自动加载Disqus的评论插件。如果在分类、标签云等页面，不想显示评论区，可以打开这个page文件夹下的md文件，添加\n\n\tcomments: false\n\n## 首页文章以摘要形式显示 ##\n\n最简单的方式是：打开**主题配置文件**，找到如下位置，修改\n\n\tauto_excerpt:\n\t  enable: true\n\t  length: 150\n\n其中`length`代表显示摘要的截取字符长度。\n\n## 设置首页文章显示篇数 ##\n\n**Step 1**: 安装相关插件\n\n输入如下命令\n\n\tnpm install --save hexo-generator-index\n\tnpm install --save hexo-generator-archive\n\tnpm install --save hexo-generator-tag\n\n**Step 2**: \n\n安装完插件后，在站点配置文件中，添加如下内容\n\n\tindex_generator:\n\t  per_page: 5\n\t\n\tarchive_generator:\n\t  per_page: 20\n\t  yearly: true\n\t  monthly: true\n\t\n\ttag_generator:\n\t  per_page: 10\n\n其中`per_page`字段是你希望设定的显示篇数。`index`, `archive`及`tag`开头分表代表主页，归档页面和标签页面。\n\n## 设置404公益页面 ##\n\n在**站点目录**的source文件夹下，新建`404.html`文件，将下面的代码复制进去保存即可。\n\n\t<!DOCTYPE HTML>\n\t<html>\n\t<head>\n\t\t<title>404 - arao'blog</title>\n\t\t<meta name=\"description\" content=\"404错误，页面不存在！\">\n\t\t<meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n\t\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n\t\t<meta name=\"robots\" content=\"all\" />\n\t\t<meta name=\"robots\" content=\"index,follow\"/>\n\t</head>\n\t<body>\n\t\t<script type=\"text/javascript\" src=\"http://qzonestyle.gtimg.cn/qzone_v6/lostchild/search_children.js\" charset=\"utf-8\"></script>\n\t</body>\n\t</html>\n\n显示效果如下\n\n![](http://i.imgur.com/n5wN34M.png)\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/next-theme-personal-settings.html\n\n**参考资料**\n\n[NexT官方帮助文档](http://theme-next.iissnan.com/)","source":"_posts/next-theme-personal-settings.md","raw":"title: NexT主题个性化设置\ndate: 2015-12-14 19:50:04\ntags: [Hexo, Next]\ncategories: Hexo\n---\n\n**提前说明**：\n\n假设网站的根目录为`D:/Hexo/`，也称为**站点目录**\n\n**站点配置文件** 是指网站目录下的`_config.yml`文件，即`D:/Hexo/_config.yml`\n\n**主题配置文件** 是指网站目录下对应的主题文件夹下的`_config.yml`文件，即`D:/Hexo/themes/next/_config.yml`.\n\n下面的功能设置完成后，记得\n\n\thexo g -d\n\n以完成网站的生成和部署。\n\n----------\n\n## 添加分类、标签云、关于等页面 ##\n\n以添加分类页面为例，\n\n在**站点目录**下，打开`git bash`，输入\n\n\thexo new page \"categories\"\n\n之后在站点目录下的source文件夹下，会新增一个`categories`的文件夹，里面有一个`index.md`文件，打开如下\n\n\ttitle: categories\n\tdate: 2015-12-04 15:37:22\n\ttype: \"categories\"\n\tcomments: false\n\t---\n\n其中，comments可以设置为false，含义是打开分类页面，评论插件不显示；如要显示则改为`true`。\n\ntags, about页面的创建类似，输入\n\n\thexo new page \"tags\"\n\thexo new page \"about\"\n\n## 添加站内搜索功能 ##\n\nNexT支持[Swiftype插件](https://swiftype.com/)以实现站内搜索功能。\n\n**Step 1**: 注册[Swiftype](https://swiftype.com/users/sign_up)\n\n**Step 2**: 创建一个新的搜索引擎 (点击`Create an engine`，按要求创建即可)\n\n**Step 3**: 点击新建的搜索引擎，按如下点击`INSTALL SEARCH`\n\n![](http://i.imgur.com/ZUvxhKH.png)\n\n然后复制下面蓝色底的字串\n\n![](http://i.imgur.com/6RfwX4n.png)\n\n**Step 4**: 编辑站点配置文件，添加如下内容\n\n\t# Swiftype Search Key\n\tswiftype_key: xxxxxxxxx(粘贴以上复制的内容)\n\n## 设置右侧栏头像 ##\n\n编辑站点配置文件，添加如下内容\n\n\tavatar: your avatar url\n\n其中，`your avatar url`可以是\n(1) 完整的互联网URL，你可以先将设置的头像图片放到图床上；\n(2) 本地地址：如`/upload/image/avatar.png` (你需要将`avatar.png`文件放在`/站点目录/source/upload/image/`里面)。\n\n## 设置favicon图标 ##\n\n**Step 1**:\n首先要有一个常见格式名(如`.jpg`, `.png`等)的图片作为备选favicon，选择一个favicon制作网站完成制作，例如[比特虫](http://www.bitbug.net/)是一个免费的在线制作ico图标网站。\n\n**Step 2**:\n将`favicon.ico`文件放在网站根目录下的source文件夹内即可。刷新网站，就可以看到效果了。\n\n## 添加社交链接 ##\n\n编辑站点配置文件，添加\n\n\tsocial:\n\t  github: https://github.com/your-user-name\n\t  twitter: https://twitter.com/your-user-name\n\t  weibo: http://weibo.com/your-user-name\n\t  douban: http://douban.com/people/your-user-name\n\t  zhihu: http://www.zhihu.com/people/your-user-name\n\t  # 等等\n\n可根据自身需要自行删减。\n\n## 添加友情链接 ##\n\n以添加github官网(`https://www.github.com`)为友情链接为例\n\n编辑站点配置文件，添加如下内容\n\n\t# title\n\tlinks_title: Links\n\t# links\n\tlinks:\n\t  Github: https://www.github.com\n\n其中，links_title为友情链接的名称。\n\n## 添加评论区 ##\n\n支持Disqus和多说两种评论样式。建议中文网站选择多说，英文网站选择`Disqus`。下面以Disqus为例说明。\n\n**Step 1**: 注册[Disqus](https://disqus.com/)\n\n**Step 2**: 登陆后进入到`Settings`，点击`Add Disqus To Site`，然后点击页面的右上角的`Install on Your Site`\n\n**Step 3**: 复制你的shortname\n\n![](http://i.imgur.com/1LZfdm5.png)\n\n**Step 4**: 编辑站点配置文件，添加\n\n\tdisqus_shortname: your disqus shortname\n\n这样你的所有文章及页面下面，会自动加载Disqus的评论插件。如果在分类、标签云等页面，不想显示评论区，可以打开这个page文件夹下的md文件，添加\n\n\tcomments: false\n\n## 首页文章以摘要形式显示 ##\n\n最简单的方式是：打开**主题配置文件**，找到如下位置，修改\n\n\tauto_excerpt:\n\t  enable: true\n\t  length: 150\n\n其中`length`代表显示摘要的截取字符长度。\n\n## 设置首页文章显示篇数 ##\n\n**Step 1**: 安装相关插件\n\n输入如下命令\n\n\tnpm install --save hexo-generator-index\n\tnpm install --save hexo-generator-archive\n\tnpm install --save hexo-generator-tag\n\n**Step 2**: \n\n安装完插件后，在站点配置文件中，添加如下内容\n\n\tindex_generator:\n\t  per_page: 5\n\t\n\tarchive_generator:\n\t  per_page: 20\n\t  yearly: true\n\t  monthly: true\n\t\n\ttag_generator:\n\t  per_page: 10\n\n其中`per_page`字段是你希望设定的显示篇数。`index`, `archive`及`tag`开头分表代表主页，归档页面和标签页面。\n\n## 设置404公益页面 ##\n\n在**站点目录**的source文件夹下，新建`404.html`文件，将下面的代码复制进去保存即可。\n\n\t<!DOCTYPE HTML>\n\t<html>\n\t<head>\n\t\t<title>404 - arao'blog</title>\n\t\t<meta name=\"description\" content=\"404错误，页面不存在！\">\n\t\t<meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/>\n\t\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" />\n\t\t<meta name=\"robots\" content=\"all\" />\n\t\t<meta name=\"robots\" content=\"index,follow\"/>\n\t</head>\n\t<body>\n\t\t<script type=\"text/javascript\" src=\"http://qzonestyle.gtimg.cn/qzone_v6/lostchild/search_children.js\" charset=\"utf-8\"></script>\n\t</body>\n\t</html>\n\n显示效果如下\n\n![](http://i.imgur.com/n5wN34M.png)\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/next-theme-personal-settings.html\n\n**参考资料**\n\n[NexT官方帮助文档](http://theme-next.iissnan.com/)","slug":"next-theme-personal-settings","published":1,"updated":"2016-01-22T15:11:14.081Z","_id":"cinjqrkon001anfq629l03iq3","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"Win10下网络连接问题及解决方案","date":"2016-01-28T09:54:15.000Z","_content":"\n回家后，发现笔记本能连上家里的wifi，但是就是不能上网。网络诊断问题提示是【**此计算机上缺少一个或多个网络协议**】。尝试了多种方法一直解决不了，经过一番折腾后终于成功，特此记录一下，以供后人参考。\n\n**操作系统环境**：Windows 10\n\n**网络诊断错误**：此计算机缺少一个或多个网络协议\n\n----------\n\n## 可能的解决方法：开启特定的网络服务项 ##\n\n网上大多都是这种方法，如下：\n\n按`windows+R`键，在运行窗口中输入`services.msc`，检查以下服务是否正常开启：\n\n\tTelephony;\n\tRemote Access Connection Manager;\n\tRemote Access Auto Connection Manager;\n\n找到上述服务中手动开启的项，右键`属性`；确认修改所选服务的启动类型为`自动`，如果服务状态为停止，点击`启动`来启动服务。\n\n但是，这个方法并没有解决问题。本人尝试后失败。\n\n## 可行的解决方法： 卸载目前的驱动程序##\n\n在`开始`处，点击`右键`，选择`网络连接`。\n\n找到连接上的无线网络，点击`右键`，选择`状态`,点开应该如下图：\n\n![](http://i.imgur.com/jFeBr1w.png)\n\n点击图中的`属性`，如下图\n\n![](http://i.imgur.com/Excc8Wr.png)\n\n点击`配置`，选择`驱动程序 > 卸载`，如下图\n\n![](http://i.imgur.com/leNeCOP.png)\n\n勾选卸载相应的驱动程序，完成卸载。重启系统，然后重连wifi即可。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/network-connection-problems-in-win10.html\n\n\n\n\n","source":"_posts/network-connection-problems-in-win10.md","raw":"title: Win10下网络连接问题及解决方案\ndate: 2016-01-28 17:54:15\ntags: [Network, Windows, Win10]\ncategories: Network\n---\n\n回家后，发现笔记本能连上家里的wifi，但是就是不能上网。网络诊断问题提示是【**此计算机上缺少一个或多个网络协议**】。尝试了多种方法一直解决不了，经过一番折腾后终于成功，特此记录一下，以供后人参考。\n\n**操作系统环境**：Windows 10\n\n**网络诊断错误**：此计算机缺少一个或多个网络协议\n\n----------\n\n## 可能的解决方法：开启特定的网络服务项 ##\n\n网上大多都是这种方法，如下：\n\n按`windows+R`键，在运行窗口中输入`services.msc`，检查以下服务是否正常开启：\n\n\tTelephony;\n\tRemote Access Connection Manager;\n\tRemote Access Auto Connection Manager;\n\n找到上述服务中手动开启的项，右键`属性`；确认修改所选服务的启动类型为`自动`，如果服务状态为停止，点击`启动`来启动服务。\n\n但是，这个方法并没有解决问题。本人尝试后失败。\n\n## 可行的解决方法： 卸载目前的驱动程序##\n\n在`开始`处，点击`右键`，选择`网络连接`。\n\n找到连接上的无线网络，点击`右键`，选择`状态`,点开应该如下图：\n\n![](http://i.imgur.com/jFeBr1w.png)\n\n点击图中的`属性`，如下图\n\n![](http://i.imgur.com/Excc8Wr.png)\n\n点击`配置`，选择`驱动程序 > 卸载`，如下图\n\n![](http://i.imgur.com/leNeCOP.png)\n\n勾选卸载相应的驱动程序，完成卸载。重启系统，然后重连wifi即可。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/network-connection-problems-in-win10.html\n\n\n\n\n","slug":"network-connection-problems-in-win10","published":1,"updated":"2016-02-26T10:49:35.539Z","_id":"cinjqrkos001hnfq6pvaxjriz","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"markdown写作中的常见问题","date":"2016-01-22T13:44:33.000Z","_content":"\n本文记录markdown写作过程中所遇到的问题及相应的解决方法，以供参考。\n\n----------\n\n\n## Q1: 代码中出现{% raw %}{% 和 %}{% endraw %}所包围的语句 ##\n\n如果代码中出现了类似于{% raw %}{%××××××%}{% endraw %}格式的语句，需要在这些`语句块的首尾`加上\n\n```\n{% raw %}\n```\n和\n```\n{% endraw %}\n```\n\n以保证显示原始的语句。\n\n示例如下：\n\n![](http://i.imgur.com/aYitATq.png)\n\n显示效果如下：\n\n\t{% raw %}\n\t{% if theme.leancloud_visitors.enable %}\n\t{% include '_scripts/lean-analytics.swig' %}\n\t{% endif %}\n\t{% endraw %}\n\n## Q2: 如何显示原始的html代码 ##\n\n在html代码块的上下均加上`三个连续的反引号`。\n\n示例如下：\n\n![](http://i.imgur.com/B1XqXXr.png)\n\n显示效果如下：\n\n```\n\t{% if theme.leancloud_visitors.enable %}\n\t{% include '_scripts/lean-analytics.swig' %}\n\t{% endif %}\n```\n\n## Q3: 怎样给字体阴影的效果 ##\n\n例如`这样的阴影效果`，只需要在内容的前后加上一个反引号，如下图：\n\n![](http://i.imgur.com/fr7Fapa.png)\n\n## Q4: 如何显示公式中的花括号{} ##\n\nmarkdown中正常文本中使用`\\`对`{}`进行转义即可；而公式中的`{}`即使这样转义也是不会显示的，正确做法是使用`\\lbrace \\rbrace`来表示左右花括号。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/markdown-common-problems.html\n\n\n**参考资料**\n\n[Markdown 语法说明 (简体中文版)](http://wowubuntu.com/markdown/)\n\n[issue#587: Markdown代码块中的Markdown语法](https://github.com/hexojs/hexo/issues/587)\n\n[V2EX: markdown反引号内怎么转义反引号](https://www.v2ex.com/t/57233)\n\n[Markdown中写数学公式](http://jzqt.github.io/2015/06/30/Markdown%E4%B8%AD%E5%86%99%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/)","source":"_posts/markdown-common-problems.md","raw":"title: markdown写作中的常见问题\ndate: 2016-01-22 21:44:33\ntags: [Markdown]\ncategories: Markdown\n---\n\n本文记录markdown写作过程中所遇到的问题及相应的解决方法，以供参考。\n\n----------\n\n\n## Q1: 代码中出现{% raw %}{% 和 %}{% endraw %}所包围的语句 ##\n\n如果代码中出现了类似于{% raw %}{%××××××%}{% endraw %}格式的语句，需要在这些`语句块的首尾`加上\n\n```\n{% raw %}\n```\n和\n```\n{% endraw %}\n```\n\n以保证显示原始的语句。\n\n示例如下：\n\n![](http://i.imgur.com/aYitATq.png)\n\n显示效果如下：\n\n\t{% raw %}\n\t{% if theme.leancloud_visitors.enable %}\n\t{% include '_scripts/lean-analytics.swig' %}\n\t{% endif %}\n\t{% endraw %}\n\n## Q2: 如何显示原始的html代码 ##\n\n在html代码块的上下均加上`三个连续的反引号`。\n\n示例如下：\n\n![](http://i.imgur.com/B1XqXXr.png)\n\n显示效果如下：\n\n```\n\t{% if theme.leancloud_visitors.enable %}\n\t{% include '_scripts/lean-analytics.swig' %}\n\t{% endif %}\n```\n\n## Q3: 怎样给字体阴影的效果 ##\n\n例如`这样的阴影效果`，只需要在内容的前后加上一个反引号，如下图：\n\n![](http://i.imgur.com/fr7Fapa.png)\n\n## Q4: 如何显示公式中的花括号{} ##\n\nmarkdown中正常文本中使用`\\`对`{}`进行转义即可；而公式中的`{}`即使这样转义也是不会显示的，正确做法是使用`\\lbrace \\rbrace`来表示左右花括号。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/markdown-common-problems.html\n\n\n**参考资料**\n\n[Markdown 语法说明 (简体中文版)](http://wowubuntu.com/markdown/)\n\n[issue#587: Markdown代码块中的Markdown语法](https://github.com/hexojs/hexo/issues/587)\n\n[V2EX: markdown反引号内怎么转义反引号](https://www.v2ex.com/t/57233)\n\n[Markdown中写数学公式](http://jzqt.github.io/2015/06/30/Markdown%E4%B8%AD%E5%86%99%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/)","slug":"markdown-common-problems","published":1,"updated":"2016-03-31T07:43:01.321Z","_id":"cinjqrkoy001qnfq659wi68t2","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"词向量表示技术(Word Representation)介绍","date":"2016-03-09T01:56:08.000Z","_content":"\n先刨个坑，以后来填:)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/introduction-to-word-representation.html\n\n**参考资料**\n\n[Deep Learning in NLP （一）词向量和语言模型](http://licstar.net/archives/328)\n\n[博士论文《基于神经网络的词和文档语义向量表示方法研究》](http://licstar.net/archives/687)\n\n[《How to Generate a Good Word Embedding?》导读](http://licstar.net/archives/620)\n\n[Deep Learning实战之word2vec](http://techblog.youdao.com/?p=915)","source":"_posts/introduction-to-word-representation.md","raw":"title: 词向量表示技术(Word Representation)介绍\ndate: 2016-03-09 09:56:08\ntags: [Machine Learning, Deep Learning, Word2Vector, Word Embedding]\ncategories: Machine Learning\n---\n\n先刨个坑，以后来填:)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/introduction-to-word-representation.html\n\n**参考资料**\n\n[Deep Learning in NLP （一）词向量和语言模型](http://licstar.net/archives/328)\n\n[博士论文《基于神经网络的词和文档语义向量表示方法研究》](http://licstar.net/archives/687)\n\n[《How to Generate a Good Word Embedding?》导读](http://licstar.net/archives/620)\n\n[Deep Learning实战之word2vec](http://techblog.youdao.com/?p=915)","slug":"introduction-to-word-representation","published":1,"updated":"2016-04-20T06:45:54.834Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinjqrkp3001vnfq6jno1547e","sticky":0},{"title":"如何在markdown中插入公式","date":"2016-01-14T12:57:19.000Z","_content":"\n## **MathJax插件** ##\n\n著名的[Stackoverflow](http://stackoverflow.com/)网站上的漂亮公式，就是使用了MathJax插件的效果。添加MathJax插件也非常简单，只需要在markdown文件中，添加`MathJax CDN`，如下：\n\n\t<script type=\"text/javascript\"\n\t   src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n\t</script>\n\n就可以在md文件中插入Tex格式的公式了。\n\n`行间公式`的形式为\n\n\t$$ 此处插入公式 $$\n\n而`行内公式`的形式为\n\n\t\\\\( 此处插入公式 \\\\)\n\n## **在MarkdownPad 2中编辑公式** ##\n\n之前的博文有推荐[Markdown Pad 2](http://markdownpad.com/)作为Window下的Markdown编辑器。如果你是使用该软件作为markdown的编辑器，你只需要在软件的`Tools-> Options-> Advanced-> HTML Head Editor`中添加上述的`MathJax CDN`即可。\n\n这样你就不必每次都在md文件中重复添加了。\n\n## **好用的Tex公式生成器** ##\n\n推荐一个在线手写公式转Tex格式的利器：[Web Equation](https://webdemo.myscript.com/#/demo/equation)。通过手写公式，即可得到公式所对应的Tex格式，非常好用。\n\n## **示例** ##\n\n举个栗子。在`Markdown Pad 2`中新建文件，添加如下内容：\n\n\t最后，我们在一个图片类别的evidence中加入偏置(bias)，加入偏置的目的是加入一些与输入独立无关的信息。所以图片类别的evidence为\n\t\n\t$$ evidence\\_{i}=\\sum \\_{j}W\\_{ij}x\\_{j}+b\\_{i} $$\n\t\n\t其中，\\\\( W\\_i \\\\) 和 \\\\( b\\_i \\\\) 分别为类别 \\\\( i \\\\) 的权值和偏置。\n\n（**注意**：markdown文件中的`_`前需要加上`\\`转移符。）\n\n最终效果如下（在Markdown Pad 2编辑器进行预览，快捷键为`F6`）：\n\n![](http://i.imgur.com/dCW2j68.png)\n\n## **Hexo中显示数学公式** ##\n\n值得注意的是，原生的Hexo并不支持数学公式的显示。所以，如果你仅仅完成了以上步骤，在`hexo g -d`之后，你会发现公式的效果并没有被渲染出来。\n\n### 安装hexo-math插件 ###\n\n在网站根目录下，打开`git bash`，输入\n\n\tnpm install hexo-math --save\n\n然后，在根目录下的`_config.yml`文件中添加\n\n\tplugins: \n\t  hexo-math\n\n之后重新生成和部署网站即可。\n\n\n----------\n\n\n**参考资料**：\n\n[MathJax with Markdownpad 2](http://pencilandengine.com/2013/08/27/mathjax-with-markdownpad-2/)\n\n[Hexo上使用MathJax来实现数学公式的表达](http://hijiangtao.github.io/2014/09/08/MathJaxinHexo/)\n","source":"_posts/how-to-insert-equations-in-markdown.md","raw":"title: 如何在markdown中插入公式\ndate: 2016-01-14 20:57:19\ntags: [Markdown, Equation, MathJax, MarkdownPad 2]\ncategories: Markdown\n---\n\n## **MathJax插件** ##\n\n著名的[Stackoverflow](http://stackoverflow.com/)网站上的漂亮公式，就是使用了MathJax插件的效果。添加MathJax插件也非常简单，只需要在markdown文件中，添加`MathJax CDN`，如下：\n\n\t<script type=\"text/javascript\"\n\t   src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n\t</script>\n\n就可以在md文件中插入Tex格式的公式了。\n\n`行间公式`的形式为\n\n\t$$ 此处插入公式 $$\n\n而`行内公式`的形式为\n\n\t\\\\( 此处插入公式 \\\\)\n\n## **在MarkdownPad 2中编辑公式** ##\n\n之前的博文有推荐[Markdown Pad 2](http://markdownpad.com/)作为Window下的Markdown编辑器。如果你是使用该软件作为markdown的编辑器，你只需要在软件的`Tools-> Options-> Advanced-> HTML Head Editor`中添加上述的`MathJax CDN`即可。\n\n这样你就不必每次都在md文件中重复添加了。\n\n## **好用的Tex公式生成器** ##\n\n推荐一个在线手写公式转Tex格式的利器：[Web Equation](https://webdemo.myscript.com/#/demo/equation)。通过手写公式，即可得到公式所对应的Tex格式，非常好用。\n\n## **示例** ##\n\n举个栗子。在`Markdown Pad 2`中新建文件，添加如下内容：\n\n\t最后，我们在一个图片类别的evidence中加入偏置(bias)，加入偏置的目的是加入一些与输入独立无关的信息。所以图片类别的evidence为\n\t\n\t$$ evidence\\_{i}=\\sum \\_{j}W\\_{ij}x\\_{j}+b\\_{i} $$\n\t\n\t其中，\\\\( W\\_i \\\\) 和 \\\\( b\\_i \\\\) 分别为类别 \\\\( i \\\\) 的权值和偏置。\n\n（**注意**：markdown文件中的`_`前需要加上`\\`转移符。）\n\n最终效果如下（在Markdown Pad 2编辑器进行预览，快捷键为`F6`）：\n\n![](http://i.imgur.com/dCW2j68.png)\n\n## **Hexo中显示数学公式** ##\n\n值得注意的是，原生的Hexo并不支持数学公式的显示。所以，如果你仅仅完成了以上步骤，在`hexo g -d`之后，你会发现公式的效果并没有被渲染出来。\n\n### 安装hexo-math插件 ###\n\n在网站根目录下，打开`git bash`，输入\n\n\tnpm install hexo-math --save\n\n然后，在根目录下的`_config.yml`文件中添加\n\n\tplugins: \n\t  hexo-math\n\n之后重新生成和部署网站即可。\n\n\n----------\n\n\n**参考资料**：\n\n[MathJax with Markdownpad 2](http://pencilandengine.com/2013/08/27/mathjax-with-markdownpad-2/)\n\n[Hexo上使用MathJax来实现数学公式的表达](http://hijiangtao.github.io/2014/09/08/MathJaxinHexo/)\n","slug":"how-to-insert-equations-in-markdown","published":1,"updated":"2016-03-03T06:52:49.879Z","_id":"cinjqrkp70023nfq6j880739p","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"Hexo网站优化之SEO","date":"2015-12-17T02:04:18.000Z","_content":"\nSEO (Search Engine Optimization)，即搜索引擎优化。对网站做SEO优化，有利于提高搜索引擎的收录速度及网页排名。下面讲解一些简单的SEO优化方法，主要针对Hexo网站。\n\n----------\n\n## SEO优化之title ##\n\n编辑站点目录下的`themes/layout/index.swig`文件，\n\n将下面的代码\n\n```\n\t{% block title %} {{ config.title }} {% endlock %}\n```\n\n改成\n\n```\n\t{% block title %} {{ config.title }} - {{ theme.description }} {% endlock %}\n```\n\n这时将网站的描述及关键词加入了网站的`title`中，更有利于详细地描述网站。\n\n## 添加robots.txt ##\n\nrobots.txt是一种存放于网站根目录下的ASCII编码的文本文件，它的作用是告诉搜索引擎此网站中哪些内容是可以被爬取的，哪些是禁止爬取的。robots.txt应该放在站点目录下的source文件中，网站生成后在网站的根目录(`站点目录/public/`)下。\n\n我的robots.txt文件内容如下\n\n\tUser-agent: *\n\tAllow: /\n\tAllow: /archives/\n\tAllow: /categories/\n\tAllow: /about/\n\t\n\tDisallow: /vendors/\n\tDisallow: /js/\n\tDisallow: /css/\n\tDisallow: /fonts/\n\tDisallow: /vendors/\n\tDisallow: /fancybox/\n\t\n## 添加sitemap ##\n\nSitemap即网站地图，它的作用在于便于搜索引擎更加智能地抓取网站。最简单和常见的sitemap形式，是XML文件，在其中列出网站中的网址以及关于每个网址的其他元数据（上次更新时间、更新的频率及相对其他网址重要程度等）。\n\n**Step 1**: 安装sitemap生成插件\n\n\tnpm install hexo-generator-sitemap --save\n\tnpm install hexo-generator-baidu-sitemap --save\n\n**Step 2**: 编辑站点目录下的_config.yml，添加\n\n\t# hexo sitemap网站地图\n\tsitemap:\n\tpath: sitemap.xml\n\tbaidusitemap:\n\tpath: baidusitemap.xml\n\n**Step 3**: 在robots.txt文件中添加\n\n\tSitemap: http://www.jeyzhang.com/sitemap.xml\n\tSitemap: http://www.jeyzhang.com/baidusitemap.xml\n\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/hexo-website-seo.html","source":"_posts/hexo-website-seo.md","raw":"title: Hexo网站优化之SEO\ndate: 2015-12-17 10:04:18\ntags: [Hexo, SEO, Web]\ncategories: Hexo\n---\n\nSEO (Search Engine Optimization)，即搜索引擎优化。对网站做SEO优化，有利于提高搜索引擎的收录速度及网页排名。下面讲解一些简单的SEO优化方法，主要针对Hexo网站。\n\n----------\n\n## SEO优化之title ##\n\n编辑站点目录下的`themes/layout/index.swig`文件，\n\n将下面的代码\n\n```\n\t{% block title %} {{ config.title }} {% endlock %}\n```\n\n改成\n\n```\n\t{% block title %} {{ config.title }} - {{ theme.description }} {% endlock %}\n```\n\n这时将网站的描述及关键词加入了网站的`title`中，更有利于详细地描述网站。\n\n## 添加robots.txt ##\n\nrobots.txt是一种存放于网站根目录下的ASCII编码的文本文件，它的作用是告诉搜索引擎此网站中哪些内容是可以被爬取的，哪些是禁止爬取的。robots.txt应该放在站点目录下的source文件中，网站生成后在网站的根目录(`站点目录/public/`)下。\n\n我的robots.txt文件内容如下\n\n\tUser-agent: *\n\tAllow: /\n\tAllow: /archives/\n\tAllow: /categories/\n\tAllow: /about/\n\t\n\tDisallow: /vendors/\n\tDisallow: /js/\n\tDisallow: /css/\n\tDisallow: /fonts/\n\tDisallow: /vendors/\n\tDisallow: /fancybox/\n\t\n## 添加sitemap ##\n\nSitemap即网站地图，它的作用在于便于搜索引擎更加智能地抓取网站。最简单和常见的sitemap形式，是XML文件，在其中列出网站中的网址以及关于每个网址的其他元数据（上次更新时间、更新的频率及相对其他网址重要程度等）。\n\n**Step 1**: 安装sitemap生成插件\n\n\tnpm install hexo-generator-sitemap --save\n\tnpm install hexo-generator-baidu-sitemap --save\n\n**Step 2**: 编辑站点目录下的_config.yml，添加\n\n\t# hexo sitemap网站地图\n\tsitemap:\n\tpath: sitemap.xml\n\tbaidusitemap:\n\tpath: baidusitemap.xml\n\n**Step 3**: 在robots.txt文件中添加\n\n\tSitemap: http://www.jeyzhang.com/sitemap.xml\n\tSitemap: http://www.jeyzhang.com/baidusitemap.xml\n\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/hexo-website-seo.html","slug":"hexo-website-seo","published":1,"updated":"2016-01-24T13:50:41.931Z","_id":"cinjqrkph002cnfq631h0zs2o","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"Hexo的NexT主题个性化：添加文章阅读量","date":"2016-01-22T01:28:40.000Z","_content":"\n关于Hexo的文章阅读量设置问题，大多数人都是使用[不蒜子](http://service.ibruce.info/)的代码实现。但是这个方法仅局限于在文章页面显示阅读数，首页是不显示的。\n\n下面介绍如何在首页及文章页面都显示`文章的阅读量`，显示效果如下：\n\n![](http://i.imgur.com/AMdIdpW.png)\n\n----------\n\n## **配置[LeanCloud](https://leancloud.cn/)** ##\n\n### 注册 ###\n\n打开LeanCloud官网，进入[注册页面](https://leancloud.cn/login.html#/signup)注册。完成邮箱激活后，点击头像，进入`控制台`页面，如下：\n\n![](http://i.imgur.com/WyRLYr3.png)\n\n### 创建新应用 ###\n\n创建一个新应用(类型为`JavaScript SDK`)，点击应用进入；\n\n创建名称为`Counter`的Class\n\n![](http://i.imgur.com/5VUiBAy.png)\n\n![](http://i.imgur.com/C8LWKT2.png)\n\n### 修改配置文件 ###\n\n编辑网站根目录下的`_config.yml`文件，添加如下：\n\n\t# add post views\n\tleancloud_visitors:\n\t  enable: true\n\t  app_id: **你的app_id**\n\t  app_key: **你的app_key**\n\n其中，app_id和app_key在你所创建的应用的`设置->应用Key`中。\n\n### Web安全性 ###\n\n为了保证应用的统计计数功能仅应用于自己的博客系统，你可以在`应用->设置->安全中心`的`Web安全域名`中加入自己的博客域名，以保证数据的调用安全。\n\n## **修改NexT主题文件** ##\n\n### 添加lean-analytics.swig文件 ###\n\n在主题目录下的`\\layout\\_scripts`路径下，新建一个名称为`lean-analytics.swig`的文件，并添加如下内容：\n\n```\n\t<!-- custom analytics part create by xiamo -->\n\t<script src=\"https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js\"></script>\n\t<script>AV.initialize(\"{{theme.leancloud_visitors.app_id}}\", \"{{theme.leancloud_visitors.app_key}}\");</script>\n\t<script>\n\tfunction showTime(Counter) {\n\t\tvar query = new AV.Query(Counter);\n\t\t$(\".leancloud_visitors\").each(function() {\n\t\t\tvar url = $(this).attr(\"id\").trim();\n\t\t\tquery.equalTo(\"url\", url);\n\t\t\tquery.find({\n\t\t\t\tsuccess: function(results) {\n\t\t\t\t\tif (results.length == 0) {\n\t\t\t\t\t\tvar content = '0 ' + $(document.getElementById(url)).text();\n\t\t\t\t\t\t$(document.getElementById(url)).text(content);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tfor (var i = 0; i < results.length; i++) {\n\t\t\t\t\t\tvar object = results[i];\n\t\t\t\t\t\tvar content = object.get('time') + ' ' + $(document.getElementById(url)).text();\n\t\t\t\t\t\t$(document.getElementById(url)).text(content);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\terror: function(object, error) {\n\t\t\t\t\tconsole.log(\"Error: \" + error.code + \" \" + error.message);\n\t\t\t\t}\n\t\t\t});\n\t\n\t\t});\n\t}\n\t\n\tfunction addCount(Counter) {\n\t\tvar Counter = AV.Object.extend(\"Counter\");\n\t\turl = $(\".leancloud_visitors\").attr('id').trim();\n\t\ttitle = $(\".leancloud_visitors\").attr('data-flag-title').trim();\n\t\tvar query = new AV.Query(Counter);\n\t\tquery.equalTo(\"url\", url);\n\t\tquery.find({\n\t\t\tsuccess: function(results) {\n\t\t\t\tif (results.length > 0) {\n\t\t\t\t\tvar counter = results[0];\n\t\t\t\t\tcounter.fetchWhenSave(true);\n\t\t\t\t\tcounter.increment(\"time\");\n\t\t\t\t\tcounter.save(null, {\n\t\t\t\t\t\tsuccess: function(counter) {\n\t\t\t\t\t\t\tvar content =  counter.get('time') + ' ' + $(document.getElementById(url)).text();\n\t\t\t\t\t\t\t$(document.getElementById(url)).text(content);\n\t\t\t\t\t\t},\n\t\t\t\t\t\terror: function(counter, error) {\n\t\t\t\t\t\t\tconsole.log('Failed to save Visitor num, with error message: ' + error.message);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t} else {\n\t\t\t\t\tvar newcounter = new Counter();\n\t\t\t\t\tnewcounter.set(\"title\", title);\n\t\t\t\t\tnewcounter.set(\"url\", url);\n\t\t\t\t\tnewcounter.set(\"time\", 1);\n\t\t\t\t\tnewcounter.save(null, {\n\t\t\t\t\t\tsuccess: function(newcounter) {\n\t\t\t\t\t\t    console.log(\"newcounter.get('time')=\"+newcounter.get('time'));\n\t\t\t\t\t\t\tvar content = newcounter.get('time') + ' ' + $(document.getElementById(url)).text();\n\t\t\t\t\t\t\t$(document.getElementById(url)).text(content);\n\t\t\t\t\t\t},\n\t\t\t\t\t\terror: function(newcounter, error) {\n\t\t\t\t\t\t\tconsole.log('Failed to create');\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t},\n\t\t\terror: function(error) {\n\t\t\t\tconsole.log('Error:' + error.code + \" \" + error.message);\n\t\t\t}\n\t\t});\n\t}\n\t$(function() {\n\t\tvar Counter = AV.Object.extend(\"Counter\");\n\t\tif ($('.leancloud_visitors').length == 1) {\n\t\t\taddCount(Counter);\n\t\t} else if ($('.post-title-link').length > 1) {\n\t\t\tshowTime(Counter);\n\t\t}\n\t}); \n\t</script>\n```\n\n其中，控制显示的格式的主要为`content`变量，按自己的需求相应修改即可。\n\n### 修改post.swig文件 ###\n\n在主题的`layout\\_macro`路径下，编辑`post.swig`文件，找到相应的插入位置（大概在98行左右）：\n\n![](http://i.imgur.com/l21gZ2f.png)\n\n插入如下代码\n\n```\n\t\t  {% if theme.leancloud_visitors.enable %}\n\t\t\t &nbsp; | &nbsp;\n\t\t\t <span id=\"{{ url_for(post.path) }}\"class=\"leancloud_visitors\" data-flag-title=\"{{ post.title }}\">\n             &nbsp;{{__('post.visitors')}}\n            </span>\n\t\t  {% endif %}\n```\n### 修改layout.swig文件 ###\n\n在主题目录下的`layout`目录下，编辑`_layout.swig`文件，在`</body>`的上方（大概在70行左右）插入如下代码：\n\n```\n\t{% if theme.leancloud_visitors.enable %}\n\t{% include '_scripts/lean-analytics.swig' %}\n\t{% endif %}\n```\n\n### 修改语言配置文件 ###\n\n如果你的网站使用的是英语，则只需要编辑主题目录下的`languages\\en.yml`文件，增加`post`字段如下：\n\n\tpost:\n\t  sticky: Sticky\n\t  posted: Posted on\n\t  visitors: Views // 增加的字段\n\t  ...\n\n如果网站使用的是中文，则编辑`languages\\zh-Hans.yml`文件，相应的增加\n\n\tpost:\n\t  posted: 发表于\n\t  visitors: 阅读次数\n\t  ...\n\n其他语言与之类似，将`visitors`设置成你希望翻译的字段。\n\n**最后，重新生成并部署你的网站即可。**\n\n## **增加网站的浏览次数与访客数量统计功能** ##\n\n网站的浏览次数，即`pv`；网站的访客数为`uv`。`pv`的计算方式是，单个用户连续点击n篇文章，记录n次访问量；`uv`的计算方式是，单个用户连续点击n篇文章，只记录1次访客数。你可以根据需要添加相应的统计功能。\n\n## 安装`busuanzi.js`脚本 ##\n\n如果你使用的是NexT主题（其他主题类似），打开`/theme/next/layout/_partial/footer.swig`文件，拷贝下面的代码至文件的开头。\n\n```\n<script async src=\"https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js\">\n</script>\n```\n\n## 显示统计标签 ##\n\n同样编辑`/theme/next/layout/_partial/footer.swig`文件。\n\n如果你想要显示`pv`统计量，复制以下代码至你想要放置的位置，\n\n```\n<span id=\"busuanzi_container_site_pv\">\n    本站总访问量<span id=\"busuanzi_value_site_pv\"></span>次\n</span>\n```\n\n如果你想要显示`uv`统计量，复制以下代码至你想要放置的位置，\n\n```\n<span id=\"busuanzi_container_site_uv\">\n  本站访客数<span id=\"busuanzi_value_site_uv\"></span>人次\n</span>\n```\n\n你可以自己修改文字样式，效果图如下：\n\n![](http://i.imgur.com/rWtu2TU.png)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/hexo-next-add-post-views.html\n\n\n**参考资料**\n\n[为NexT主题添加文章阅读量统计功能](http://notes.xiamo.tk/2015-10-21-%E4%B8%BANexT%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%E9%87%8F%E7%BB%9F%E8%AE%A1%E5%8A%9F%E8%83%BD.html)","source":"_posts/hexo-next-add-post-views.md","raw":"title: Hexo的NexT主题个性化：添加文章阅读量\ndate: 2016-01-22 09:28:40\ntags: [Hexo, Next, LeanCloud]\ncategories: Hexo\n---\n\n关于Hexo的文章阅读量设置问题，大多数人都是使用[不蒜子](http://service.ibruce.info/)的代码实现。但是这个方法仅局限于在文章页面显示阅读数，首页是不显示的。\n\n下面介绍如何在首页及文章页面都显示`文章的阅读量`，显示效果如下：\n\n![](http://i.imgur.com/AMdIdpW.png)\n\n----------\n\n## **配置[LeanCloud](https://leancloud.cn/)** ##\n\n### 注册 ###\n\n打开LeanCloud官网，进入[注册页面](https://leancloud.cn/login.html#/signup)注册。完成邮箱激活后，点击头像，进入`控制台`页面，如下：\n\n![](http://i.imgur.com/WyRLYr3.png)\n\n### 创建新应用 ###\n\n创建一个新应用(类型为`JavaScript SDK`)，点击应用进入；\n\n创建名称为`Counter`的Class\n\n![](http://i.imgur.com/5VUiBAy.png)\n\n![](http://i.imgur.com/C8LWKT2.png)\n\n### 修改配置文件 ###\n\n编辑网站根目录下的`_config.yml`文件，添加如下：\n\n\t# add post views\n\tleancloud_visitors:\n\t  enable: true\n\t  app_id: **你的app_id**\n\t  app_key: **你的app_key**\n\n其中，app_id和app_key在你所创建的应用的`设置->应用Key`中。\n\n### Web安全性 ###\n\n为了保证应用的统计计数功能仅应用于自己的博客系统，你可以在`应用->设置->安全中心`的`Web安全域名`中加入自己的博客域名，以保证数据的调用安全。\n\n## **修改NexT主题文件** ##\n\n### 添加lean-analytics.swig文件 ###\n\n在主题目录下的`\\layout\\_scripts`路径下，新建一个名称为`lean-analytics.swig`的文件，并添加如下内容：\n\n```\n\t<!-- custom analytics part create by xiamo -->\n\t<script src=\"https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js\"></script>\n\t<script>AV.initialize(\"{{theme.leancloud_visitors.app_id}}\", \"{{theme.leancloud_visitors.app_key}}\");</script>\n\t<script>\n\tfunction showTime(Counter) {\n\t\tvar query = new AV.Query(Counter);\n\t\t$(\".leancloud_visitors\").each(function() {\n\t\t\tvar url = $(this).attr(\"id\").trim();\n\t\t\tquery.equalTo(\"url\", url);\n\t\t\tquery.find({\n\t\t\t\tsuccess: function(results) {\n\t\t\t\t\tif (results.length == 0) {\n\t\t\t\t\t\tvar content = '0 ' + $(document.getElementById(url)).text();\n\t\t\t\t\t\t$(document.getElementById(url)).text(content);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tfor (var i = 0; i < results.length; i++) {\n\t\t\t\t\t\tvar object = results[i];\n\t\t\t\t\t\tvar content = object.get('time') + ' ' + $(document.getElementById(url)).text();\n\t\t\t\t\t\t$(document.getElementById(url)).text(content);\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\terror: function(object, error) {\n\t\t\t\t\tconsole.log(\"Error: \" + error.code + \" \" + error.message);\n\t\t\t\t}\n\t\t\t});\n\t\n\t\t});\n\t}\n\t\n\tfunction addCount(Counter) {\n\t\tvar Counter = AV.Object.extend(\"Counter\");\n\t\turl = $(\".leancloud_visitors\").attr('id').trim();\n\t\ttitle = $(\".leancloud_visitors\").attr('data-flag-title').trim();\n\t\tvar query = new AV.Query(Counter);\n\t\tquery.equalTo(\"url\", url);\n\t\tquery.find({\n\t\t\tsuccess: function(results) {\n\t\t\t\tif (results.length > 0) {\n\t\t\t\t\tvar counter = results[0];\n\t\t\t\t\tcounter.fetchWhenSave(true);\n\t\t\t\t\tcounter.increment(\"time\");\n\t\t\t\t\tcounter.save(null, {\n\t\t\t\t\t\tsuccess: function(counter) {\n\t\t\t\t\t\t\tvar content =  counter.get('time') + ' ' + $(document.getElementById(url)).text();\n\t\t\t\t\t\t\t$(document.getElementById(url)).text(content);\n\t\t\t\t\t\t},\n\t\t\t\t\t\terror: function(counter, error) {\n\t\t\t\t\t\t\tconsole.log('Failed to save Visitor num, with error message: ' + error.message);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t} else {\n\t\t\t\t\tvar newcounter = new Counter();\n\t\t\t\t\tnewcounter.set(\"title\", title);\n\t\t\t\t\tnewcounter.set(\"url\", url);\n\t\t\t\t\tnewcounter.set(\"time\", 1);\n\t\t\t\t\tnewcounter.save(null, {\n\t\t\t\t\t\tsuccess: function(newcounter) {\n\t\t\t\t\t\t    console.log(\"newcounter.get('time')=\"+newcounter.get('time'));\n\t\t\t\t\t\t\tvar content = newcounter.get('time') + ' ' + $(document.getElementById(url)).text();\n\t\t\t\t\t\t\t$(document.getElementById(url)).text(content);\n\t\t\t\t\t\t},\n\t\t\t\t\t\terror: function(newcounter, error) {\n\t\t\t\t\t\t\tconsole.log('Failed to create');\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t},\n\t\t\terror: function(error) {\n\t\t\t\tconsole.log('Error:' + error.code + \" \" + error.message);\n\t\t\t}\n\t\t});\n\t}\n\t$(function() {\n\t\tvar Counter = AV.Object.extend(\"Counter\");\n\t\tif ($('.leancloud_visitors').length == 1) {\n\t\t\taddCount(Counter);\n\t\t} else if ($('.post-title-link').length > 1) {\n\t\t\tshowTime(Counter);\n\t\t}\n\t}); \n\t</script>\n```\n\n其中，控制显示的格式的主要为`content`变量，按自己的需求相应修改即可。\n\n### 修改post.swig文件 ###\n\n在主题的`layout\\_macro`路径下，编辑`post.swig`文件，找到相应的插入位置（大概在98行左右）：\n\n![](http://i.imgur.com/l21gZ2f.png)\n\n插入如下代码\n\n```\n\t\t  {% if theme.leancloud_visitors.enable %}\n\t\t\t &nbsp; | &nbsp;\n\t\t\t <span id=\"{{ url_for(post.path) }}\"class=\"leancloud_visitors\" data-flag-title=\"{{ post.title }}\">\n             &nbsp;{{__('post.visitors')}}\n            </span>\n\t\t  {% endif %}\n```\n### 修改layout.swig文件 ###\n\n在主题目录下的`layout`目录下，编辑`_layout.swig`文件，在`</body>`的上方（大概在70行左右）插入如下代码：\n\n```\n\t{% if theme.leancloud_visitors.enable %}\n\t{% include '_scripts/lean-analytics.swig' %}\n\t{% endif %}\n```\n\n### 修改语言配置文件 ###\n\n如果你的网站使用的是英语，则只需要编辑主题目录下的`languages\\en.yml`文件，增加`post`字段如下：\n\n\tpost:\n\t  sticky: Sticky\n\t  posted: Posted on\n\t  visitors: Views // 增加的字段\n\t  ...\n\n如果网站使用的是中文，则编辑`languages\\zh-Hans.yml`文件，相应的增加\n\n\tpost:\n\t  posted: 发表于\n\t  visitors: 阅读次数\n\t  ...\n\n其他语言与之类似，将`visitors`设置成你希望翻译的字段。\n\n**最后，重新生成并部署你的网站即可。**\n\n## **增加网站的浏览次数与访客数量统计功能** ##\n\n网站的浏览次数，即`pv`；网站的访客数为`uv`。`pv`的计算方式是，单个用户连续点击n篇文章，记录n次访问量；`uv`的计算方式是，单个用户连续点击n篇文章，只记录1次访客数。你可以根据需要添加相应的统计功能。\n\n## 安装`busuanzi.js`脚本 ##\n\n如果你使用的是NexT主题（其他主题类似），打开`/theme/next/layout/_partial/footer.swig`文件，拷贝下面的代码至文件的开头。\n\n```\n<script async src=\"https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js\">\n</script>\n```\n\n## 显示统计标签 ##\n\n同样编辑`/theme/next/layout/_partial/footer.swig`文件。\n\n如果你想要显示`pv`统计量，复制以下代码至你想要放置的位置，\n\n```\n<span id=\"busuanzi_container_site_pv\">\n    本站总访问量<span id=\"busuanzi_value_site_pv\"></span>次\n</span>\n```\n\n如果你想要显示`uv`统计量，复制以下代码至你想要放置的位置，\n\n```\n<span id=\"busuanzi_container_site_uv\">\n  本站访客数<span id=\"busuanzi_value_site_uv\"></span>人次\n</span>\n```\n\n你可以自己修改文字样式，效果图如下：\n\n![](http://i.imgur.com/rWtu2TU.png)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/hexo-next-add-post-views.html\n\n\n**参考资料**\n\n[为NexT主题添加文章阅读量统计功能](http://notes.xiamo.tk/2015-10-21-%E4%B8%BANexT%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB%E9%87%8F%E7%BB%9F%E8%AE%A1%E5%8A%9F%E8%83%BD.html)","slug":"hexo-next-add-post-views","published":1,"updated":"2016-04-20T06:45:54.834Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cinjqrkpo002jnfq6xp9c0nlz","sticky":0},{"title":"Hexo+Github: 搭建属于自己的静态博客","date":"2015-12-07T13:44:01.000Z","_content":"Hexo是一个快速、简洁且高效的博客框架，而Github是一个免费的代码托管工具，利用Github Page可以免费创建一个静态网站。下面将介绍如何使用Hexo和Github，在win10环境下搭建一个静态的博客。\n\n全文分为三个部分：\n\n1. 安装和配置Hexo及Github\n2. 选择Hexo主题及发表文章\n3. 注册及绑定自己的域名地址\n\n----------\n\n## **安装和配置Hexo及Github** ##\n\n### 安装Hexo ###\n\n安装Hexo前，需要安装以下：\n\n- [Node.js](http://nodejs.org/)\n- [Git](https://git-scm.com/download/win)\n\n如果已经安装完成以上程序，打开Git-bash或者cmd，输入\n\n\tnpm install -g hexo-cli\n\n即可完成Hexo的安装。\n\n### 使用Hexo进行本地建站 ###\n\n选择一个本地的文件夹，如`D:\\hexo`。\n\n输入\n\n\thexo init D:\\hexo\n\tcd D:\\hexo\n\tnpm install\n\n如果hexo安装成功，则在`D:\\hexo`文件夹下的文件目录为\n\n\t.\n\t├── _config.yml // 网站的配置信息，你可以在此配置大部分的参数。\n\t├── package.json \n\t├── scaffolds // 模板文件夹。当你新建文章时，Hexo会根据scaffold来建立文件。\n\t├── source // 存放用户资源的地方\n\t|   ├── _drafts\n\t|   └── _posts\n\t└── themes // 存放网站的主题。Hexo会根据主题来生成静态页面。\n\n详细文件或文件夹的具体含义见 [Hexo官方文档之建站](https://hexo.io/zh-cn/docs/setup.html)\n\n为了测试本地建站是否成功，输入\n\n\thexo s\n\n如果显示如下\n\n![](http://i.imgur.com/7iVVdep.png)\n\n则说明本地建站成功，访问[本地地址](http://localhost:4000/)可以看到Hexo默认主题的效果。\n\n至此，Hexo的安装和本地建站完成，如需更加深入全面地了解Hexo，可访问[Hexo官方文档](https://hexo.io/zh-cn/docs/)。\n\n### 创建Github账号 ###\n\n如果已经注册Github，可跳过此步骤。否则，访问[Github官网](https://github.com/)进行注册，下面假设你注册Github账号名为MyGithub。\n\n### 创建与账号同名的Repository ###\n\n注册并登陆Github官网成功后，点击页面右上角的`+`，选择`New repository`。\n\n在`Repository name`中填写`你的Github账号名.github.io`，这里是`MyGithub.github.io`。`Description`中填写对此repository的描述信息(可选，但建议填写，如`Personal website`)。\n\n点击`Create repository`，完成创建。\n\n### 配置SSH ###\n\n**(1) 生成SSH**\n\n检查是否已经有SSH Key，打开Git Bash，输入\n\n\tcd ~/.ssh\n\n如果没有这个目录，则生成一个新的SSH，输入\n\n\tssh-keygen -t rsa -C \"your e-mail\"\n\n其中，`your e-mail`是你注册Github时用到的邮箱。\n\n然后接下来几步都直接按回车键，最后生成如下\n\n![](http://i.imgur.com/RSCTurW.jpg)\n\n**(2) 复制公钥内容到Github账户信息中**\n\n打开`~/.ssh/id_rsa.pub`文件，复制里面的内容；\n\n打开Github官网，登陆后进入到个人设置(`点击头像->setting`)，点击右侧的`SSH Keys`，点击`Add SSH key`；填写title之后，将之前复制的内容粘贴到Key框中，最后点击`Add key`即可。\n\n**(3) 测试SSH是否配置成功**\n\n输入\n\n\tssh -T git@github.com\n\n如果显示以下，则说明ssh配置成功。\n\n\tHi username! You've successfully authenticated, but GitHub does not\n\tprovide shell access.\n\n\n### 将网站发布到Github的同名repository中 ###\n\n打开`D:\\Hexo`文件夹中的`_config.yml`文件，找到如下位置，填写\n\n\t# Deployment\n\t## Docs: http://hexo.io/docs/deployment.html\n\tdeploy: \n\t  type: git\n\t  repo: git@github.com:MyGithub/MyGithub.github.io\n\n**注**： (1) 其中`MyGithub`替换成你的Github账户; (2) 注意在yml文件中，`:`后面都是要带空格的。\n\n此时，通过访问`http://MyGithub.github.io`可以看到默认的Hexo首页面（与之前本地测试时一样）。\n\n## **选择Hexo主题及发表文章** ##\n\n### 简洁的Next主题 ###\n\n本网站使用的是[Next主题](https://github.com/iissnan/hexo-theme-next)。该主题简洁易用，在移动端也表现不错。\n\n**(1) 下载Next主题**\n\n\tcd D:\\Hexo\n\tgit clone https://github.com/iissnan/hexo-theme-next themes/next\n\n**(2) 修改网站的主题为Next**\n\n打开`D:\\Hexo`下的`_config.yml`文件，找到`theme`字段，将其修改为`next`\n\n\t# Extensions\n\t## Plugins: http://hexo.io/plugins/\n\t## Themes: http://hexo.io/themes/\n\ttheme: next\n\n**(3) 本地验证是否可用**\n\n输入\n\n\thexo s --debug\n\n访问[本地网站](http://localhost:4000)，确认网站主题是否切换为Next.\n\n**(4) 更新Github**\n\n输入\n\n\thexo g -d\n\n完成Github上网页文件的更新。\n\n### 发表新文章 ###\n\n发表文章操作非常简单，在网站存放的根目录打开`git bash`，输入\n\n\thexo n \"name of the new post\"\n\n回车后，在source文件夹下的_post文件夹下，可以看到新建了一个`name of the new post.md`的文件，打开\n\n\ttitle: name of the new post\n\tdate: 2015-12-09 22:55:25\n\ttags:\n\t---\n\n可以给文章贴上相应的tags，如有多个则按照如下格式\n\n\t[tag1, tag2, tag3, ...]\n\n在`- - -`下方添加正文内容即可，注意需要使用markdown语法进行书写。\n\n[在这里](http://wowubuntu.com/markdown/)有关于Markdown语法的简单说明。推荐使用[MarkdownPad2](http://markdownpad.com/)进行md文件的编辑工作。\n\n文章撰写完成后保存，输入\n\n\thexo g -d\n\n即可生成新网站，并且同步Github上的网站内容。\n\n## **注册及绑定自己的域名地址** ##\n\n截止到目前为止，你应该可以通过访问`http://MyGithub.github.io`来看到以上创建的网站了。\n\n但是，如何拥有一个属于自己的域名地址，并将其指向在Github上所创建的网站呢？\n\n### 注册域名 ###\n\n推荐选择国内的[万网](http://wanwang.aliyun.com/)或者国外的[Goddady](https://www.godaddy.com/)进行域名的注册。\n\n### DNS域名解析设置 ###\n\n如果你选择的是万网注册的域名，可以使用其自带的域名解析服务。\n\n进入[万网](http://wanwang.aliyun.com/)，登陆后进入到个人中心(点击用户名即可)，点击左侧的\"云解析\"，点击之前所购买的域名，在\"解析设置\"中，添加如下解析规则:\n\n![](http://i.imgur.com/AqhPQst.png)\n\n其中，当记录类型为A时，记录值为服务器的ip地址，这里的服务器地址为存放`Github page`的地址，你可以通过命令行输入\n\n\tping github.io\n\n得到。\n\nDNS域名解析设置需要一定时间，之后你可以通过ping自己的域名地址来查看是否解析成功。\n\n### 在Github对应的repository中添加CNAME文件 ###\n\n即在 MyGithub/MyGithub.github.io 中加入名为\"CNAME\"的文件，文件内容为你的域名地址，如\n\n\twww.××××××.com\n\n保存即可。\n\nCNAME文件设置的目的是，通过访问 MyGithub.github.io 可以跳转到你所注册的域名上。\n\n为了方便本地文件deploy的时候，CNAME文件不发生丢失，可以在本地网站根目录下的source文件夹下，添加以上的CNAME文件。以后每次deploy的时候，CNAME文件不会发生丢失。\n\n----------\n\n通过以上的设置，相信你已经可以通过注册域名来访问一个默认的hexo主题页面了。之后的工作就在于，(1)如何对主题进行个性化设置及；(2)发表博文以充实网站内容。[这里](http://theme-next.iissnan.com/)有关于next主题的个性化设置说明。\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/hexo-github-blog-building.html\n\n","source":"_posts/hexo-github-blog-building.md","raw":"title: 'Hexo+Github: 搭建属于自己的静态博客'\ndate: 2015-12-07 21:44:01\ntags: [Hexo, Github Page, Blog, Personal Website]\ncategories: Hexo\n---\nHexo是一个快速、简洁且高效的博客框架，而Github是一个免费的代码托管工具，利用Github Page可以免费创建一个静态网站。下面将介绍如何使用Hexo和Github，在win10环境下搭建一个静态的博客。\n\n全文分为三个部分：\n\n1. 安装和配置Hexo及Github\n2. 选择Hexo主题及发表文章\n3. 注册及绑定自己的域名地址\n\n----------\n\n## **安装和配置Hexo及Github** ##\n\n### 安装Hexo ###\n\n安装Hexo前，需要安装以下：\n\n- [Node.js](http://nodejs.org/)\n- [Git](https://git-scm.com/download/win)\n\n如果已经安装完成以上程序，打开Git-bash或者cmd，输入\n\n\tnpm install -g hexo-cli\n\n即可完成Hexo的安装。\n\n### 使用Hexo进行本地建站 ###\n\n选择一个本地的文件夹，如`D:\\hexo`。\n\n输入\n\n\thexo init D:\\hexo\n\tcd D:\\hexo\n\tnpm install\n\n如果hexo安装成功，则在`D:\\hexo`文件夹下的文件目录为\n\n\t.\n\t├── _config.yml // 网站的配置信息，你可以在此配置大部分的参数。\n\t├── package.json \n\t├── scaffolds // 模板文件夹。当你新建文章时，Hexo会根据scaffold来建立文件。\n\t├── source // 存放用户资源的地方\n\t|   ├── _drafts\n\t|   └── _posts\n\t└── themes // 存放网站的主题。Hexo会根据主题来生成静态页面。\n\n详细文件或文件夹的具体含义见 [Hexo官方文档之建站](https://hexo.io/zh-cn/docs/setup.html)\n\n为了测试本地建站是否成功，输入\n\n\thexo s\n\n如果显示如下\n\n![](http://i.imgur.com/7iVVdep.png)\n\n则说明本地建站成功，访问[本地地址](http://localhost:4000/)可以看到Hexo默认主题的效果。\n\n至此，Hexo的安装和本地建站完成，如需更加深入全面地了解Hexo，可访问[Hexo官方文档](https://hexo.io/zh-cn/docs/)。\n\n### 创建Github账号 ###\n\n如果已经注册Github，可跳过此步骤。否则，访问[Github官网](https://github.com/)进行注册，下面假设你注册Github账号名为MyGithub。\n\n### 创建与账号同名的Repository ###\n\n注册并登陆Github官网成功后，点击页面右上角的`+`，选择`New repository`。\n\n在`Repository name`中填写`你的Github账号名.github.io`，这里是`MyGithub.github.io`。`Description`中填写对此repository的描述信息(可选，但建议填写，如`Personal website`)。\n\n点击`Create repository`，完成创建。\n\n### 配置SSH ###\n\n**(1) 生成SSH**\n\n检查是否已经有SSH Key，打开Git Bash，输入\n\n\tcd ~/.ssh\n\n如果没有这个目录，则生成一个新的SSH，输入\n\n\tssh-keygen -t rsa -C \"your e-mail\"\n\n其中，`your e-mail`是你注册Github时用到的邮箱。\n\n然后接下来几步都直接按回车键，最后生成如下\n\n![](http://i.imgur.com/RSCTurW.jpg)\n\n**(2) 复制公钥内容到Github账户信息中**\n\n打开`~/.ssh/id_rsa.pub`文件，复制里面的内容；\n\n打开Github官网，登陆后进入到个人设置(`点击头像->setting`)，点击右侧的`SSH Keys`，点击`Add SSH key`；填写title之后，将之前复制的内容粘贴到Key框中，最后点击`Add key`即可。\n\n**(3) 测试SSH是否配置成功**\n\n输入\n\n\tssh -T git@github.com\n\n如果显示以下，则说明ssh配置成功。\n\n\tHi username! You've successfully authenticated, but GitHub does not\n\tprovide shell access.\n\n\n### 将网站发布到Github的同名repository中 ###\n\n打开`D:\\Hexo`文件夹中的`_config.yml`文件，找到如下位置，填写\n\n\t# Deployment\n\t## Docs: http://hexo.io/docs/deployment.html\n\tdeploy: \n\t  type: git\n\t  repo: git@github.com:MyGithub/MyGithub.github.io\n\n**注**： (1) 其中`MyGithub`替换成你的Github账户; (2) 注意在yml文件中，`:`后面都是要带空格的。\n\n此时，通过访问`http://MyGithub.github.io`可以看到默认的Hexo首页面（与之前本地测试时一样）。\n\n## **选择Hexo主题及发表文章** ##\n\n### 简洁的Next主题 ###\n\n本网站使用的是[Next主题](https://github.com/iissnan/hexo-theme-next)。该主题简洁易用，在移动端也表现不错。\n\n**(1) 下载Next主题**\n\n\tcd D:\\Hexo\n\tgit clone https://github.com/iissnan/hexo-theme-next themes/next\n\n**(2) 修改网站的主题为Next**\n\n打开`D:\\Hexo`下的`_config.yml`文件，找到`theme`字段，将其修改为`next`\n\n\t# Extensions\n\t## Plugins: http://hexo.io/plugins/\n\t## Themes: http://hexo.io/themes/\n\ttheme: next\n\n**(3) 本地验证是否可用**\n\n输入\n\n\thexo s --debug\n\n访问[本地网站](http://localhost:4000)，确认网站主题是否切换为Next.\n\n**(4) 更新Github**\n\n输入\n\n\thexo g -d\n\n完成Github上网页文件的更新。\n\n### 发表新文章 ###\n\n发表文章操作非常简单，在网站存放的根目录打开`git bash`，输入\n\n\thexo n \"name of the new post\"\n\n回车后，在source文件夹下的_post文件夹下，可以看到新建了一个`name of the new post.md`的文件，打开\n\n\ttitle: name of the new post\n\tdate: 2015-12-09 22:55:25\n\ttags:\n\t---\n\n可以给文章贴上相应的tags，如有多个则按照如下格式\n\n\t[tag1, tag2, tag3, ...]\n\n在`- - -`下方添加正文内容即可，注意需要使用markdown语法进行书写。\n\n[在这里](http://wowubuntu.com/markdown/)有关于Markdown语法的简单说明。推荐使用[MarkdownPad2](http://markdownpad.com/)进行md文件的编辑工作。\n\n文章撰写完成后保存，输入\n\n\thexo g -d\n\n即可生成新网站，并且同步Github上的网站内容。\n\n## **注册及绑定自己的域名地址** ##\n\n截止到目前为止，你应该可以通过访问`http://MyGithub.github.io`来看到以上创建的网站了。\n\n但是，如何拥有一个属于自己的域名地址，并将其指向在Github上所创建的网站呢？\n\n### 注册域名 ###\n\n推荐选择国内的[万网](http://wanwang.aliyun.com/)或者国外的[Goddady](https://www.godaddy.com/)进行域名的注册。\n\n### DNS域名解析设置 ###\n\n如果你选择的是万网注册的域名，可以使用其自带的域名解析服务。\n\n进入[万网](http://wanwang.aliyun.com/)，登陆后进入到个人中心(点击用户名即可)，点击左侧的\"云解析\"，点击之前所购买的域名，在\"解析设置\"中，添加如下解析规则:\n\n![](http://i.imgur.com/AqhPQst.png)\n\n其中，当记录类型为A时，记录值为服务器的ip地址，这里的服务器地址为存放`Github page`的地址，你可以通过命令行输入\n\n\tping github.io\n\n得到。\n\nDNS域名解析设置需要一定时间，之后你可以通过ping自己的域名地址来查看是否解析成功。\n\n### 在Github对应的repository中添加CNAME文件 ###\n\n即在 MyGithub/MyGithub.github.io 中加入名为\"CNAME\"的文件，文件内容为你的域名地址，如\n\n\twww.××××××.com\n\n保存即可。\n\nCNAME文件设置的目的是，通过访问 MyGithub.github.io 可以跳转到你所注册的域名上。\n\n为了方便本地文件deploy的时候，CNAME文件不发生丢失，可以在本地网站根目录下的source文件夹下，添加以上的CNAME文件。以后每次deploy的时候，CNAME文件不会发生丢失。\n\n----------\n\n通过以上的设置，相信你已经可以通过注册域名来访问一个默认的hexo主题页面了。之后的工作就在于，(1)如何对主题进行个性化设置及；(2)发表博文以充实网站内容。[这里](http://theme-next.iissnan.com/)有关于next主题的个性化设置说明。\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/hexo-github-blog-building.html\n\n","slug":"hexo-github-blog-building","published":1,"updated":"2016-01-22T15:06:22.739Z","_id":"cinjqrkpt002pnfq6h2hvwrok","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"卷积神经网络(CNN)学习笔记2：模型训练","date":"2016-03-03T05:41:05.000Z","_content":"\n[**上篇博文**](http://www.jeyzhang.com/cnn-learning-notes-1.html)主要对CNN的基本网络结构及连接方式做了简单的介绍，还介绍了一个界内经典的**`LeNet-5`**模型。下面重点介绍CNN模型的训练过程/参数学习，在阅读本文之前，最好需要有以下方面的预备知识：\n\n- 神经网络基础（网络结构，前向/后向传播方式，激活函数等）；\n- 基础的最优化求解方法（梯度法，牛顿法等）；\n- 机器学习基础\n----------\n\n神经网络模型常用于处理有监督学习的问题，例如分类问题，CNN也不例外。模型需要一些有标注的数据进行训练，训练过程中主要涉及到网络的**前向传播**和**反向传播**计算，前向传播体现了特征信息的传递，而反向传播则是体现误差信息对模型参数的矫正。\n\n### CNN前向传播 ###\n\n与普通的神经网络的前向传播过程一样。用 \\\\( l \\\\) 表示当前层，\\\\( x^{l} \\\\) 表示当前层的输出，\\\\( W^{l} \\\\) 和 \\\\( b^{l} \\\\) 分别表示当前层的权值和偏置，则前向传播可以用下面的公式表示：\n\n$$ x^{l} = f\\left( u^{l}\\right), \\ with \\; u^{l} = W^{l}x^{l-1} + b^{l} $$\n\n其中 \\\\(f\\left( \\right)\\\\) 函数为激活函数，可以选择`sigmod`或者`tanh`等函数。\n\n对于卷积层，其前向传播如下图：\n\n![](http://i.imgur.com/4mCbV3d.png)\n\n### CNN反向传播 ###\n\n#### 代价函数 ####\n\n代价函数（或损失函数）有较多形式，常用的有平方误差函数，交叉熵等。这里我们用平方误差函数作为代价函数，公式如下：\n\n$$ E^{n} = \\dfrac {1} {2}\\sum \\_{k=1}^{c}\\left( t\\_{k}^{n} - y\\_{k}^{n}\\right) ^{2} = \\dfrac {1} {2}||t^{n} - y^{n}||\\_{2}^{2}$$\n\n以上公式描述了样本 \\\\( n \\\\) 的训练误差，其中 \\\\( c \\\\) 为输出层节点的个数（通常就是最终的分类类别数目），\\\\( t \\\\) 是训练样本的正确结果，\\\\( y \\\\) 是网络训练的输出结果。\n\n#### BP反向传播 ####\n\n基本的反向传播与BP神经网络类似，首先，简单回顾一下BP神经网络中的反向传播计算过程：\n\n权值参数调整的方向如下公式：\n\n$$ \\Delta W^{l} = -\\eta \\dfrac {\\partial E} {\\partial W^{l}}, \\ \\ \\dfrac {\\partial E} {\\partial W^{l}} = x^{l-1}(\\delta ^{l})^{T} $$\n\n其中，\\\\( \\eta \\\\) 为学习率。\n\n$$ \\dfrac {\\partial E} {\\partial b} = \\dfrac {\\partial E} {\\partial u} \\dfrac {\\partial u} {\\partial b} = \\dfrac {\\partial E} {\\partial u} = \\delta $$\n\n其中，\\\\( \\delta \\\\) 称之为**敏感度**，也就是**误差度**。 \\\\( \\delta \\\\)的计算方式如下：\n\n$$ \\delta ^{L} = f'(u^{L})\\circ (y^{n} - t^{n}) $$\n\n$$ \\delta ^{l} = (W^{l+1})^{T}\\circ f'(u^{l}) $$\n\n其中，\\\\( L \\\\) 表示网络的最后一层，\\\\( l \\\\) 表示网络的其他层，\\\\( \\circ \\\\) 表示点乘。 以上的两个公式反映了误差由网络的最后一层逐步向前传递的计算过程。\n\n#### 特殊的反向传播 ####\n\n由于CNN中有不同类型的层级，并且层级之间的连接关系有可能是不确定的（如LeNet-5网络中S2层到C3层）。所以，有几个情形下的反向传播比较特别：\n\n- **情况一**：当前为Pooling层，前一层是卷积层；\n- **情况二**：当前为卷积层，前一层是Pooling层；\n- **情况三**：当前层与前一层的连接关系不确定（**？尚不理解？**）；\n\n#### 情况一：当前为Pooling层，前一层是卷积层####\n\n![](http://i.imgur.com/TcfFA3Y.png)\n\n![](http://i.imgur.com/zsFtAhI.png)\n\n![](http://i.imgur.com/iUghGWY.png)\n\n其中，`Kronecker`乘积的计算如下：\n\n![](http://i.imgur.com/zH179Jk.png)\n\n#### 情况二：当前为卷积层，前一层是Pooling层 ####\n\n![](http://i.imgur.com/2R5A7VT.png)\n\n![](http://i.imgur.com/tm4daZv.png)\n\n以上的矩阵1和矩阵2进行卷积操作时，需要将矩阵2先**水平翻转**，然后再**垂直翻转**；最后在矩阵1上进行`卷积操作`（和前向传播时类似）。\n\n![](http://i.imgur.com/Q5pSR1x.png)\n\n![](http://i.imgur.com/fm30a99.png)\n\n#### 情况三：当前层与前一层的连接关系不确定 ####\n\n个人理解，当前层与前一层的连接关系不确定时，反向传播与传统的BP算法类似，只不过更新的是局部连接的那些值。所以需要提前记录当前层的神经元与前一层的哪些元素是连接的。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/cnn-learning-notes-2.html\n\n**参考资料**\n\n[卷积神经网络全面解析](http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi)\n\n[CNN卷积神经网络反向传播机制的理解](http://blog.csdn.net/vintage_1/article/details/17253997)\n\n\n","source":"_posts/cnn-learning-notes-2.md","raw":"title: 卷积神经网络(CNN)学习笔记2：模型训练\ndate: 2016-03-03 13:41:05\ntags: [Machine Learning, Deep Learning, CNN]\ncategories: Machine Learning\n---\n\n[**上篇博文**](http://www.jeyzhang.com/cnn-learning-notes-1.html)主要对CNN的基本网络结构及连接方式做了简单的介绍，还介绍了一个界内经典的**`LeNet-5`**模型。下面重点介绍CNN模型的训练过程/参数学习，在阅读本文之前，最好需要有以下方面的预备知识：\n\n- 神经网络基础（网络结构，前向/后向传播方式，激活函数等）；\n- 基础的最优化求解方法（梯度法，牛顿法等）；\n- 机器学习基础\n----------\n\n神经网络模型常用于处理有监督学习的问题，例如分类问题，CNN也不例外。模型需要一些有标注的数据进行训练，训练过程中主要涉及到网络的**前向传播**和**反向传播**计算，前向传播体现了特征信息的传递，而反向传播则是体现误差信息对模型参数的矫正。\n\n### CNN前向传播 ###\n\n与普通的神经网络的前向传播过程一样。用 \\\\( l \\\\) 表示当前层，\\\\( x^{l} \\\\) 表示当前层的输出，\\\\( W^{l} \\\\) 和 \\\\( b^{l} \\\\) 分别表示当前层的权值和偏置，则前向传播可以用下面的公式表示：\n\n$$ x^{l} = f\\left( u^{l}\\right), \\ with \\; u^{l} = W^{l}x^{l-1} + b^{l} $$\n\n其中 \\\\(f\\left( \\right)\\\\) 函数为激活函数，可以选择`sigmod`或者`tanh`等函数。\n\n对于卷积层，其前向传播如下图：\n\n![](http://i.imgur.com/4mCbV3d.png)\n\n### CNN反向传播 ###\n\n#### 代价函数 ####\n\n代价函数（或损失函数）有较多形式，常用的有平方误差函数，交叉熵等。这里我们用平方误差函数作为代价函数，公式如下：\n\n$$ E^{n} = \\dfrac {1} {2}\\sum \\_{k=1}^{c}\\left( t\\_{k}^{n} - y\\_{k}^{n}\\right) ^{2} = \\dfrac {1} {2}||t^{n} - y^{n}||\\_{2}^{2}$$\n\n以上公式描述了样本 \\\\( n \\\\) 的训练误差，其中 \\\\( c \\\\) 为输出层节点的个数（通常就是最终的分类类别数目），\\\\( t \\\\) 是训练样本的正确结果，\\\\( y \\\\) 是网络训练的输出结果。\n\n#### BP反向传播 ####\n\n基本的反向传播与BP神经网络类似，首先，简单回顾一下BP神经网络中的反向传播计算过程：\n\n权值参数调整的方向如下公式：\n\n$$ \\Delta W^{l} = -\\eta \\dfrac {\\partial E} {\\partial W^{l}}, \\ \\ \\dfrac {\\partial E} {\\partial W^{l}} = x^{l-1}(\\delta ^{l})^{T} $$\n\n其中，\\\\( \\eta \\\\) 为学习率。\n\n$$ \\dfrac {\\partial E} {\\partial b} = \\dfrac {\\partial E} {\\partial u} \\dfrac {\\partial u} {\\partial b} = \\dfrac {\\partial E} {\\partial u} = \\delta $$\n\n其中，\\\\( \\delta \\\\) 称之为**敏感度**，也就是**误差度**。 \\\\( \\delta \\\\)的计算方式如下：\n\n$$ \\delta ^{L} = f'(u^{L})\\circ (y^{n} - t^{n}) $$\n\n$$ \\delta ^{l} = (W^{l+1})^{T}\\circ f'(u^{l}) $$\n\n其中，\\\\( L \\\\) 表示网络的最后一层，\\\\( l \\\\) 表示网络的其他层，\\\\( \\circ \\\\) 表示点乘。 以上的两个公式反映了误差由网络的最后一层逐步向前传递的计算过程。\n\n#### 特殊的反向传播 ####\n\n由于CNN中有不同类型的层级，并且层级之间的连接关系有可能是不确定的（如LeNet-5网络中S2层到C3层）。所以，有几个情形下的反向传播比较特别：\n\n- **情况一**：当前为Pooling层，前一层是卷积层；\n- **情况二**：当前为卷积层，前一层是Pooling层；\n- **情况三**：当前层与前一层的连接关系不确定（**？尚不理解？**）；\n\n#### 情况一：当前为Pooling层，前一层是卷积层####\n\n![](http://i.imgur.com/TcfFA3Y.png)\n\n![](http://i.imgur.com/zsFtAhI.png)\n\n![](http://i.imgur.com/iUghGWY.png)\n\n其中，`Kronecker`乘积的计算如下：\n\n![](http://i.imgur.com/zH179Jk.png)\n\n#### 情况二：当前为卷积层，前一层是Pooling层 ####\n\n![](http://i.imgur.com/2R5A7VT.png)\n\n![](http://i.imgur.com/tm4daZv.png)\n\n以上的矩阵1和矩阵2进行卷积操作时，需要将矩阵2先**水平翻转**，然后再**垂直翻转**；最后在矩阵1上进行`卷积操作`（和前向传播时类似）。\n\n![](http://i.imgur.com/Q5pSR1x.png)\n\n![](http://i.imgur.com/fm30a99.png)\n\n#### 情况三：当前层与前一层的连接关系不确定 ####\n\n个人理解，当前层与前一层的连接关系不确定时，反向传播与传统的BP算法类似，只不过更新的是局部连接的那些值。所以需要提前记录当前层的神经元与前一层的哪些元素是连接的。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/cnn-learning-notes-2.html\n\n**参考资料**\n\n[卷积神经网络全面解析](http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi)\n\n[CNN卷积神经网络反向传播机制的理解](http://blog.csdn.net/vintage_1/article/details/17253997)\n\n\n","slug":"cnn-learning-notes-2","published":1,"updated":"2016-03-03T11:25:39.607Z","_id":"cinjqrkpz002ynfq6gp2j1ujv","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"卷积神经网络(CNN)学习笔记1：基础入门","date":"2016-03-01T11:25:11.000Z","_content":"\n## 概述 ##\n\n**卷积神经网络(Convolutional Neural Network, CNN)**是深度学习技术中极具代表的网络结构之一，在图像处理领域取得了很大的成功，在国际标准的ImageNet数据集上，许多成功的模型都是基于CNN的。CNN相较于传统的图像处理算法的优点之一在于，避免了对图像复杂的前期预处理过程（提取人工特征等），可以直接输入原始图像。\n\n图像处理中，往往会将图像看成是一个或多个的二维向量，如之前博文中提到的MNIST手写体图片就可以看做是一个28 × 28的二维向量（黑白图片，只有一个颜色通道；如果是RGB表示的彩色图片则有三个颜色通道，可表示为三张二维向量）。传统的神经网络都是采用全连接的方式，即输入层到隐藏层的神经元都是全部连接的，这样做将导致参数量巨大，使得网络训练耗时甚至难以训练，而CNN则通过**`局部连接`**、**`权值共享`**等方法避免这一困难，有趣的是，这些方法都是受到现代生物神经网络相关研究的启发（感兴趣可阅读以下部分）。\n\n![](http://i.imgur.com/UK1cQOP.png)\n\n下面重点介绍下CNN中的**局部连接(Sparse Connectivity)**和**权值共享(Shared Weights)**方法，理解它们很重要。\n\n### 局部连接与权值共享 ###\n\n下图是一个很经典的图示，左边是全连接，右边是局部连接。\n\n![](http://i.imgur.com/PHbta3D.jpg)\n\n对于一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为10^6个，采用全连接则有1000 × 1000 × 10^6 = 10^12个权值参数，如此数目巨大的参数几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8，将直接减少4个数量级。\n\n尽管减少了几个数量级，但参数数量依然较多。能不能再进一步减少呢？能！方法就是**权值共享**。具体做法是，在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，**将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同**，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 **10 × 10个权值参数**（也就是卷积核(也称滤波器)的大小），如下图。\n\n![](http://i.imgur.com/IIBM59H.jpg)\n\n这大概就是CNN的一个神奇之处，尽管只有这么少的参数，依旧有出色的性能。但是，这样仅提取了图像的一种特征，如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像的不同映射下的特征，称之为**`Feature Map`**。如果有100个卷积核，最终的权值参数也仅为100 × 100 = 10^4个而已。另外，偏置参数也是共享的，同一种滤波器共享一个。\n\n卷积神经网络的核心思想是：局部感受野(local field)，权值共享以及时间或空间亚采样这三种思想结合起来，获得了某种程度的位移、尺度、形变不变性（**？不够理解透彻？**）。\n\n## 网络结构 ##\n\n下图是一个经典的CNN结构，称为**`LeNet-5网络`**。\n\n![](http://i.imgur.com/qMs50Ma.png)\n\n可以看出，CNN中主要有两种类型的网络层，分别是**卷积层**和**池化/采样层(Pooling)**。卷积层的作用是提取图像的各种特征；池化层的作用是对原始特征信号进行抽象，从而大幅度减少训练参数，另外还可以减轻模型过拟合的程度。\n\n### 卷积层 ###\n\n卷积层是卷积核在上一级输入层上通过逐一滑动窗口计算而得，卷积核中的每一个参数都相当于传统神经网络中的权值参数，与对应的局部像素相连接，将卷积核的各个参数与对应的局部像素值相乘之和，（通常还要再加上一个偏置参数），得到卷积层上的结果。如下图所示。\n\n![](http://i.imgur.com/w8enPv2.png)\n\n下面的动图能够更好地解释卷积过程：\n\n![](http://i.imgur.com/KPyqPOB.gif)\n\n### 池化/采样层 ###\n\n通过卷积层获得了图像的特征之后，理论上我们可以直接使用这些特征训练分类器（如softmax），但是这样做将面临巨大的计算量的挑战，而且容易产生过拟合的现象。为了进一步降低网络训练参数及模型的过拟合程度，我们对卷积层进行**池化/采样(Pooling)**处理。池化/采样的方式通常有以下两种：\n\n- **Max-Pooling**: 选择Pooling窗口中的最大值作为采样值；\n- **Mean-Pooling**: 将Pooling窗口中的所有值相加取平均，以平均值作为采样值； \n\n如下图所示。\n\n![](http://i.imgur.com/bHBUsr4.png)\n\n### LeNet-5网络详解 ###\n\n以上较详细地介绍了CNN的网络结构和基本原理，下面介绍一个经典的CNN模型：**`LeNet-5网络`**。\n\n![](http://i.imgur.com/2AuotA0.png)\n\n![](http://i.imgur.com/Zzm048o.png)\n\n![](http://i.imgur.com/aJlgVHg.png)\n\n![](http://i.imgur.com/SiVPyWR.png)\n\n![](http://i.imgur.com/gTphBu6.png)\n\n![](http://i.imgur.com/6L3CmUc.png)\n\n![](http://i.imgur.com/SNLgNWe.png)\n\n![](http://i.imgur.com/kJtbaEz.png)\n\n**LeNet-5网络在MNIST数据集上的结果**\n\n![](http://i.imgur.com/cXSxkVY.png)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/cnn-learning-notes-1.html\n\n**参考资料**\n\n[Deep Learning（深度学习）学习笔记整理系列之（七）](http://blog.csdn.net/zouxy09/article/details/8781543)\n\n部分图片出自北京大学信息科学技术学院李戈教授的《深度学习技术与应用》课件\n\n\n\n\n\n","source":"_posts/cnn-learning-notes-1.md","raw":"title: 卷积神经网络(CNN)学习笔记1：基础入门\ndate: 2016-03-01 19:25:11\ntags: [Machine Learning, Deep Learning, CNN]\ncategories: Machine Learning\n---\n\n## 概述 ##\n\n**卷积神经网络(Convolutional Neural Network, CNN)**是深度学习技术中极具代表的网络结构之一，在图像处理领域取得了很大的成功，在国际标准的ImageNet数据集上，许多成功的模型都是基于CNN的。CNN相较于传统的图像处理算法的优点之一在于，避免了对图像复杂的前期预处理过程（提取人工特征等），可以直接输入原始图像。\n\n图像处理中，往往会将图像看成是一个或多个的二维向量，如之前博文中提到的MNIST手写体图片就可以看做是一个28 × 28的二维向量（黑白图片，只有一个颜色通道；如果是RGB表示的彩色图片则有三个颜色通道，可表示为三张二维向量）。传统的神经网络都是采用全连接的方式，即输入层到隐藏层的神经元都是全部连接的，这样做将导致参数量巨大，使得网络训练耗时甚至难以训练，而CNN则通过**`局部连接`**、**`权值共享`**等方法避免这一困难，有趣的是，这些方法都是受到现代生物神经网络相关研究的启发（感兴趣可阅读以下部分）。\n\n![](http://i.imgur.com/UK1cQOP.png)\n\n下面重点介绍下CNN中的**局部连接(Sparse Connectivity)**和**权值共享(Shared Weights)**方法，理解它们很重要。\n\n### 局部连接与权值共享 ###\n\n下图是一个很经典的图示，左边是全连接，右边是局部连接。\n\n![](http://i.imgur.com/PHbta3D.jpg)\n\n对于一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为10^6个，采用全连接则有1000 × 1000 × 10^6 = 10^12个权值参数，如此数目巨大的参数几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8，将直接减少4个数量级。\n\n尽管减少了几个数量级，但参数数量依然较多。能不能再进一步减少呢？能！方法就是**权值共享**。具体做法是，在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，**将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同**，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 **10 × 10个权值参数**（也就是卷积核(也称滤波器)的大小），如下图。\n\n![](http://i.imgur.com/IIBM59H.jpg)\n\n这大概就是CNN的一个神奇之处，尽管只有这么少的参数，依旧有出色的性能。但是，这样仅提取了图像的一种特征，如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像的不同映射下的特征，称之为**`Feature Map`**。如果有100个卷积核，最终的权值参数也仅为100 × 100 = 10^4个而已。另外，偏置参数也是共享的，同一种滤波器共享一个。\n\n卷积神经网络的核心思想是：局部感受野(local field)，权值共享以及时间或空间亚采样这三种思想结合起来，获得了某种程度的位移、尺度、形变不变性（**？不够理解透彻？**）。\n\n## 网络结构 ##\n\n下图是一个经典的CNN结构，称为**`LeNet-5网络`**。\n\n![](http://i.imgur.com/qMs50Ma.png)\n\n可以看出，CNN中主要有两种类型的网络层，分别是**卷积层**和**池化/采样层(Pooling)**。卷积层的作用是提取图像的各种特征；池化层的作用是对原始特征信号进行抽象，从而大幅度减少训练参数，另外还可以减轻模型过拟合的程度。\n\n### 卷积层 ###\n\n卷积层是卷积核在上一级输入层上通过逐一滑动窗口计算而得，卷积核中的每一个参数都相当于传统神经网络中的权值参数，与对应的局部像素相连接，将卷积核的各个参数与对应的局部像素值相乘之和，（通常还要再加上一个偏置参数），得到卷积层上的结果。如下图所示。\n\n![](http://i.imgur.com/w8enPv2.png)\n\n下面的动图能够更好地解释卷积过程：\n\n![](http://i.imgur.com/KPyqPOB.gif)\n\n### 池化/采样层 ###\n\n通过卷积层获得了图像的特征之后，理论上我们可以直接使用这些特征训练分类器（如softmax），但是这样做将面临巨大的计算量的挑战，而且容易产生过拟合的现象。为了进一步降低网络训练参数及模型的过拟合程度，我们对卷积层进行**池化/采样(Pooling)**处理。池化/采样的方式通常有以下两种：\n\n- **Max-Pooling**: 选择Pooling窗口中的最大值作为采样值；\n- **Mean-Pooling**: 将Pooling窗口中的所有值相加取平均，以平均值作为采样值； \n\n如下图所示。\n\n![](http://i.imgur.com/bHBUsr4.png)\n\n### LeNet-5网络详解 ###\n\n以上较详细地介绍了CNN的网络结构和基本原理，下面介绍一个经典的CNN模型：**`LeNet-5网络`**。\n\n![](http://i.imgur.com/2AuotA0.png)\n\n![](http://i.imgur.com/Zzm048o.png)\n\n![](http://i.imgur.com/aJlgVHg.png)\n\n![](http://i.imgur.com/SiVPyWR.png)\n\n![](http://i.imgur.com/gTphBu6.png)\n\n![](http://i.imgur.com/6L3CmUc.png)\n\n![](http://i.imgur.com/SNLgNWe.png)\n\n![](http://i.imgur.com/kJtbaEz.png)\n\n**LeNet-5网络在MNIST数据集上的结果**\n\n![](http://i.imgur.com/cXSxkVY.png)\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/cnn-learning-notes-1.html\n\n**参考资料**\n\n[Deep Learning（深度学习）学习笔记整理系列之（七）](http://blog.csdn.net/zouxy09/article/details/8781543)\n\n部分图片出自北京大学信息科学技术学院李戈教授的《深度学习技术与应用》课件\n\n\n\n\n\n","slug":"cnn-learning-notes-1","published":1,"updated":"2016-03-09T02:12:45.988Z","_id":"cinjqrkq30034nfq6zq4gigcp","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"卷积神经网络(CNN)在句子建模上的应用","date":"2016-03-11T02:36:35.000Z","_content":"\n之前的博文已经介绍了CNN的基本原理，本文将大概总结一下最近CNN在NLP中的句子建模（或者句子表示）方面的应用情况，主要阅读了以下的文献：\n\n> Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.\n\n> Kalchbrenner N, Grefenstette E, Blunsom P. A convolutional neural network for modelling sentences[J]. arXiv preprint arXiv:1404.2188, 2014.\n\n> Hu B, Lu Z, Li H, et al. Convolutional neural network architectures for matching natural language sentences[C]//Advances in Neural Information Processing Systems. 2014: 2042-2050.\n\n> He H, Gimpel K, Lin J. Multi-perspective sentence similarity modeling with convolutional neural networks[C]//Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015: 1576-1586.\n\n> Wenpeng Yin, Hinrich Schütze. Convolutional Neural Network for Paraphrase Identification. The 2015 Conference of the North American Chapter of the Association for Computational Linguistics\n\n> Zhang Y, Wallace B. A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification[J]. arXiv preprint arXiv:1510.03820, 2015.\n\n下面对文献中CNN的结构和细节进行梳理。\n\n----------\n\n### Kim Y's Paper ###\n\n#### 模型结构及原理 ####\n\n模型的结构如下：\n\n![](http://i.imgur.com/yxoZDt9.png)\n\n说明如下：\n\n- **输入层**\n\n如图所示，输入层是句子中的词语对应的word vector依次（从上到下）排列的矩阵，假设句子有 \\\\( n \\\\) 个词，vector的维数为 \\\\( k \\\\) ，那么这个矩阵就是 \\\\( n × k \\\\) 的。\n\n这个矩阵的类型可以是静态的(static)，也可以是动态的(non static)。静态就是word vector是固定不变的，而动态则是在模型训练过程中，word vector也当做是可优化的参数，通常把反向误差传播导致word vector中值发生变化的这一过程称为**`Fine tune`**。\n\n对于未登录词的vector，可以用0或者随机小的正数来填充。\n\n- **第一层卷积层**\n\n输入层通过卷积操作得到若干个`Feature Map`，卷积窗口的大小为 \\\\( h × k \\\\) ，其中 \\\\( h \\\\) 表示纵向词语的个数，而 \\\\( k \\\\) 表示word vector的维数。通过这样一个大型的卷积窗口，将得到若干个列数为1的`Feature Map`。\n\n- **池化层**\n\n接下来的池化层，文中用了一种称为**`Max-over-time Pooling`**的方法。这种方法就是简单地从之前一维的`Feature Map`中提出最大的值，文中解释最大值代表着最重要的信号。可以看出，这种Pooling方式可以解决可变长度的句子输入问题（因为不管`Feature Map`中有多少个值，只需要提取其中的最大值）。\n\n最终池化层的输出为各个`Feature Map`的最大值们，即一个一维的向量。\n\n- **全连接 + Softmax层**\n\n池化层的一维向量的输出通过全连接的方式，连接一个Softmax层，Softmax层可根据任务的需要设置（通常反映着最终类别上的概率分布）。\n\n最终实现时，我们可以在倒数第二层的全连接部分上使用`Dropout`技术，即对全连接层上的权值参数给予**`L2正则化`**的限制。这样做的好处是防止隐藏层单元自适应（或者对称），从而减轻过拟合的程度。\n\n#### 实验部分 ####\n\n**1. 数据**\n\n实验用到的数据集如下（具体的名称和来源可以参考论文）：\n\n![](http://i.imgur.com/8VDJDDJ.png)\n\n**2. 模型训练和调参**\n\n- 修正线性单元(Rectified linear units)\n- 滤波器的h大小：3,4,5；对应的Feature Map的数量为100；\n- Dropout率为0.5，L2正则化限制权值大小不超过3；\n- mini-batch的大小为50；\n\n这些参数的选择都是基于SST-2 dev数据集，通过网格搜索方法(Grid Search)得到的最优参数。另外，训练过程中采用随机梯度下降方法，基于shuffled mini-batches之上的，使用了Adadelta update rule(Zeiler, 2012)。\n\n**3. 预训练的Word Vector**\n\n这里的word vector使用的是公开的数据，即连续词袋模型(COW)在Google News上的训练结果。未登录次的vector值是随机初始化的。\n\n**4. 实验结果**\n\n实验结果如下图：\n\n![](http://i.imgur.com/sNpll24.png)\n\n其中，前四个模型是上文中所提出的基本模型的各个变种：\n\n- **CNN-rand**: 所有的word vector都是随机初始化的，同时当做训练过程中优化的参数；\n- **CNN-static**: 所有的word vector直接使用无监督学习即Google的Word2Vector工具(COW模型)得到的结果，并且是固定不变的；\n- **CNN-non-static**: 所有的word vector直接使用无监督学习即Google的Word2Vector工具(COW模型)得到的结果，但是会在训练过程中被`Fine tuned`；\n- **CNN-multichannel**: CNN-static和CNN-non-static的混合版本，即两种类型的输入；\n\n博主自己下载了论文作者的实现程序([**Github地址**](https://github.com/yoonkim/CNN_sentence))，最终在MR数据集上的运行结果如下：\n\n- CNN-rand: 0.7669\n- CNN-static: 0.8076\n- CNN-non-static: 0.8151\n\n和论文中的结果差不多。\n\n**5. 结论**\n\n- **`CNN-static`**较与**`CNN-rand`**好，**说明pre-training的word vector确实有较大的提升作用**（这也难怪，因为pre-training的word vector显然利用了更大规模的文本数据信息）；\n- **`CNN-non-static`**较于**`CNN-static`**大部分要好，**说明适当的Fine tune也是有利的，是因为使得vectors更加贴近于具体的任务**；\n- **`CNN-multichannel`**较于**`CNN-single`**在小规模的数据集上有更好的表现，实际上**`CNN-multichannel`**体现了一种折中思想，即既不希望Fine tuned的vector距离原始值太远，但同时保留其一定的变化空间。\n\n值得注意的是，static的vector和non-static的相比，有一些有意思的现象如下表格：\n\n![](http://i.imgur.com/fW6pr0p.png)\n\n- 原始的word2vector训练结果中，`bad`对应的最相近词为`good`，原因是这两个词在句法上的使用是极其类似的（可以简单替换，不会出现语句毛病）；而在`non-static`的版本中，`bad`对应的最相近词为`terrible`，这是因为在`Fune tune`的过程中，vector的值发生改变从而更加贴切数据集（是一个情感分类的数据集），所以在情感表达的角度这两个词会更加接近；\n- 句子中的**`!`**最接近一些表达形式较为激进的词汇，如`lush`等；而**`,`**则接近于一些连接词，这和我们的主观感受也是相符的。\n\nKim Y的这个模型很简单，但是却有着很好的性能。后续Denny用TensorFlow实现了这个模型的简单版本，可参考**[这篇博文](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)**；以及Ye Zhang等人对这个模型进行了大量的实验，并给出了调参的建议，可参考**[这篇论文](http://arxiv.org/abs/1510.03820)**。\n\n下面总结一下Ye Zhang等人基于Kim Y的模型做了大量的调参实验之后的结论：\n\n* 由于模型训练过程中的随机性因素，如随机初始化的权重参数，mini-batch，随机梯度下降优化算法等，造成模型在数据集上的结果有一定的浮动，如准确率(accuracy)能达到1.5%的浮动，而AUC则有3.4%的浮动；\n* 词向量是使用word2vec还是GloVe，对实验结果有一定的影响，具体哪个更好依赖于任务本身；\n* Filter的大小对模型性能有较大的影响，并且Filter的参数应该是可以更新的；\n* Feature Map的数量也有一定影响，但是需要兼顾模型的训练效率；\n* 1-max pooling的方式已经足够好了，相比于其他的pooling方式而言；\n* 正则化的作用微乎其微。\n\nYe Zhang等人给予模型调参者的建议如下：\n\n* 使用**`non-static`**版本的**`word2vec`**或者**`GloVe`**要比单纯的`one-hot representation`取得的效果好得多；\n* 为了找到最优的过滤器(Filter)大小，可以使用线性搜索的方法。通常过滤器的大小范围在**`1-10`**之间，当然对于长句，使用更大的过滤器也是有必要的；\n* **`Feature Map`**的数量在**`100-600`**之间；\n* 可以尽量多尝试激活函数，实验发现**`ReLU`**和**`tanh`**两种激活函数表现较佳；\n* 使用简单的**`1-max pooling`**就已经足够了，可以没必要设置太复杂的pooling方式；\n* 当发现增加`Feature Map`的数量使得模型的性能下降时，可以考虑增大正则的力度，如调高`dropout`的概率；\n* 为了检验模型的性能水平，多次反复的交叉验证是必要的，这可以确保模型的高性能并不是偶然。\n\n论文附录中还附上了各种调参结果，感兴趣的可以前往阅读之。\n\n### Kalchbrenner's Paper ###\n\nKal的这篇文章引用次数较高，他提出了一种名为DCNN(Dynamic Convolutional Neural Network)的网络模型，在上一篇（Kim's Paper）中的实验结果部分也验证了这种模型的有效性。这个模型的精妙之处在于Pooling的方式，使用了一种称为**`动态Pooling`**的方法。\n\n下图是这个模型对句子语义建模的过程，可以看到底层通过组合邻近的词语信息，逐步向上传递，上层则又组合新的Phrase信息，从而使得句子中即使相离较远的词语也有交互行为（或者某种语义联系）。从直观上来看，这个模型能够通过词语的组合，提取出句子中重要的语义信息（通过Pooling），某种意义上来说，层次结构的**`feature graph`**的作用类似于一棵语法解析树。\n\n![](http://i.imgur.com/3IbLJX4.png)\n\nDCNN能够处理可变长度的输入，网络中包含两种类型的层，分别是**一维的卷积层**和**动态k-max的池化层(Dynamic k-max pooling)**。其中，动态k-max池化是最大化池化更一般的形式。之前LeCun将CNN的池化操作定义为一种非线性的抽样方式，返回一堆数中的最大值，原话如下：\n\n> The max pooling operator is a non-linear subsampling function that returns the maximum of a set of values (LuCun et al., 1998).\n\n而文中的k-max pooling方式的一般化体现在：\n\n- pooling的结果不是返回一个最大值，而是返回k组最大值，这些最大值是原输入的一个子序列；\n- pooling中的参数k可以是一个动态函数，具体的值依赖于输入或者网络的其他参数；\n\n#### 模型结构及原理 ####\n\nDCNN的网络结构如下图：\n\n![](http://i.imgur.com/CNMa0VL.png)\n\n网络中的卷积层使用了一种称之为**`宽卷积(Wide Convolution)`**的方式，紧接着是动态的k-max池化层。中间卷积层的输出即`Feature Map`的大小会根据输入句子的长度而变化。下面讲解一下这些操作的具体细节：\n\n**1. 宽卷积**\n\n相比于传统的卷积操作，宽卷积的输出的`Feature Map`的宽度(width)会更宽，原因是卷积窗口并不需要覆盖所有的输入值，也可以是部分输入值（可以认为此时其余的输入值为0，即填充0）。如下图所示：\n\n![](http://i.imgur.com/YgM3Tsg.png)\n\n图中的右图即表示宽卷积的计算过程，当计算第一个节点即\\\\( s\\_1 \\\\)时，可以假使\\\\( s\\_1 \\\\)节点前面有四个输入值为0的节点参与卷积（卷积窗口为5）。明显看出，狭义上的卷积输出结果是宽卷积输出结果的一个子集。\n\n**2. k-max池化**\n\n给出数学形式化的表述是，给定一个\\\\( k \\\\)值，和一个序列\\\\( p \\in R^p \\\\)(其中\\\\( p ≥ k \\\\))，`k-max pooling`选择了序列\\\\( p \\\\)中的前\\\\( k \\\\)个最大值，这些最大值保留原来序列的次序（实际上是原序列的一个子序列）。\n\n`k-max pooling`的好处在于，既提取除了句子中的较重要信息（不止一个），同时保留了它们的次序信息（相对位置）。同时，由于应用在最后的卷积层上只需要提取出\\\\( k \\\\)个值，所以这种方法允许不同长度的输入（输入的长度应该要大于\\\\( k \\\\)）。然而，对于中间的卷积层而言，池化的参数\\\\( k \\\\)不是固定的，具体的选择方法见下面的介绍。\n\n**3. 动态k-max池化**\n\n动态k-max池化操作，其中的\\\\( k \\\\)是`输入句子长度`和`网络深度`两个参数的函数，具体如下：\n\n$$ K\\_{l}=\\max \\left( k\\_{top}, \\left \\lceil \\frac {L-l}{L} s \\right \\rceil \\right) $$\n\n其中\\\\( l \\\\)表示当前卷积的层数（即第几个卷积层），\\\\( L \\\\)是网络中总共卷积层的层数；\\\\( k\\_{top} \\\\)为最顶层的卷积层pooling对应的\\\\( k \\\\)值，是一个固定的值。举个例子，例如网络中有三个卷积层，\\\\( k\\_{top} = 3\\\\)，输入的句子长度为18；那么，对于第一层卷积层下面的pooling参数\\\\( k\\_{1} = 12\\\\)，而第二层卷积层对于的为\\\\( k\\_{2} = 6\\\\)，而\\\\( k\\_{3} = k\\_{top} = 3\\\\)。\n\n动态k-max池化的意义在于，从不同长度的句子中提取出相应数量的语义特征信息，以保证后续的卷积层的统一性。\n\n**4. 非线性特征函数**\n\npooling层与下一个卷积层之间，是通过与一些权值参数相乘后，加上某个偏置参数而来的，这与传统的CNN模型是一样的。\n\n**5. 多个Feature Map**\n\n和传统的CNN一样，会提出多个Feature Map以保证提取特征的多样性。\n\n**6. 折叠操作(Folding)**\n\n之前的宽卷积是在输入矩阵\\\\( d × s \\\\)中的每一行内进行计算操作，其中\\\\(d\\\\)是word vector的维数，\\\\(s\\\\)是输入句子的词语数量。而**`Folding`**操作则是考虑相邻的两行之间的某种联系，方式也很简单，就是将两行的vector相加；该操作没有增加参数数量，但是提前（在最后的全连接层之前）考虑了特征矩阵中行与行之间的某种关联。\n\n#### 模型的特点 ####\n\n- 保留了句子中词序信息和词语之间的相对位置；\n- 宽卷积的结果是传统卷积的一个扩展，某种意义上，也是n-gram的一个扩展；\n- 模型不需要任何的先验知识，例如句法依存树等，并且模型考虑了句子中相隔较远的词语之间的语义信息；\n\n#### 实验部分 ####\n\n**1. 模型训练及参数**\n\n- 输出层是一个类别概率分布（即softmax），与倒数第二层全连接；\n- 代价函数为交叉熵，训练目标是最小化代价函数；\n- L2正则化；\n- 优化方法：mini-batch + gradient-based (使用Adagrad update rule, Duchi et al., 2011)\n\n**2. 实验结果**\n\n在三个数据集上进行了实验，分别是(1)电影评论数据集上的情感识别，(2)TREC问题分类，以及(3)Twitter数据集上的情感识别。结果如下图：\n\n![](http://i.imgur.com/zuf2bSu.png)\n\n![](http://i.imgur.com/6lWY7zC.png)\n\n![](http://i.imgur.com/PX9N2JB.png)\n\n可以看出，DCNN的性能非常好，几乎不逊色于传统的模型；而且，DCNN的好处在于不需要任何的先验信息输入，也不需要构造非常复杂的人工特征。\n\n\n### Hu's Paper ###\n\n#### 模型结构与原理 ####\n\n**1. 基于CNN的句子建模**\n\n这篇论文主要针对的是**句子匹配(Sentence Matching)**的问题，但是基础问题仍然是句子建模。首先，文中提出了一种基于CNN的句子建模网络，如下图：\n\n![](http://i.imgur.com/kG7AbW3.png)\n\n图中灰色的部分表示对于长度较短的句子，其后面不足的部分填充的全是0值(Zero Padding)。可以看出，模型解决不同长度句子输入的方法是规定一个最大的可输入句子长度，然后长度不够的部分进行0值的填充；图中的卷积计算和传统的CNN卷积计算无异，而池化则是使用Max-Pooling。\n\n- **卷积结构的分析**\n\n下图示意性地说明了卷积结构的作用，作者认为卷积的作用是**从句子中提取出局部的语义组合信息**，而多张`Feature Map`则是从多种角度进行提取，也就是**保证提取的语义组合的多样性**；而池化的作用是对多种语义组合进行选择，过滤掉一些置信度低的组合（可能这样的组合语义上并无意义）。\n\n![](http://i.imgur.com/yrFS2k1.png)\n\n**2. 基于CNN的句子匹配模型**\n\n下面是基于之前的句子模型，建立的两种用于两个句子的匹配模型。\n\n**2.1 结构I**\n\n模型结构如下图：\n\n![](http://i.imgur.com/xaP0KNV.png)\n\n简单来说，首先分别单独地对两个句子进行建模（使用上文中的句子模型），从而得到两个相同且固定长度的向量，向量表示句子经过建模后抽象得来的特征信息；然后，将这两个向量作为一个多层感知机(MLP)的输入，最后计算匹配的分数。\n\n这个模型比较简单，但是有一个较大的缺点：两个句子在建模过程中是完全独立的，没有任何交互行为，一直到最后生成抽象的向量表示后才有交互行为（一起作为下一个模型的输入），这样做使得句子在抽象建模的过程中会丧失很多语义细节，同时过早地失去了句子间语义交互计算的机会。因此，推出了第二种模型结构。\n\n**2.2 结构II**\n\n模型结构如下图：\n\n![](http://i.imgur.com/NWvAPVr.png)\n\n图中可以看出，这种结构提前了两个句子间的交互行为。\n\n- **第一层卷积层**\n\n第一层中，首先取一个固定的卷积窗口\\\\( k1 \\\\)，然后遍历 \\\\( S\\_{x} \\\\) 和 \\\\( S\\_{y} \\\\) 中所有组合的二维矩阵进行卷积，每一个二维矩阵输出一个值（文中把这个称作为一维卷积，因为实际上是把组合中所有词语的vector排成一行进行的卷积计算），构成Layer-2。下面给出数学形式化表述：\n\n![](http://i.imgur.com/f3DqYsp.png)\n\n- **第一层卷积层后的Max-Pooling层**\n\n从而得到Layer-2，然后进行2×2的Max-pooling：\n\n![](http://i.imgur.com/DaFv3ps.png)\n\n- **后续的卷积层**\n\n后续的卷积层均是传统的二维卷积操作，形式化表述如下：\n\n![](http://i.imgur.com/Pr5Mm9n.png)\n\n- **二维卷积结果后的Pooling层**\n\n与第一层卷积层后的简单Max-Pooling方式不同，后续的卷积层的Pooling是一种**动态Pooling方法**，这种方法来源于参考文献[1]。\n\n- **结构II的性质**\n\n1. 保留了词序信息；\n2. 更具一般性，实际上结构I是结构II的一种特殊情况（取消指定的权值参数）；\n\n#### 实验部分 ####\n\n**1. 模型训练及参数**\n\n- 使用基于排序的自定义损失函数(Ranking-based Loss)\n- BP反向传播+随机梯度下降；\n- mini-batch为100-200,并行化；\n- 为了防止过拟合，对于中型和大型数据集，会提前停止模型训练；而对于小型数据集，还会使用Dropout策略；\n- Word2Vector：50维；英文语料为Wikipedia(~1B words)，中文语料为微博数据(~300M words)；\n- 使用ReLu函数作为激活函数；\n- 卷积窗口为3-word window；\n- 使用Fine tuning；\n\n**2. 实验结果**\n\n一共做了三个实验，分别是(1)句子自动填充任务，(2)推文与评论的匹配，以及(3)同义句识别；结果如下面的图示：\n\n![](http://i.imgur.com/wLIUAHW.png)\n\n![](http://i.imgur.com/fO0Xhnj.png)\n\n![](http://i.imgur.com/qRfsoB0.png)\n\n其实结构I和结构II的结果相差不大，结构II稍好一些；而相比于其他的模型而言，结构I和结构II的优势还是较大的。\n\n\n### He's Paper ###\n\n第四篇论文即He的文章中所提出的模型，是所有基于NN的模型中，在Paraphrase identification任务标准数据集MSRP上效果最佳的。下面我们来学习一下这个模型。\n\n#### 模型结构与原理 ####\n\n模型主要分为两个部分：\n\n- **句子的表征模型**：得到句子的表征(representation)，以供后续的相似度计算；\n- **相似度计算模型**：使用多种相似度计算方法，针对句子表征后的局部进行相应的计算；\n\n模型不需要借助WordNet, 句法解析树等资源；但是可以选择性地使用词性标注、word embedding等方法来增强模型的性能；与之前的模型区别在于，文中的模型使用了多种类型的卷积、池化方法，以及针对得到的句子表征的局部进行相应的相似度计算。（这样做的优点在于能够更加充分地挖掘出句子中的特征信息，从而提升性能，但同时使得模型变得复杂、耗时）\n\n模型的整体框架如下：\n\n![](http://i.imgur.com/uz4z7le.png)\n\n下面具体看看这两个模型是如何实现的。\n\n1. **句子的表征模型**\n\n模型是基于CNN的，卷积层有两种卷积方式，池化层则有三种。\n\n- **卷积层**\n\n假设模型的输入为二维矩阵 \\\\( Sent \\\\)，\\\\( Sent \\in R^{len×Dim} \\\\)，其中 \\\\(len\\\\) 表示句子切分为Token List后的长度(Token可以是词/字)，\\\\(Dim\\\\) 表示Token的Embedding表示的维度。由此有 \\\\(Sent\\_{i}\\\\) 表示矩阵的第 \\\\(i\\\\) 行，即输入中的第 \\\\(i\\\\) 个Token的Embedding表示；\\\\(Sent\\_{i:j}\\\\) 表示矩阵中的第 \\\\(i\\\\) 到第 \\\\(j\\\\) 行的一个切片，也是一个子矩阵；\\\\(Sent\\_{i}^{[k]}\\\\) 表示矩阵的第 \\\\(i\\\\) 行第 \\\\(k\\\\) 列的值，对应是Embedding的第 \\\\(k\\\\) 个值；而 \\\\(Sent\\_{i:j}^{[k]}\\\\) 则是矩阵中第 \\\\(i\\\\) 行到第 \\\\(j\\\\) 行中的第 \\\\(k\\\\) 列的一个切片。\n\n卷积层有两种卷积的方式：(1)粒度为word的卷积;(2)粒度为embedding 维度上的卷积。如下图：\n\n![](http://i.imgur.com/26LDDfD.png)\n\n其中，第一种卷积方式与之前的Kim Y提出模型中的相同，相当于是*n-gram*特征的抽取；而对于第二种卷积方式，论文作者给出的解释是，(1)这种方式有助于充分地提取出输入的特征信息；(2)由于粒度更小，所以在学习过程中的参数调整上，每一个维度能够得到不同程度的参数调整。（第二种卷积方式从直观上没有太多的物理意义，而作者也是直说不能够给出符合人直观想法上的解释）。\n\n- **池化层**\n\n模型除了使用传统的`max-pooling`，还使用了`min-pooling`和`mean-pooling`方式。\n\n假设 \\\\(group(ws, pooling, sent)\\\\) 表示卷积宽度为 \\\\(ws\\\\)，使用 \\\\(pooling\\\\) 池化函数，应用在输入的句子 \\\\(sent\\\\) 上。我们使用了两种类型的**`building block`**，分别是 \\\\(block\\_{A}\\\\) 和 \\\\(block\\_{B}\\\\) 上，定义如下\n\n$$ block\\_{A} = \\lbrace group\\_{A}(ws\\_{a}, p, sent): p \\in {max, min, mean} \\rbrace $$\n\n这里 \\\\(block\\_{A}\\\\) 有三组卷积层，卷积窗口的宽度一致(都是 \\\\(ws\\_{a}\\\\) )，每一组对应一种池化操作。这里池化操作和卷积层是一一对应的，也就是说并不是一个卷积层上实施三种池化操作(虽然也可以这么做，作者没有这么做的原因是由于激活函数的存在，对每个卷积结果都进行`max-pooling`和`min-pooling`是没有必要的)。\n\n而 \\\\(block\\_{B}\\\\) 的定义如下：\n\n$$ block\\_{B} = \\lbrace group\\_{B}(ws\\_{b}, p, sent): p \\in {max, min} \\rbrace $$\n\n这里 \\\\(block\\_{B}\\\\) 有两组卷积层，卷积窗口的宽度为 \\\\(ws\\_{b}\\\\)，两组分别对应`max-pooling`和`min-pooling`的操作。值得说明的是，\\\\(group\\_{B}(*)\\\\) 中的卷积层对应有 \\\\(Dim\\\\) 个以`embedding dimension`为粒度的卷积窗口，也就是对`embedding`的每一维度做卷积运算。\n\n这里只所以要组合这些多样的卷积和池化操作，原因是希望能够从多个方面来提取出输入中的特征信息，以供后续的决策任务。\n\n- **多种窗口尺寸**\n\n与传统的*n-gram*模型相似，这里在**`building block`**中使用了多种尺寸的卷积窗口。如下图所示：\n\n![](http://imgur.com/kRijNVc.png)\n\n其中 \\\\(ws\\\\) 表示卷积时卷积的*n-gram*长度，而 \\\\(ws=\\infty\\\\) 表示卷积窗口为整个`word embedding`矩阵。\\\\(ws\\\\) 的值及`Feature Map` 的数量都是需要调参的。\n\n2. **相似度计算模型**\n\n下面介绍在得到句子的表征向量之后，如何计算它们的相似度。直观的想法是，我们可以使用传统的相似度计算方法如余弦相似度等来计算两个句子向量的相似度。但是，**直接应用这种做法在两个句子向量上并不是最优的**，原因在于最后生成的句子向量中的每一个部分的意义各不相同，这样简单粗暴的计算势必会影响效果，所以做法是**对句子向量中的各个部分进行相应的比较和计算(Structured Comparision)**。为了使得句子向量中的局部间的比较和计算更加有效，我们需要考虑如下方面：\n\n(1) 是否来自相同的`building block`；\n(2) 是否来自相同卷积窗口大小下的卷积结果；\n(3) 是否来自相同的`pooling层`；\n(4) 是否来自相同的`Feature Map`；\n\n最终比较句子中的相应部分时，需要至少满足以上两个条件。为了识别句子中的哪些对应部分需要参与到相似度计算，文中提供了两种算法。\n\n2.1. **相似度计算单元(Unit)** \n\n两种相似度计算单元如下：\n\n![](http://imgur.com/wttqwKe.png)\n\n\n2.2. **基于句子局部的相似度计算**\n\n算法1和算法2为句子表征向量的两种计算方法，其中算法1仅用在 \\\\(block\\_{A}\\\\) 上；而算法2则都用在 \\\\(block\\_{A}\\\\) 和 \\\\(block\\_{B}\\\\) 上，两种算法都是针对相同类型(pooling和block类型)的输出做局部比较。\n\n给出如下的符号假设：\n\n![](http://imgur.com/0Oxsp9O.png)\n\n算法的伪代码如下：\n\n![](http://imgur.com/pkDPaky.png)\n\n下面的图示说明了在 \\\\(block\\_{A}\\\\) 上，两种算法的计算方式的区别，算法一表现了向量在水平方向上的比较；而算法二则是在垂直方向。\n\n![](http://imgur.com/f4qrseS.png)\n\n需要注意的是，在算法二中相同类型的pooling的输出groups中，向量是两两进行比较的（图中的红色虚线只是为了说明比较的方向，并不是只针对group中相同大小的卷积窗口作比较）；而算法一中的每一行都要作比较，不仅仅是第一行。\n\n3. **模型的其他细节**\n\n- **相似度向量输出 + 全连接层**\n\n基于句子局部的相似度计算之后，得到相应的相似度向量；然后这组向量之后连接一个全连接层，最后softmax对应输出。如果是计算相似度度量值，可以用softmax输出的类别概率值。\n\n- **激活函数**\n\n使用`tanh`函数作为激活函数。\n\n#### 实验部分 ####\n\n1. **实验数据集**\n\n- [Microsoft Research Paraphrase Corpus (MSRP)](http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/)\n\n用于评测同义句检测 (Paraphrase Identification) 任务的经典数据集，数据集来源于新闻；包含5801对句子对，其中4076对用于模型训练，而1725对用于测试；每一对句子拥有一个标签，0或者1,0表示两个句子不是互为同义句，而1则表示两个句子互为同义句。因此这是一个二分类的任务。\n\n- [Sentences Involving Compositional Knowledge (SICK)](http://alt.qcri.org/semeval2014/task1/index.php?id=data-and-tools)\n\n数据来源于2014年SemEval比赛，数据集有9927对句子对，其中4500对用于模型训练，500对用于模型验证，而剩下的4927对用于模型测试。这些句子都是在图片和视频描述中抽取得到的，每一对句子对有一个相关分数，区间在[1, 5]，分数越高表示句子越相关。\n\n- [Microsoft Video Paraphrase Corpus (MSRVID)](https://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/train-readme.txt)\n\n数据集来源于2012年的SemEval比赛，包含1500对短文本（用于描述视频信息）。其中一般用于模型训练，一半用于模型测试，每一对句子有一个相关性分数，区间在[0, 5]，分数越高表示句子越相关。\n\n2. **模型训练**\n\n针对MSRP和其他两个数据集，分别使用两种损失函数。对于MSRP数据集，损失函数（Hinge Loss）如下：\n\n![](http://imgur.com/jjQu3pY.png)\n\n对于其余两个数据集，损失函数（KL-divergence Loss）如下：\n\n![](http://imgur.com/kfVigMW.png)\n\n3. **实验参数设置**\n\n- **\\\\(ws\\\\) 的值**：\\\\(ws \\in [1, 3]\\\\)和 \\\\(ws=\\infty\\\\).\n- **Word Embedding**: 300维的`GloVe word embedding`；对于MSRP数据集，还额外使用了200维的`POS embedding` ([Standford POS tagger](http://nlp.stanford.edu/software/tagger.shtml))和25维的`Paragram Vectors` ([Wieting et al., 2015 PDF](http://ttic.uchicago.edu/~wieting/wieting2015TACL.pdf)，[数据下载地址](http://ttic.uchicago.edu/~wieting/paragram_vectors.txt))。因此对于MSRP任务而言，`word embedding`的维数为525维 (200+300+25)；而其余两个任务则对应是300维。\n- 在MSRP上使用了**5-折交叉验证**的方式，对模型参数进行*tuning*. *Tuning*好的模型参数将会用在另外两个数据集任务上。\n- 只有在MSRP数据集任务上，允许模型参数进行更新。\n- 输出的全连接层，MSRP有250个神经元节点，而SICK和MSRVID则是150个。\n- 在 \\\\(block\\_{A}\\\\) 中，`Feature Map` 的数量与输入的`embedding`维数相同，即MSRP是525个，而SICK和MSRVID则是300个。\n- 优化算法使用随机梯度下降方法。\n- 学习率为0.01，而正则化参数 \\\\(\\lambda=10^{-4}\\\\).\n\n4. **实验结果**\n\n- **MSRP数据集**\n\n![](http://imgur.com/CLF0SKJ.png)\n\n可以看出，文中的模型是所有基于NN的方法中在MSRP数据集上性能最好的。\n\n- **SICK数据集**\n\n![](http://imgur.com/16bJWHS.png)\n\n- **MSRVID数据集**\n\n![](http://imgur.com/s89LYEb.png)\n\n而模型在SICK和MSRVID数据集上的表现也很好。\n\n5. **模型的敏感度分析**\n\n下面的表格说明了在不使用某种技术下，模型性能在实验数据集上的变化情况。\n\n![](http://imgur.com/pmTY9TY.png)\n\n从中可以得出以下结论：\n\n- 对于MSRP数据集任务而言，增加**`POS Embedding`**和**`Paragram Vector`**效果显著；\n- 移除相似度计算层的影响显著，说明结构化的句子局部比较方法是有效且必要的；\n- **`Horizontal`**和**`Vertical`**算法均有一定的提升效果，而**`Vertical`**算法的提升程度更高；\n- **`max-pooling`**方式确实要比**`min-pooling`**和**`mean-pooling`**强太多。\n\n5. **总结**\n\n文中的模型包含两个部分：卷积-池化模型和相似度计算模型。实验部分已经验证了模型的有效性，在MSRP数据集上模型取得了仅次于state-of-art的结果，并且在基于NN的方法中是最好的。模型中的相似度计算层是有必要的，因为对卷积池化处理后的句子成分进行了针对性的比较，从直观上要比直接扔进全连接层更合理，而实验结果也表明了这一点。\n\n然而，个人觉得，文中的模型结构较为复杂，而且其中有很多trick的地方，比如为什么要对word embedding中的每一维度做卷积，\\\\(block\\_{B}\\\\) 中的`pooling`方式为什么只用了max和min，不用mean的方式等问题，而这些方式或许是作者自己做了大量实验后，从果到因而使用的。\n\n### Yin's Paper ###\n\nYin的这篇论文提出了一种叫`Bi-CNN-MI`的架构，其中`Bi-CNN`表示两个使用`Siamese`框架的CNN模型；`MI`表示多粒度的交互特征。`Bi-CNN-MI`包含三个部分：\n\n* **句子分析模型 (CNN-SM)**\n\n这部分模型主要使用了上述Kal在2014年提出的模型，针对句子本身提取出四种粒度的特征表示：词、短*ngram*、长*ngram*和句子粒度。多种粒度的特征表示是非常必要的，一方面提高模型的性能，另一方面增强模型的鲁棒性。\n\n* **句子交互计算模型 (CNN-IM)**\n\n这部分模型主要是基于2011年Socher提出的RAE模型，做了一些简化，即仅对同一种粒度下的提取特征做两两比较。\n\n* **LR或Softmax网络层以适配任务**\n\n#### 模型结构 ####\n\n论文提出的模型主要是基于Kal的模型及Socher的RAE模型的结合体，如下图：\n\n![](http://imgur.com/Ubku2XR.png)\n\n通过模型图可以看出模型的主要思想：一方面利用Kal的模型进行多种粒度上的特征提取，另一方面采取RAE模型的思想，对提取出来的特征进行两两的相似度计算，计算完成的结果通过`dynamic pooling`的方式进一步提取少量特征，然后各个层次的`pooling`计算结果平摊为一组向量，通过全连接的方式与LR(或者softmax)层连接，从而适配同义句检测任务本身。\n\n这个模型具体的计算细节不再赘述了，感兴趣的读者可以直接去看论文。除了提出这种模型结构之外，论文还有一个亮点在于使用了一种类似于语言模型的`CNN-LM`来对上述CNN部分的模型进行预训练，从而提前确定模型的参数。`CNN-LM`的网络结构如下图：\n\n![](http://imgur.com/zMyzscM.png)\n\n`CNN-LM`模型的训练预料使用了最终的实验数据集，即MSRP；另外，由于MSRP的数据规模较小，所以作者又增加了100,000个英文句子语料。`CNN-LM`模型最终能够得到word embedding, 模型权值等参数。需要注意的是，这些参数并不是固定的，在之后的句子匹配任务中是会不断更新的。从后面的实验结果中可以看出，`CNN-LM`的作用是显著的。\n\n#### 实验结果 ####\n\n论文仅使用了一种数据集，即公认的PI (Paraphrase Identification)任务数据集，MSRP。实验结果如下：\n\n![](http://imgur.com/Y67eY0a.png)\n\n可以看出，`CNN-LM`的预训练效果显著，预训练后的模型性能很强（但是结果上比之前He提出的模型稍差一些）。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html\n\n**参考文献**\n\n[1] R. Socher, E. H. Huang, and A. Y. Ng. Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In Advances in NIPS, 2011.\n\n**推荐资料**\n\n[A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification](http://arxiv.org/abs/1510.03820)\n\n[Implementing a CNN for Text Classification in TensorFlow](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)\n\n[Kim Y's Implement: Convolutional Neural Networks for Sentence Classification](https://github.com/yoonkim/CNN_sentence)\n\n\n\n","source":"_posts/cnn-apply-on-modelling-sentence.md","raw":"title: 卷积神经网络(CNN)在句子建模上的应用\ndate: 2016-03-11 10:36:35\ntags: [Machine Learning, Deep Learning, CNN, Sentence Model, NLP]\ncategories: Machine Learning\n---\n\n之前的博文已经介绍了CNN的基本原理，本文将大概总结一下最近CNN在NLP中的句子建模（或者句子表示）方面的应用情况，主要阅读了以下的文献：\n\n> Kim Y. Convolutional neural networks for sentence classification[J]. arXiv preprint arXiv:1408.5882, 2014.\n\n> Kalchbrenner N, Grefenstette E, Blunsom P. A convolutional neural network for modelling sentences[J]. arXiv preprint arXiv:1404.2188, 2014.\n\n> Hu B, Lu Z, Li H, et al. Convolutional neural network architectures for matching natural language sentences[C]//Advances in Neural Information Processing Systems. 2014: 2042-2050.\n\n> He H, Gimpel K, Lin J. Multi-perspective sentence similarity modeling with convolutional neural networks[C]//Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015: 1576-1586.\n\n> Wenpeng Yin, Hinrich Schütze. Convolutional Neural Network for Paraphrase Identification. The 2015 Conference of the North American Chapter of the Association for Computational Linguistics\n\n> Zhang Y, Wallace B. A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification[J]. arXiv preprint arXiv:1510.03820, 2015.\n\n下面对文献中CNN的结构和细节进行梳理。\n\n----------\n\n### Kim Y's Paper ###\n\n#### 模型结构及原理 ####\n\n模型的结构如下：\n\n![](http://i.imgur.com/yxoZDt9.png)\n\n说明如下：\n\n- **输入层**\n\n如图所示，输入层是句子中的词语对应的word vector依次（从上到下）排列的矩阵，假设句子有 \\\\( n \\\\) 个词，vector的维数为 \\\\( k \\\\) ，那么这个矩阵就是 \\\\( n × k \\\\) 的。\n\n这个矩阵的类型可以是静态的(static)，也可以是动态的(non static)。静态就是word vector是固定不变的，而动态则是在模型训练过程中，word vector也当做是可优化的参数，通常把反向误差传播导致word vector中值发生变化的这一过程称为**`Fine tune`**。\n\n对于未登录词的vector，可以用0或者随机小的正数来填充。\n\n- **第一层卷积层**\n\n输入层通过卷积操作得到若干个`Feature Map`，卷积窗口的大小为 \\\\( h × k \\\\) ，其中 \\\\( h \\\\) 表示纵向词语的个数，而 \\\\( k \\\\) 表示word vector的维数。通过这样一个大型的卷积窗口，将得到若干个列数为1的`Feature Map`。\n\n- **池化层**\n\n接下来的池化层，文中用了一种称为**`Max-over-time Pooling`**的方法。这种方法就是简单地从之前一维的`Feature Map`中提出最大的值，文中解释最大值代表着最重要的信号。可以看出，这种Pooling方式可以解决可变长度的句子输入问题（因为不管`Feature Map`中有多少个值，只需要提取其中的最大值）。\n\n最终池化层的输出为各个`Feature Map`的最大值们，即一个一维的向量。\n\n- **全连接 + Softmax层**\n\n池化层的一维向量的输出通过全连接的方式，连接一个Softmax层，Softmax层可根据任务的需要设置（通常反映着最终类别上的概率分布）。\n\n最终实现时，我们可以在倒数第二层的全连接部分上使用`Dropout`技术，即对全连接层上的权值参数给予**`L2正则化`**的限制。这样做的好处是防止隐藏层单元自适应（或者对称），从而减轻过拟合的程度。\n\n#### 实验部分 ####\n\n**1. 数据**\n\n实验用到的数据集如下（具体的名称和来源可以参考论文）：\n\n![](http://i.imgur.com/8VDJDDJ.png)\n\n**2. 模型训练和调参**\n\n- 修正线性单元(Rectified linear units)\n- 滤波器的h大小：3,4,5；对应的Feature Map的数量为100；\n- Dropout率为0.5，L2正则化限制权值大小不超过3；\n- mini-batch的大小为50；\n\n这些参数的选择都是基于SST-2 dev数据集，通过网格搜索方法(Grid Search)得到的最优参数。另外，训练过程中采用随机梯度下降方法，基于shuffled mini-batches之上的，使用了Adadelta update rule(Zeiler, 2012)。\n\n**3. 预训练的Word Vector**\n\n这里的word vector使用的是公开的数据，即连续词袋模型(COW)在Google News上的训练结果。未登录次的vector值是随机初始化的。\n\n**4. 实验结果**\n\n实验结果如下图：\n\n![](http://i.imgur.com/sNpll24.png)\n\n其中，前四个模型是上文中所提出的基本模型的各个变种：\n\n- **CNN-rand**: 所有的word vector都是随机初始化的，同时当做训练过程中优化的参数；\n- **CNN-static**: 所有的word vector直接使用无监督学习即Google的Word2Vector工具(COW模型)得到的结果，并且是固定不变的；\n- **CNN-non-static**: 所有的word vector直接使用无监督学习即Google的Word2Vector工具(COW模型)得到的结果，但是会在训练过程中被`Fine tuned`；\n- **CNN-multichannel**: CNN-static和CNN-non-static的混合版本，即两种类型的输入；\n\n博主自己下载了论文作者的实现程序([**Github地址**](https://github.com/yoonkim/CNN_sentence))，最终在MR数据集上的运行结果如下：\n\n- CNN-rand: 0.7669\n- CNN-static: 0.8076\n- CNN-non-static: 0.8151\n\n和论文中的结果差不多。\n\n**5. 结论**\n\n- **`CNN-static`**较与**`CNN-rand`**好，**说明pre-training的word vector确实有较大的提升作用**（这也难怪，因为pre-training的word vector显然利用了更大规模的文本数据信息）；\n- **`CNN-non-static`**较于**`CNN-static`**大部分要好，**说明适当的Fine tune也是有利的，是因为使得vectors更加贴近于具体的任务**；\n- **`CNN-multichannel`**较于**`CNN-single`**在小规模的数据集上有更好的表现，实际上**`CNN-multichannel`**体现了一种折中思想，即既不希望Fine tuned的vector距离原始值太远，但同时保留其一定的变化空间。\n\n值得注意的是，static的vector和non-static的相比，有一些有意思的现象如下表格：\n\n![](http://i.imgur.com/fW6pr0p.png)\n\n- 原始的word2vector训练结果中，`bad`对应的最相近词为`good`，原因是这两个词在句法上的使用是极其类似的（可以简单替换，不会出现语句毛病）；而在`non-static`的版本中，`bad`对应的最相近词为`terrible`，这是因为在`Fune tune`的过程中，vector的值发生改变从而更加贴切数据集（是一个情感分类的数据集），所以在情感表达的角度这两个词会更加接近；\n- 句子中的**`!`**最接近一些表达形式较为激进的词汇，如`lush`等；而**`,`**则接近于一些连接词，这和我们的主观感受也是相符的。\n\nKim Y的这个模型很简单，但是却有着很好的性能。后续Denny用TensorFlow实现了这个模型的简单版本，可参考**[这篇博文](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)**；以及Ye Zhang等人对这个模型进行了大量的实验，并给出了调参的建议，可参考**[这篇论文](http://arxiv.org/abs/1510.03820)**。\n\n下面总结一下Ye Zhang等人基于Kim Y的模型做了大量的调参实验之后的结论：\n\n* 由于模型训练过程中的随机性因素，如随机初始化的权重参数，mini-batch，随机梯度下降优化算法等，造成模型在数据集上的结果有一定的浮动，如准确率(accuracy)能达到1.5%的浮动，而AUC则有3.4%的浮动；\n* 词向量是使用word2vec还是GloVe，对实验结果有一定的影响，具体哪个更好依赖于任务本身；\n* Filter的大小对模型性能有较大的影响，并且Filter的参数应该是可以更新的；\n* Feature Map的数量也有一定影响，但是需要兼顾模型的训练效率；\n* 1-max pooling的方式已经足够好了，相比于其他的pooling方式而言；\n* 正则化的作用微乎其微。\n\nYe Zhang等人给予模型调参者的建议如下：\n\n* 使用**`non-static`**版本的**`word2vec`**或者**`GloVe`**要比单纯的`one-hot representation`取得的效果好得多；\n* 为了找到最优的过滤器(Filter)大小，可以使用线性搜索的方法。通常过滤器的大小范围在**`1-10`**之间，当然对于长句，使用更大的过滤器也是有必要的；\n* **`Feature Map`**的数量在**`100-600`**之间；\n* 可以尽量多尝试激活函数，实验发现**`ReLU`**和**`tanh`**两种激活函数表现较佳；\n* 使用简单的**`1-max pooling`**就已经足够了，可以没必要设置太复杂的pooling方式；\n* 当发现增加`Feature Map`的数量使得模型的性能下降时，可以考虑增大正则的力度，如调高`dropout`的概率；\n* 为了检验模型的性能水平，多次反复的交叉验证是必要的，这可以确保模型的高性能并不是偶然。\n\n论文附录中还附上了各种调参结果，感兴趣的可以前往阅读之。\n\n### Kalchbrenner's Paper ###\n\nKal的这篇文章引用次数较高，他提出了一种名为DCNN(Dynamic Convolutional Neural Network)的网络模型，在上一篇（Kim's Paper）中的实验结果部分也验证了这种模型的有效性。这个模型的精妙之处在于Pooling的方式，使用了一种称为**`动态Pooling`**的方法。\n\n下图是这个模型对句子语义建模的过程，可以看到底层通过组合邻近的词语信息，逐步向上传递，上层则又组合新的Phrase信息，从而使得句子中即使相离较远的词语也有交互行为（或者某种语义联系）。从直观上来看，这个模型能够通过词语的组合，提取出句子中重要的语义信息（通过Pooling），某种意义上来说，层次结构的**`feature graph`**的作用类似于一棵语法解析树。\n\n![](http://i.imgur.com/3IbLJX4.png)\n\nDCNN能够处理可变长度的输入，网络中包含两种类型的层，分别是**一维的卷积层**和**动态k-max的池化层(Dynamic k-max pooling)**。其中，动态k-max池化是最大化池化更一般的形式。之前LeCun将CNN的池化操作定义为一种非线性的抽样方式，返回一堆数中的最大值，原话如下：\n\n> The max pooling operator is a non-linear subsampling function that returns the maximum of a set of values (LuCun et al., 1998).\n\n而文中的k-max pooling方式的一般化体现在：\n\n- pooling的结果不是返回一个最大值，而是返回k组最大值，这些最大值是原输入的一个子序列；\n- pooling中的参数k可以是一个动态函数，具体的值依赖于输入或者网络的其他参数；\n\n#### 模型结构及原理 ####\n\nDCNN的网络结构如下图：\n\n![](http://i.imgur.com/CNMa0VL.png)\n\n网络中的卷积层使用了一种称之为**`宽卷积(Wide Convolution)`**的方式，紧接着是动态的k-max池化层。中间卷积层的输出即`Feature Map`的大小会根据输入句子的长度而变化。下面讲解一下这些操作的具体细节：\n\n**1. 宽卷积**\n\n相比于传统的卷积操作，宽卷积的输出的`Feature Map`的宽度(width)会更宽，原因是卷积窗口并不需要覆盖所有的输入值，也可以是部分输入值（可以认为此时其余的输入值为0，即填充0）。如下图所示：\n\n![](http://i.imgur.com/YgM3Tsg.png)\n\n图中的右图即表示宽卷积的计算过程，当计算第一个节点即\\\\( s\\_1 \\\\)时，可以假使\\\\( s\\_1 \\\\)节点前面有四个输入值为0的节点参与卷积（卷积窗口为5）。明显看出，狭义上的卷积输出结果是宽卷积输出结果的一个子集。\n\n**2. k-max池化**\n\n给出数学形式化的表述是，给定一个\\\\( k \\\\)值，和一个序列\\\\( p \\in R^p \\\\)(其中\\\\( p ≥ k \\\\))，`k-max pooling`选择了序列\\\\( p \\\\)中的前\\\\( k \\\\)个最大值，这些最大值保留原来序列的次序（实际上是原序列的一个子序列）。\n\n`k-max pooling`的好处在于，既提取除了句子中的较重要信息（不止一个），同时保留了它们的次序信息（相对位置）。同时，由于应用在最后的卷积层上只需要提取出\\\\( k \\\\)个值，所以这种方法允许不同长度的输入（输入的长度应该要大于\\\\( k \\\\)）。然而，对于中间的卷积层而言，池化的参数\\\\( k \\\\)不是固定的，具体的选择方法见下面的介绍。\n\n**3. 动态k-max池化**\n\n动态k-max池化操作，其中的\\\\( k \\\\)是`输入句子长度`和`网络深度`两个参数的函数，具体如下：\n\n$$ K\\_{l}=\\max \\left( k\\_{top}, \\left \\lceil \\frac {L-l}{L} s \\right \\rceil \\right) $$\n\n其中\\\\( l \\\\)表示当前卷积的层数（即第几个卷积层），\\\\( L \\\\)是网络中总共卷积层的层数；\\\\( k\\_{top} \\\\)为最顶层的卷积层pooling对应的\\\\( k \\\\)值，是一个固定的值。举个例子，例如网络中有三个卷积层，\\\\( k\\_{top} = 3\\\\)，输入的句子长度为18；那么，对于第一层卷积层下面的pooling参数\\\\( k\\_{1} = 12\\\\)，而第二层卷积层对于的为\\\\( k\\_{2} = 6\\\\)，而\\\\( k\\_{3} = k\\_{top} = 3\\\\)。\n\n动态k-max池化的意义在于，从不同长度的句子中提取出相应数量的语义特征信息，以保证后续的卷积层的统一性。\n\n**4. 非线性特征函数**\n\npooling层与下一个卷积层之间，是通过与一些权值参数相乘后，加上某个偏置参数而来的，这与传统的CNN模型是一样的。\n\n**5. 多个Feature Map**\n\n和传统的CNN一样，会提出多个Feature Map以保证提取特征的多样性。\n\n**6. 折叠操作(Folding)**\n\n之前的宽卷积是在输入矩阵\\\\( d × s \\\\)中的每一行内进行计算操作，其中\\\\(d\\\\)是word vector的维数，\\\\(s\\\\)是输入句子的词语数量。而**`Folding`**操作则是考虑相邻的两行之间的某种联系，方式也很简单，就是将两行的vector相加；该操作没有增加参数数量，但是提前（在最后的全连接层之前）考虑了特征矩阵中行与行之间的某种关联。\n\n#### 模型的特点 ####\n\n- 保留了句子中词序信息和词语之间的相对位置；\n- 宽卷积的结果是传统卷积的一个扩展，某种意义上，也是n-gram的一个扩展；\n- 模型不需要任何的先验知识，例如句法依存树等，并且模型考虑了句子中相隔较远的词语之间的语义信息；\n\n#### 实验部分 ####\n\n**1. 模型训练及参数**\n\n- 输出层是一个类别概率分布（即softmax），与倒数第二层全连接；\n- 代价函数为交叉熵，训练目标是最小化代价函数；\n- L2正则化；\n- 优化方法：mini-batch + gradient-based (使用Adagrad update rule, Duchi et al., 2011)\n\n**2. 实验结果**\n\n在三个数据集上进行了实验，分别是(1)电影评论数据集上的情感识别，(2)TREC问题分类，以及(3)Twitter数据集上的情感识别。结果如下图：\n\n![](http://i.imgur.com/zuf2bSu.png)\n\n![](http://i.imgur.com/6lWY7zC.png)\n\n![](http://i.imgur.com/PX9N2JB.png)\n\n可以看出，DCNN的性能非常好，几乎不逊色于传统的模型；而且，DCNN的好处在于不需要任何的先验信息输入，也不需要构造非常复杂的人工特征。\n\n\n### Hu's Paper ###\n\n#### 模型结构与原理 ####\n\n**1. 基于CNN的句子建模**\n\n这篇论文主要针对的是**句子匹配(Sentence Matching)**的问题，但是基础问题仍然是句子建模。首先，文中提出了一种基于CNN的句子建模网络，如下图：\n\n![](http://i.imgur.com/kG7AbW3.png)\n\n图中灰色的部分表示对于长度较短的句子，其后面不足的部分填充的全是0值(Zero Padding)。可以看出，模型解决不同长度句子输入的方法是规定一个最大的可输入句子长度，然后长度不够的部分进行0值的填充；图中的卷积计算和传统的CNN卷积计算无异，而池化则是使用Max-Pooling。\n\n- **卷积结构的分析**\n\n下图示意性地说明了卷积结构的作用，作者认为卷积的作用是**从句子中提取出局部的语义组合信息**，而多张`Feature Map`则是从多种角度进行提取，也就是**保证提取的语义组合的多样性**；而池化的作用是对多种语义组合进行选择，过滤掉一些置信度低的组合（可能这样的组合语义上并无意义）。\n\n![](http://i.imgur.com/yrFS2k1.png)\n\n**2. 基于CNN的句子匹配模型**\n\n下面是基于之前的句子模型，建立的两种用于两个句子的匹配模型。\n\n**2.1 结构I**\n\n模型结构如下图：\n\n![](http://i.imgur.com/xaP0KNV.png)\n\n简单来说，首先分别单独地对两个句子进行建模（使用上文中的句子模型），从而得到两个相同且固定长度的向量，向量表示句子经过建模后抽象得来的特征信息；然后，将这两个向量作为一个多层感知机(MLP)的输入，最后计算匹配的分数。\n\n这个模型比较简单，但是有一个较大的缺点：两个句子在建模过程中是完全独立的，没有任何交互行为，一直到最后生成抽象的向量表示后才有交互行为（一起作为下一个模型的输入），这样做使得句子在抽象建模的过程中会丧失很多语义细节，同时过早地失去了句子间语义交互计算的机会。因此，推出了第二种模型结构。\n\n**2.2 结构II**\n\n模型结构如下图：\n\n![](http://i.imgur.com/NWvAPVr.png)\n\n图中可以看出，这种结构提前了两个句子间的交互行为。\n\n- **第一层卷积层**\n\n第一层中，首先取一个固定的卷积窗口\\\\( k1 \\\\)，然后遍历 \\\\( S\\_{x} \\\\) 和 \\\\( S\\_{y} \\\\) 中所有组合的二维矩阵进行卷积，每一个二维矩阵输出一个值（文中把这个称作为一维卷积，因为实际上是把组合中所有词语的vector排成一行进行的卷积计算），构成Layer-2。下面给出数学形式化表述：\n\n![](http://i.imgur.com/f3DqYsp.png)\n\n- **第一层卷积层后的Max-Pooling层**\n\n从而得到Layer-2，然后进行2×2的Max-pooling：\n\n![](http://i.imgur.com/DaFv3ps.png)\n\n- **后续的卷积层**\n\n后续的卷积层均是传统的二维卷积操作，形式化表述如下：\n\n![](http://i.imgur.com/Pr5Mm9n.png)\n\n- **二维卷积结果后的Pooling层**\n\n与第一层卷积层后的简单Max-Pooling方式不同，后续的卷积层的Pooling是一种**动态Pooling方法**，这种方法来源于参考文献[1]。\n\n- **结构II的性质**\n\n1. 保留了词序信息；\n2. 更具一般性，实际上结构I是结构II的一种特殊情况（取消指定的权值参数）；\n\n#### 实验部分 ####\n\n**1. 模型训练及参数**\n\n- 使用基于排序的自定义损失函数(Ranking-based Loss)\n- BP反向传播+随机梯度下降；\n- mini-batch为100-200,并行化；\n- 为了防止过拟合，对于中型和大型数据集，会提前停止模型训练；而对于小型数据集，还会使用Dropout策略；\n- Word2Vector：50维；英文语料为Wikipedia(~1B words)，中文语料为微博数据(~300M words)；\n- 使用ReLu函数作为激活函数；\n- 卷积窗口为3-word window；\n- 使用Fine tuning；\n\n**2. 实验结果**\n\n一共做了三个实验，分别是(1)句子自动填充任务，(2)推文与评论的匹配，以及(3)同义句识别；结果如下面的图示：\n\n![](http://i.imgur.com/wLIUAHW.png)\n\n![](http://i.imgur.com/fO0Xhnj.png)\n\n![](http://i.imgur.com/qRfsoB0.png)\n\n其实结构I和结构II的结果相差不大，结构II稍好一些；而相比于其他的模型而言，结构I和结构II的优势还是较大的。\n\n\n### He's Paper ###\n\n第四篇论文即He的文章中所提出的模型，是所有基于NN的模型中，在Paraphrase identification任务标准数据集MSRP上效果最佳的。下面我们来学习一下这个模型。\n\n#### 模型结构与原理 ####\n\n模型主要分为两个部分：\n\n- **句子的表征模型**：得到句子的表征(representation)，以供后续的相似度计算；\n- **相似度计算模型**：使用多种相似度计算方法，针对句子表征后的局部进行相应的计算；\n\n模型不需要借助WordNet, 句法解析树等资源；但是可以选择性地使用词性标注、word embedding等方法来增强模型的性能；与之前的模型区别在于，文中的模型使用了多种类型的卷积、池化方法，以及针对得到的句子表征的局部进行相应的相似度计算。（这样做的优点在于能够更加充分地挖掘出句子中的特征信息，从而提升性能，但同时使得模型变得复杂、耗时）\n\n模型的整体框架如下：\n\n![](http://i.imgur.com/uz4z7le.png)\n\n下面具体看看这两个模型是如何实现的。\n\n1. **句子的表征模型**\n\n模型是基于CNN的，卷积层有两种卷积方式，池化层则有三种。\n\n- **卷积层**\n\n假设模型的输入为二维矩阵 \\\\( Sent \\\\)，\\\\( Sent \\in R^{len×Dim} \\\\)，其中 \\\\(len\\\\) 表示句子切分为Token List后的长度(Token可以是词/字)，\\\\(Dim\\\\) 表示Token的Embedding表示的维度。由此有 \\\\(Sent\\_{i}\\\\) 表示矩阵的第 \\\\(i\\\\) 行，即输入中的第 \\\\(i\\\\) 个Token的Embedding表示；\\\\(Sent\\_{i:j}\\\\) 表示矩阵中的第 \\\\(i\\\\) 到第 \\\\(j\\\\) 行的一个切片，也是一个子矩阵；\\\\(Sent\\_{i}^{[k]}\\\\) 表示矩阵的第 \\\\(i\\\\) 行第 \\\\(k\\\\) 列的值，对应是Embedding的第 \\\\(k\\\\) 个值；而 \\\\(Sent\\_{i:j}^{[k]}\\\\) 则是矩阵中第 \\\\(i\\\\) 行到第 \\\\(j\\\\) 行中的第 \\\\(k\\\\) 列的一个切片。\n\n卷积层有两种卷积的方式：(1)粒度为word的卷积;(2)粒度为embedding 维度上的卷积。如下图：\n\n![](http://i.imgur.com/26LDDfD.png)\n\n其中，第一种卷积方式与之前的Kim Y提出模型中的相同，相当于是*n-gram*特征的抽取；而对于第二种卷积方式，论文作者给出的解释是，(1)这种方式有助于充分地提取出输入的特征信息；(2)由于粒度更小，所以在学习过程中的参数调整上，每一个维度能够得到不同程度的参数调整。（第二种卷积方式从直观上没有太多的物理意义，而作者也是直说不能够给出符合人直观想法上的解释）。\n\n- **池化层**\n\n模型除了使用传统的`max-pooling`，还使用了`min-pooling`和`mean-pooling`方式。\n\n假设 \\\\(group(ws, pooling, sent)\\\\) 表示卷积宽度为 \\\\(ws\\\\)，使用 \\\\(pooling\\\\) 池化函数，应用在输入的句子 \\\\(sent\\\\) 上。我们使用了两种类型的**`building block`**，分别是 \\\\(block\\_{A}\\\\) 和 \\\\(block\\_{B}\\\\) 上，定义如下\n\n$$ block\\_{A} = \\lbrace group\\_{A}(ws\\_{a}, p, sent): p \\in {max, min, mean} \\rbrace $$\n\n这里 \\\\(block\\_{A}\\\\) 有三组卷积层，卷积窗口的宽度一致(都是 \\\\(ws\\_{a}\\\\) )，每一组对应一种池化操作。这里池化操作和卷积层是一一对应的，也就是说并不是一个卷积层上实施三种池化操作(虽然也可以这么做，作者没有这么做的原因是由于激活函数的存在，对每个卷积结果都进行`max-pooling`和`min-pooling`是没有必要的)。\n\n而 \\\\(block\\_{B}\\\\) 的定义如下：\n\n$$ block\\_{B} = \\lbrace group\\_{B}(ws\\_{b}, p, sent): p \\in {max, min} \\rbrace $$\n\n这里 \\\\(block\\_{B}\\\\) 有两组卷积层，卷积窗口的宽度为 \\\\(ws\\_{b}\\\\)，两组分别对应`max-pooling`和`min-pooling`的操作。值得说明的是，\\\\(group\\_{B}(*)\\\\) 中的卷积层对应有 \\\\(Dim\\\\) 个以`embedding dimension`为粒度的卷积窗口，也就是对`embedding`的每一维度做卷积运算。\n\n这里只所以要组合这些多样的卷积和池化操作，原因是希望能够从多个方面来提取出输入中的特征信息，以供后续的决策任务。\n\n- **多种窗口尺寸**\n\n与传统的*n-gram*模型相似，这里在**`building block`**中使用了多种尺寸的卷积窗口。如下图所示：\n\n![](http://imgur.com/kRijNVc.png)\n\n其中 \\\\(ws\\\\) 表示卷积时卷积的*n-gram*长度，而 \\\\(ws=\\infty\\\\) 表示卷积窗口为整个`word embedding`矩阵。\\\\(ws\\\\) 的值及`Feature Map` 的数量都是需要调参的。\n\n2. **相似度计算模型**\n\n下面介绍在得到句子的表征向量之后，如何计算它们的相似度。直观的想法是，我们可以使用传统的相似度计算方法如余弦相似度等来计算两个句子向量的相似度。但是，**直接应用这种做法在两个句子向量上并不是最优的**，原因在于最后生成的句子向量中的每一个部分的意义各不相同，这样简单粗暴的计算势必会影响效果，所以做法是**对句子向量中的各个部分进行相应的比较和计算(Structured Comparision)**。为了使得句子向量中的局部间的比较和计算更加有效，我们需要考虑如下方面：\n\n(1) 是否来自相同的`building block`；\n(2) 是否来自相同卷积窗口大小下的卷积结果；\n(3) 是否来自相同的`pooling层`；\n(4) 是否来自相同的`Feature Map`；\n\n最终比较句子中的相应部分时，需要至少满足以上两个条件。为了识别句子中的哪些对应部分需要参与到相似度计算，文中提供了两种算法。\n\n2.1. **相似度计算单元(Unit)** \n\n两种相似度计算单元如下：\n\n![](http://imgur.com/wttqwKe.png)\n\n\n2.2. **基于句子局部的相似度计算**\n\n算法1和算法2为句子表征向量的两种计算方法，其中算法1仅用在 \\\\(block\\_{A}\\\\) 上；而算法2则都用在 \\\\(block\\_{A}\\\\) 和 \\\\(block\\_{B}\\\\) 上，两种算法都是针对相同类型(pooling和block类型)的输出做局部比较。\n\n给出如下的符号假设：\n\n![](http://imgur.com/0Oxsp9O.png)\n\n算法的伪代码如下：\n\n![](http://imgur.com/pkDPaky.png)\n\n下面的图示说明了在 \\\\(block\\_{A}\\\\) 上，两种算法的计算方式的区别，算法一表现了向量在水平方向上的比较；而算法二则是在垂直方向。\n\n![](http://imgur.com/f4qrseS.png)\n\n需要注意的是，在算法二中相同类型的pooling的输出groups中，向量是两两进行比较的（图中的红色虚线只是为了说明比较的方向，并不是只针对group中相同大小的卷积窗口作比较）；而算法一中的每一行都要作比较，不仅仅是第一行。\n\n3. **模型的其他细节**\n\n- **相似度向量输出 + 全连接层**\n\n基于句子局部的相似度计算之后，得到相应的相似度向量；然后这组向量之后连接一个全连接层，最后softmax对应输出。如果是计算相似度度量值，可以用softmax输出的类别概率值。\n\n- **激活函数**\n\n使用`tanh`函数作为激活函数。\n\n#### 实验部分 ####\n\n1. **实验数据集**\n\n- [Microsoft Research Paraphrase Corpus (MSRP)](http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/)\n\n用于评测同义句检测 (Paraphrase Identification) 任务的经典数据集，数据集来源于新闻；包含5801对句子对，其中4076对用于模型训练，而1725对用于测试；每一对句子拥有一个标签，0或者1,0表示两个句子不是互为同义句，而1则表示两个句子互为同义句。因此这是一个二分类的任务。\n\n- [Sentences Involving Compositional Knowledge (SICK)](http://alt.qcri.org/semeval2014/task1/index.php?id=data-and-tools)\n\n数据来源于2014年SemEval比赛，数据集有9927对句子对，其中4500对用于模型训练，500对用于模型验证，而剩下的4927对用于模型测试。这些句子都是在图片和视频描述中抽取得到的，每一对句子对有一个相关分数，区间在[1, 5]，分数越高表示句子越相关。\n\n- [Microsoft Video Paraphrase Corpus (MSRVID)](https://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/train-readme.txt)\n\n数据集来源于2012年的SemEval比赛，包含1500对短文本（用于描述视频信息）。其中一般用于模型训练，一半用于模型测试，每一对句子有一个相关性分数，区间在[0, 5]，分数越高表示句子越相关。\n\n2. **模型训练**\n\n针对MSRP和其他两个数据集，分别使用两种损失函数。对于MSRP数据集，损失函数（Hinge Loss）如下：\n\n![](http://imgur.com/jjQu3pY.png)\n\n对于其余两个数据集，损失函数（KL-divergence Loss）如下：\n\n![](http://imgur.com/kfVigMW.png)\n\n3. **实验参数设置**\n\n- **\\\\(ws\\\\) 的值**：\\\\(ws \\in [1, 3]\\\\)和 \\\\(ws=\\infty\\\\).\n- **Word Embedding**: 300维的`GloVe word embedding`；对于MSRP数据集，还额外使用了200维的`POS embedding` ([Standford POS tagger](http://nlp.stanford.edu/software/tagger.shtml))和25维的`Paragram Vectors` ([Wieting et al., 2015 PDF](http://ttic.uchicago.edu/~wieting/wieting2015TACL.pdf)，[数据下载地址](http://ttic.uchicago.edu/~wieting/paragram_vectors.txt))。因此对于MSRP任务而言，`word embedding`的维数为525维 (200+300+25)；而其余两个任务则对应是300维。\n- 在MSRP上使用了**5-折交叉验证**的方式，对模型参数进行*tuning*. *Tuning*好的模型参数将会用在另外两个数据集任务上。\n- 只有在MSRP数据集任务上，允许模型参数进行更新。\n- 输出的全连接层，MSRP有250个神经元节点，而SICK和MSRVID则是150个。\n- 在 \\\\(block\\_{A}\\\\) 中，`Feature Map` 的数量与输入的`embedding`维数相同，即MSRP是525个，而SICK和MSRVID则是300个。\n- 优化算法使用随机梯度下降方法。\n- 学习率为0.01，而正则化参数 \\\\(\\lambda=10^{-4}\\\\).\n\n4. **实验结果**\n\n- **MSRP数据集**\n\n![](http://imgur.com/CLF0SKJ.png)\n\n可以看出，文中的模型是所有基于NN的方法中在MSRP数据集上性能最好的。\n\n- **SICK数据集**\n\n![](http://imgur.com/16bJWHS.png)\n\n- **MSRVID数据集**\n\n![](http://imgur.com/s89LYEb.png)\n\n而模型在SICK和MSRVID数据集上的表现也很好。\n\n5. **模型的敏感度分析**\n\n下面的表格说明了在不使用某种技术下，模型性能在实验数据集上的变化情况。\n\n![](http://imgur.com/pmTY9TY.png)\n\n从中可以得出以下结论：\n\n- 对于MSRP数据集任务而言，增加**`POS Embedding`**和**`Paragram Vector`**效果显著；\n- 移除相似度计算层的影响显著，说明结构化的句子局部比较方法是有效且必要的；\n- **`Horizontal`**和**`Vertical`**算法均有一定的提升效果，而**`Vertical`**算法的提升程度更高；\n- **`max-pooling`**方式确实要比**`min-pooling`**和**`mean-pooling`**强太多。\n\n5. **总结**\n\n文中的模型包含两个部分：卷积-池化模型和相似度计算模型。实验部分已经验证了模型的有效性，在MSRP数据集上模型取得了仅次于state-of-art的结果，并且在基于NN的方法中是最好的。模型中的相似度计算层是有必要的，因为对卷积池化处理后的句子成分进行了针对性的比较，从直观上要比直接扔进全连接层更合理，而实验结果也表明了这一点。\n\n然而，个人觉得，文中的模型结构较为复杂，而且其中有很多trick的地方，比如为什么要对word embedding中的每一维度做卷积，\\\\(block\\_{B}\\\\) 中的`pooling`方式为什么只用了max和min，不用mean的方式等问题，而这些方式或许是作者自己做了大量实验后，从果到因而使用的。\n\n### Yin's Paper ###\n\nYin的这篇论文提出了一种叫`Bi-CNN-MI`的架构，其中`Bi-CNN`表示两个使用`Siamese`框架的CNN模型；`MI`表示多粒度的交互特征。`Bi-CNN-MI`包含三个部分：\n\n* **句子分析模型 (CNN-SM)**\n\n这部分模型主要使用了上述Kal在2014年提出的模型，针对句子本身提取出四种粒度的特征表示：词、短*ngram*、长*ngram*和句子粒度。多种粒度的特征表示是非常必要的，一方面提高模型的性能，另一方面增强模型的鲁棒性。\n\n* **句子交互计算模型 (CNN-IM)**\n\n这部分模型主要是基于2011年Socher提出的RAE模型，做了一些简化，即仅对同一种粒度下的提取特征做两两比较。\n\n* **LR或Softmax网络层以适配任务**\n\n#### 模型结构 ####\n\n论文提出的模型主要是基于Kal的模型及Socher的RAE模型的结合体，如下图：\n\n![](http://imgur.com/Ubku2XR.png)\n\n通过模型图可以看出模型的主要思想：一方面利用Kal的模型进行多种粒度上的特征提取，另一方面采取RAE模型的思想，对提取出来的特征进行两两的相似度计算，计算完成的结果通过`dynamic pooling`的方式进一步提取少量特征，然后各个层次的`pooling`计算结果平摊为一组向量，通过全连接的方式与LR(或者softmax)层连接，从而适配同义句检测任务本身。\n\n这个模型具体的计算细节不再赘述了，感兴趣的读者可以直接去看论文。除了提出这种模型结构之外，论文还有一个亮点在于使用了一种类似于语言模型的`CNN-LM`来对上述CNN部分的模型进行预训练，从而提前确定模型的参数。`CNN-LM`的网络结构如下图：\n\n![](http://imgur.com/zMyzscM.png)\n\n`CNN-LM`模型的训练预料使用了最终的实验数据集，即MSRP；另外，由于MSRP的数据规模较小，所以作者又增加了100,000个英文句子语料。`CNN-LM`模型最终能够得到word embedding, 模型权值等参数。需要注意的是，这些参数并不是固定的，在之后的句子匹配任务中是会不断更新的。从后面的实验结果中可以看出，`CNN-LM`的作用是显著的。\n\n#### 实验结果 ####\n\n论文仅使用了一种数据集，即公认的PI (Paraphrase Identification)任务数据集，MSRP。实验结果如下：\n\n![](http://imgur.com/Y67eY0a.png)\n\n可以看出，`CNN-LM`的预训练效果显著，预训练后的模型性能很强（但是结果上比之前He提出的模型稍差一些）。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html\n\n**参考文献**\n\n[1] R. Socher, E. H. Huang, and A. Y. Ng. Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In Advances in NIPS, 2011.\n\n**推荐资料**\n\n[A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification](http://arxiv.org/abs/1510.03820)\n\n[Implementing a CNN for Text Classification in TensorFlow](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)\n\n[Kim Y's Implement: Convolutional Neural Networks for Sentence Classification](https://github.com/yoonkim/CNN_sentence)\n\n\n\n","slug":"cnn-apply-on-modelling-sentence","published":1,"updated":"2016-04-11T08:58:41.081Z","_id":"cinjqrkq90039nfq6c95hdqgi","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"如何将博客托管至Coding及相应的DNS设置","date":"2015-12-20T02:19:18.000Z","_content":"在[之前的博文](http://www.jeyzhang.com/Hexo-Github-%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/)中，已经介绍了如何创建一个Hexo网站并且将其托管至Github上，从而实现一个静态的博客网站。由于国内访问Github速度较慢甚至无法访问，因此有了国内版的Github，也就是Gitcafe。将网站托管至Gitcafe上的好处就是，你的网站即使在国内的网络环境下也能被访问，同时也便于百度等中文搜索引擎的收录。\n\n将博客托管至Gitcafe与托管至Github类似，但是仍存在一些细小的差别。下面将介绍如何将之前所创建的网站托管至Gitcafe上，主要包含两方面的内容：\n\n1. 将网站托管至Gitcafe上；\n2. 相应的DNS域名解析设置以实现国内外分流访问网站（即国外网络环境下是通过Github Page访问你的网站，而国内则是通过Gitcafe Page访问）。\n\n**Gitcafe目前已经面临关闭，博文最后介绍了将静态网站迁移至Coding的方法。**\n\n----------\n\n# 将博客托管至Gitcafe上 #\n\n## 注册Gitcafe账号 ##\n\n打开[Gitcafe官网](https://gitcafe.com)，注册账号。\n\n## 配置SSH ##\n\n假设你已经完成将网站托管至Github上，此时你的本地已经生成了SSH公钥文件，打开这个文件并复制其中的内容。下面是我的ssh公钥文件路径\n\n\tC:\\Users\\ZhangJie\\.ssh\\id_rsa.pub\n\n打开Gitcafe主页，登陆后进入到“账户设置”中，点击左侧的`SSH公钥管理`，然后`添加新的公钥`，将之前的内容粘贴到对应的栏目里即可。\n\n为了测试ssh是否配置成功，打开本地的`git bash`，输入\n\n\tssh -T git@gitcafe.com\n\n如果显示\n\t\n\tHi USERNAME! You've successfully authenticated...\n\n则说明配置成功，此时你可以免密码将本地的项目文件同步至Gitcafe中。\n\n如果依然存在问题，可以查看[官网详细的帮助页面](https://help.gitcafe.com/manuals/help/ssh-key)。\n\n## 创建同名项目以及修改配置文件 ##\n\n在Gitcafe上新建一个与你的账户名同名的项目。\n\n修改站点目录下的配置文件，找到`deploy`项。我的deploy项内容如下\n\n\t# Deployment\n\t## Docs: http://hexo.io/docs/deployment.html\n\tdeploy:\n\t  type: git\n\t  repo: \n\t    github: git@github.com:JeyZhang/JeyZhang.github.io.git\n\t    gitcafe: git@gitcafe.com:JeyZhang/JeyZhang.git,gitcafe-pages\n\n注意对于gitcafe，网站应该托管至其`gitcafe-pages`分支上。\n\n## 将本地网站同步至Gitcafe项目中 ##\n\n在网站根目录下，打开gitbash，输入\n\n\thexo g -d\n\n即可将本地网站同步至Github和Gitcafe上。\n\n（注意：在本地网站根目录下的source文件夹下，需要新建一个文件名为`CNAME`的文件（无后缀名），里面填写你所绑定的域名地址，如www.jeyzhang.com.）\n\n## 测试是否成功将网站托管至Gitcafe上 ##\n\n如果项目根目录下存在`CNAME`文件，暂时现将其删除。（因为目前你还没有将你的网站域名解析至Gitcafe服务器上）\n\n在浏览器输入地址\n\n\thttp://jeyzhang.gitcafe.io\n\n看网站是否访问成功（国内网络即可）。\n\n# DNS解析设置 #\n\n笔者使用[DNSPod](https://www.dnspod.cn)的域名解析,我的域名解析设置如下\n\n![](http://i.imgur.com/gw8SKtu.png)\n\n国内线路选择Gitcafe，国外线路选择Github，从而实现国内外分流访问网站。主机记录为`@`可以实现访问`××××××.com`时，自动填充\"www\"开头，因为之前我们绑定的网站是`www.××××××.com`的二级域名。\n\n等待一段时间生效即可。\n\n# 将博客托管至Coding平台 #\n\n托管的方法与Gitcafe的类似，托管完成后，你可以手动删除Gitcafe上的项目（2016年5月31号之后系统也会自动清除的）。\n\n## 注册Coding账户并建立项目 ##\n\n去[Coding的官网](https://coding.net)注册，在个人主页的`项目`中创建一个项目，最好创建与你账户名相同的项目。例如，我的账户名为jeyzhang, 创建的项目名为JeyZhang（大小写不区分）。\n\n## 上传SSH文件 ##\n\n在Coding的个人主页的`账户`中，进入`SSH公钥`。添加你的公钥，如果你之前生成过，公钥在`C:\\Users\\你的用户名\\.ssh\\id_rsa.pub`。复制里面的内容在`SSH-RSA公钥内容`中即可。\n\n打开`git bash`，输入\n\t\n\tssh -T git@git.coding.net\n\n进行测试，如果显示如下则SSH配置成功：\n\n\tHello ...! You've conected to Coding.net by SSH successfully!\n\n## 修改网站的配置文件 ##\n\n修改网站根目录下的配置文件`_config.yml`，找到`deploy`的设置处，改为如下：\n\n\tdeploy:\n\t  type: git\n\t  repo: \n\t    github: git@github.com:JeyZhang/jeyzhang.github.io.git\n\t    coding: git@git.coding.net:JeyZhang/JeyZhang.git,master\n\n注意要改成你的项目地址。\n\n## 将网站文件部署至Coding ##\n\n在网站根目录下打开`git bash`，输入\n\n\thexo g -d\n\n进行网站文件的生成和部署。成功之后，进入你的Coding对应的项目中应该能看到网站文件。\n\n## 配置Coding的Page服务 ##\n\n进入你在Coding上的项目，点击左侧的`代码`可以看到`Coding Pages`服务。输入分支为`master`，点击开启服务。在自定义域名处填上你的网站域名，如下图所示：\n\n![](http://i.imgur.com/2Ko41Xk.png)\n\n## 配置DNS ##\n\n笔者使用[DNSPod](https://www.dnspod.cn/)进行网站的DNS设置。将国内线路设置为`CNAME`的`page.coding.me`即可。如下图所示。\n\n![](http://i.imgur.com/rMOVcTS.png)\n\n等待一会儿，你就能在国内网络快速访问你的网站了。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/blog-on-gitcafe-with-dns-settings.html","source":"_posts/blog-on-gitcafe-with-dns-settings.md","raw":"title: 如何将博客托管至Coding及相应的DNS设置\ndate: 2015-12-20 10:19:18\ntags: [Hexo, Gitcafe, Coding, DNS, Github]\ncategories: Hexo\n---\n在[之前的博文](http://www.jeyzhang.com/Hexo-Github-%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/)中，已经介绍了如何创建一个Hexo网站并且将其托管至Github上，从而实现一个静态的博客网站。由于国内访问Github速度较慢甚至无法访问，因此有了国内版的Github，也就是Gitcafe。将网站托管至Gitcafe上的好处就是，你的网站即使在国内的网络环境下也能被访问，同时也便于百度等中文搜索引擎的收录。\n\n将博客托管至Gitcafe与托管至Github类似，但是仍存在一些细小的差别。下面将介绍如何将之前所创建的网站托管至Gitcafe上，主要包含两方面的内容：\n\n1. 将网站托管至Gitcafe上；\n2. 相应的DNS域名解析设置以实现国内外分流访问网站（即国外网络环境下是通过Github Page访问你的网站，而国内则是通过Gitcafe Page访问）。\n\n**Gitcafe目前已经面临关闭，博文最后介绍了将静态网站迁移至Coding的方法。**\n\n----------\n\n# 将博客托管至Gitcafe上 #\n\n## 注册Gitcafe账号 ##\n\n打开[Gitcafe官网](https://gitcafe.com)，注册账号。\n\n## 配置SSH ##\n\n假设你已经完成将网站托管至Github上，此时你的本地已经生成了SSH公钥文件，打开这个文件并复制其中的内容。下面是我的ssh公钥文件路径\n\n\tC:\\Users\\ZhangJie\\.ssh\\id_rsa.pub\n\n打开Gitcafe主页，登陆后进入到“账户设置”中，点击左侧的`SSH公钥管理`，然后`添加新的公钥`，将之前的内容粘贴到对应的栏目里即可。\n\n为了测试ssh是否配置成功，打开本地的`git bash`，输入\n\n\tssh -T git@gitcafe.com\n\n如果显示\n\t\n\tHi USERNAME! You've successfully authenticated...\n\n则说明配置成功，此时你可以免密码将本地的项目文件同步至Gitcafe中。\n\n如果依然存在问题，可以查看[官网详细的帮助页面](https://help.gitcafe.com/manuals/help/ssh-key)。\n\n## 创建同名项目以及修改配置文件 ##\n\n在Gitcafe上新建一个与你的账户名同名的项目。\n\n修改站点目录下的配置文件，找到`deploy`项。我的deploy项内容如下\n\n\t# Deployment\n\t## Docs: http://hexo.io/docs/deployment.html\n\tdeploy:\n\t  type: git\n\t  repo: \n\t    github: git@github.com:JeyZhang/JeyZhang.github.io.git\n\t    gitcafe: git@gitcafe.com:JeyZhang/JeyZhang.git,gitcafe-pages\n\n注意对于gitcafe，网站应该托管至其`gitcafe-pages`分支上。\n\n## 将本地网站同步至Gitcafe项目中 ##\n\n在网站根目录下，打开gitbash，输入\n\n\thexo g -d\n\n即可将本地网站同步至Github和Gitcafe上。\n\n（注意：在本地网站根目录下的source文件夹下，需要新建一个文件名为`CNAME`的文件（无后缀名），里面填写你所绑定的域名地址，如www.jeyzhang.com.）\n\n## 测试是否成功将网站托管至Gitcafe上 ##\n\n如果项目根目录下存在`CNAME`文件，暂时现将其删除。（因为目前你还没有将你的网站域名解析至Gitcafe服务器上）\n\n在浏览器输入地址\n\n\thttp://jeyzhang.gitcafe.io\n\n看网站是否访问成功（国内网络即可）。\n\n# DNS解析设置 #\n\n笔者使用[DNSPod](https://www.dnspod.cn)的域名解析,我的域名解析设置如下\n\n![](http://i.imgur.com/gw8SKtu.png)\n\n国内线路选择Gitcafe，国外线路选择Github，从而实现国内外分流访问网站。主机记录为`@`可以实现访问`××××××.com`时，自动填充\"www\"开头，因为之前我们绑定的网站是`www.××××××.com`的二级域名。\n\n等待一段时间生效即可。\n\n# 将博客托管至Coding平台 #\n\n托管的方法与Gitcafe的类似，托管完成后，你可以手动删除Gitcafe上的项目（2016年5月31号之后系统也会自动清除的）。\n\n## 注册Coding账户并建立项目 ##\n\n去[Coding的官网](https://coding.net)注册，在个人主页的`项目`中创建一个项目，最好创建与你账户名相同的项目。例如，我的账户名为jeyzhang, 创建的项目名为JeyZhang（大小写不区分）。\n\n## 上传SSH文件 ##\n\n在Coding的个人主页的`账户`中，进入`SSH公钥`。添加你的公钥，如果你之前生成过，公钥在`C:\\Users\\你的用户名\\.ssh\\id_rsa.pub`。复制里面的内容在`SSH-RSA公钥内容`中即可。\n\n打开`git bash`，输入\n\t\n\tssh -T git@git.coding.net\n\n进行测试，如果显示如下则SSH配置成功：\n\n\tHello ...! You've conected to Coding.net by SSH successfully!\n\n## 修改网站的配置文件 ##\n\n修改网站根目录下的配置文件`_config.yml`，找到`deploy`的设置处，改为如下：\n\n\tdeploy:\n\t  type: git\n\t  repo: \n\t    github: git@github.com:JeyZhang/jeyzhang.github.io.git\n\t    coding: git@git.coding.net:JeyZhang/JeyZhang.git,master\n\n注意要改成你的项目地址。\n\n## 将网站文件部署至Coding ##\n\n在网站根目录下打开`git bash`，输入\n\n\thexo g -d\n\n进行网站文件的生成和部署。成功之后，进入你的Coding对应的项目中应该能看到网站文件。\n\n## 配置Coding的Page服务 ##\n\n进入你在Coding上的项目，点击左侧的`代码`可以看到`Coding Pages`服务。输入分支为`master`，点击开启服务。在自定义域名处填上你的网站域名，如下图所示：\n\n![](http://i.imgur.com/2Ko41Xk.png)\n\n## 配置DNS ##\n\n笔者使用[DNSPod](https://www.dnspod.cn/)进行网站的DNS设置。将国内线路设置为`CNAME`的`page.coding.me`即可。如下图所示。\n\n![](http://i.imgur.com/rMOVcTS.png)\n\n等待一会儿，你就能在国内网络快速访问你的网站了。\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/blog-on-gitcafe-with-dns-settings.html","slug":"blog-on-gitcafe-with-dns-settings","published":1,"updated":"2016-05-12T09:40:00.840Z","_id":"cinjqrkqj003infq6etx6yfzd","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"2015年校招总结：技术面试干货","date":"2016-03-03T12:11:07.000Z","_content":"\n关于实习及校招的全面概括性总结在[**这篇博文**](http://www.jeyzhang.com/2015-campus-recruit-summary.html)，里面也提出了一些技术面试过程中的注意事项。本文主要是单纯针对**程序员技术面试的面试内容**，将（1）推荐一些优秀的资源（包括书籍、网站等），以及（2）总结一下自己及周遭同学在实习与校招技术面试过程中遇到的各种原题，以供后人参考。\n\n----------\n\n# 推荐资源 #\n\n## 书籍 ##\n\n### 算法类 ###\n\n- **《Crack the code interview》(Gayle Laakmann著) [[PDF下载地址](http://vdisk.weibo.com/s/DpqS8KKk4Vcu)]**\n\n这本书是经典的程序员技术面试必备书了，作者是曾经的Google面试官，从面试官的角度教你应该如何一步步地准备面试。书中分析了硅谷的一些巨头公司的面试风格和特点，对于想要面国外公司的再合适不过了；还帮助你制定了面试准备的流程和计划，给出写简历的建议，如何应对行为面试(Behavioral Interview)等；当然，最主要的篇幅集中在技术面试的准备中，总结了常见的数据结构及相应的算法题，数理概率，及一些其他面试中常见的技术题型。\n\n- **《进军硅谷：程序员面试揭秘》(陈东锋著) [[豆瓣地址](https://book.douban.com/subject/25844586/)]**\n\n尽管这本书在豆瓣上的评分很低（leetcode作者认为该书抄袭了leetcode上的题目...），但对于面试者来说，这本书还是值得推荐的。这本书前面部分也是主要介绍了一下面试流程和注意事项，硅谷公司的特点；其余的大篇幅都是集中在算法题的解题思路分析和代码实现，确实大部分的算法题与leetcode上的一样，所以刷leetcode的时候配合这本书，应该会顺畅挺多的。这本书的代码都是Java，简单易懂。\n\n\n- **《剑指Offer》(何海涛著) [[PDF下载地址](http://vdisk.weibo.com/s/EjagsS5Ugjw)]**\n\n这本书的结构其实与前两本比较类似，但是有一个亮点是，对于所有的算法题都会给出测试样例，包括特殊边界和正常功能测试样例等。写算法题能够提前考虑测试样例是非常好的编程习惯，称之为**`防御式编程`**；大多数人都是习惯写完代码后，再进行样例测试，然后修修补补之类的。\n\n- **《微软面试100题系列》(July著) [[PDF下载地址](http://vdisk.weibo.com/s/akZyBqthxGDMn?from=page_100505_profile&wvr=6)]**\n\n严格上来说，这个并不是一本正式的书籍。但是这个资料里收集了许多经典真实的企业面试题。题型比较杂，大部分是算法题，还有智力题等。虽然答案不是很全，但是值得好好看看里面的题，从本人的笔试面试经历来看，遇到了里面挺多的原题~\n\n- **《编程之美：微软技术面试心得》[[PDF下载地址](http://download.csdn.net/detail/sunmeng_alex/4606246)]**\n\n如果时间充裕的话，这本书也可一看。这本书是由MSRA的一些FTE和实习生们编写的，老实说，这本书中很多题还是挺有难度的，有许多数学相关的题，不折不扣地考验你的智商……偶尔翻翻，转转脑子也挺好的。\n\n此外，还有一些神书，例如《算法导论》《编程珠玑》也可一看。但是，时间总是有限的，**认真刷刷1-2本书，然后多动手配合刷题（刷题平台下面有推荐）**，应付面试的算法能力自然会慢慢变强。\n\n\n### 数据结构类 ###\n\n- **《Java数据结构和算法》(Robert Lafore著) [[PDF下载地址](http://vdisk.weibo.com/s/dhYy6pCj8N-9z?from=page_100505_profile&wvr=6)]**\n\n相比起清华的严奶奶那本，这本书通俗易懂得多:)要是觉得之前的数据结构掌握的不够好，这本书绝对能拉你入门~\n\n- **《数据结构：C语言版》(严蔚敏著) [[PDF下载地址](http://vdisk.weibo.com/s/aFmBnrN-WDuX6)]**\n\n虽然刚学的时候觉得晦涩难懂，但是还是国内经典的书籍，对数据结构研究的比较深刻，内容较上本会丰富很多。\n\n### 编程语言类 ###\n\n- **Java**\n\n《Java编程思想》(Bruce Eckel著) [[PDF下载地址](http://vdisk.weibo.com/s/aPgqW10HL3Q90)]\n\n《Effective Java》(Joshua Bloch著)(中文版) [[PDF下载地址](http://vdisk.weibo.com/s/grsVw)] | (英文版) [[PDF下载地址](http://vdisk.weibo.com/s/dq65Vm6HA4vmD)]\n\n《疯狂Java讲义》(李刚著) [[PDF下载地址](http://vdisk.weibo.com/s/A-1hO0QV0ZhQ)]\n\n- **C**\n\n《C Primer Plus》(Stephen Prata著) [[PDF下载地址](http://vdisk.weibo.com/s/zfhMNTK9gWJOV)]\n\n《征服C指针》(前桥和弥著) [[PDF下载地址](http://vdisk.weibo.com/s/e41M8kWaqoim)]\n\n- **Python**\n\n《Python基础教程》(Magnus Lie Hetland著) [[PDF下载地址](http://vdisk.weibo.com/s/dhZbFvYADsgqr)]\n\n《Python简明教程》(Swaroop著) [[PDF下载地址](http://vdisk.weibo.com/s/BE2Z8B94-5w97)]\n\n《利用Python进行数据分析》(Wes McKinney著) [[PDF下载地址](http://vdisk.weibo.com/s/AFN3jW3skIDf)]\n\n《Learn Python The Hard Way》[[PDF下载地址](http://vdisk.weibo.com/s/BCRaGM7XY1jut)]\n\n\n### 数据库类 ###\n\n《SQL必知必会》(Ben Forta著) [[PDF下载地址](http://vdisk.weibo.com/s/y-3ktzWX4vlzr)]\n\n《深入浅出SQL》(Lynn Beighley著) [[PDF下载地址](http://vdisk.weibo.com/s/aHSh1alRGXpb)]\n\n《高性能MySQL》(Baron Schwarlz等著) [[PDF下载地址](http://vdisk.weibo.com/s/GNZwNnGfiqSm)]\n\n## 刷题网站 ##\n\n- **[Leetcode](https://leetcode.com/)**\n\n众所周知的刷题网站了，许多公司的面试题都是从里面出的。建议刷3遍左右。\n\n- **[Lintcode](http://www.lintcode.com/)**\n\n一个类似于leetcode的刷题网站，但是比起leetcode，里面的题目更加齐全。还有一些特色的功能，如限时提交，编程风格检测等。\n\n- **[九度OJ](http://ac.jobdu.com/)**\n\n里面收录了《剑指Offer》中的题，可以配合看书练习。还有一些考研机试、比赛类型的题，适合刷完leetcode等网站后，磨练算法能力。\n\n- **[hihoCoder](http://www.hihocoder.com/)**\n\n这个平台经常举办一些编程比赛，一些公司的笔试会选择在这个平台进行，例如微软(中国)、网易游戏等。另外，这个平台里面的题有一定难度，适合算法能力中上的人。\n\n## 网站与论坛 ##\n\n- **[九章算法](http://www.jiuzhang.com/)**\n\n曾经上过它的算法课，还可以。里面有leetcode中大多数题的解答（只有代码，大多数是Java），还有一些面筋之类的分享。有时间和米的还可以去听听他家的课，都是PPT+白板+语音的形式。\n\n- **[GeeksforGeeks](http://www.geeksforgeeks.org/)** \n\n- **[Career Cup](https://www.careercup.com/)**\n\n以上这两个网站上面有很多国外最近的、真实的面试题分享和讨论，也可以经常去水水~另外，这个**[知乎问题](https://www.zhihu.com/question/20368410)**，票数第一的回答还总结了挺多的。\n\n- **[July的cnblog](http://home.cnblogs.com/u/v-July-v/)**\n\n这个博主总结了之前提及的《微软面试100题系列》，有个**[教你如何迅速秒杀99%的海量数据处理面试题](http://www.cnblogs.com/v-July-v/archive/2012/03/22/2413055.html)**也写得不错，基本足够应付面试中遇到的大数据相关的题。\n\n- **[我的cnblog](http://www.cnblogs.com/harrygogo/)**\n\n之前在面试准备过程中，在cnblog上建了个博客，记录了以下刷的算法题及面试题。欢迎访问。\n\n# 真实面筋 #\n\n## 算法和数据结构 ##\n\n> **Google SED实习**\n\n- 非递归实现二叉树深度的求解\n- 如何实现双端队列\n\n> **阿里春招实习**\n\n- 一维的连连看实现 \n- 动归和贪心的区别 \n- 大小为999的一维数组，按序存放着1-1000的数字，但有一个数字缺失，找到它\n- 最长公共子序列 \n- 一个排序的数组, 如何做压缩?\n- 三个排序数组, 找到同时存在于三个数组中的元素\n- three sum\n- 判断链表中有环 环的大小\n- 写个KMP\n- 给定一些金币，金币的数额都是2的整数幂，然后每种硬币都有两枚，然后给定一个数额，求可行的组合方式（重复不算）[动态规划]\n- 给定一个m*n的长方形，然后每次对长方形进行分割，分割的直线均平行于长方形的边，而且落在长方形内，给定一系列有顺序的分割直线，问每次分割后形成的所有小长方形中面积最大的。[最小堆]\n- Leetcode: Excel Sheet Column Title\n- 给定N个骰子, 每一面上有一个字母. 给定一个长度为M的单词. 问这些骰子您不能拼出这个单词. 每个骰子只能用一次, 顺序随便排.\n- 两个骰子, 每个骰子各个面上可以放不同数字(自己安排数字), 问能否组成1~31. 如果扩展为N个骰子, 能组成的最长的连续数字(从1开始)是多大.\n- 数组表示的数, 实现一个加一函数.\n- 字符串中找到字母数不超过M的最长子串.\n- \n\n> **Hulu实习**\n\n- 判断一颗二叉树是否完全二叉树\n- 给一个整数数组，找其中的连续子序列，使得字段和的绝对值最小\n- 给一个单链表，写个快排\n- 给一个值已排序的双链表，双链表存储在一个Node*数组里，每个元素是一个指向双链表某个节点的指针。现在只有一次查询x，找到x在双链表中的位置或报告找不到\n- 整数数组，找到满足f(j) > f(i) 最大的（j - i）\n- 一个数组两种操作，1）修改数组中的一个值，2）计算数组某个子区间所有数字之和。写个线段树？\n- 一个矩形格子区域，每个格子上有一个数字，还有红蓝2中颜色其中之一，初始从某个位置开始，问能否找到一条能够走到边界外的路线，这条路线要满足，1）数字大小严格递增，2）红蓝两色至少各出现一次。（搜索？我先说宽搜，后来想想只要找一条就行那就深搜。这里貌似可以记忆化一下存储一些信息，可惜当时并没有很清晰地考虑清楚，而且时间不很足够的样子了。写代码。）\n- 写代码判断一棵树是否是完全二叉树\n- 一个长度为n的数组，求最小连续子段和，求绝对值最小的连续子段和，求绝对值最接近某个数的连续子段和\n- 蛇形打印矩阵\n- n个数字，a1,a2...an，数字之间可以添加+、*、括号变成一个表达式，求表达式的最大值\n- 有一个字符串流，里面是一些单词和空格。给一个api：read_char()，每次调用将在流中读取一个字符，如果遇到流的结尾，则返回0。请设计函数print_stream()，通过调用read_char()打印流中的单词，要求，每行长度不超过M，一个单词不能跨越两行，单词之间只保留1个空格，删除首尾空格。\n- n个元素的数组，设计算法找出现次数大于n/3的元素，要求时空复杂度尽可能小\n- \n\n\n> **有道实习**\n\n- 判断2个url是否是同一个网站的。比如news.sina.com.cn/asdasd和car.sina.com.cn/asdasd/asdasd就是同一个网站的.\n- 给定整数b，求最大的a，满足a*(a+b)是完全平方数\n- 给定一个棋盘，马初始在(0,0)，棋盘上有些点为禁行点，用*表示。另外棋盘上有个兵，兵的移动路线已知，每次移一步，在棋盘上用1,2,3....表示出。要求计算马最少跳多少步能把兵吃掉。\n- \n\n> **豌豆荚**\n\n- 实现atoi函数\n- 码镜像二叉树\n- 找最后一个出现的字符串匹配\n- 求树的深度\n- 高精度加法\n- \n\n> **网易游戏实习**\n\n- m个数中找最小的n个\n- 删除链表的某个节点\n- 无向普通图G中找两个点最短路径\n- \n\n## 大数据 ##\n\n> **阿里春招实习**\n\n- 集合A：40亿个未排序，不重复的unsigned int；集合B：1万个unsined int；判断集合B中的数是否属于集合A。（输出1W个bool值）\n- 1亿个查询记录，找出frequency top1000；follow up：讲解堆的调整过程。\n- [一个100G的文件, 存放搜索的关键词, 统计其中出现最多的20个](http://www.cnblogs.com/v-July-v/archive/2012/03/22/2413055.html)\n- 现在有淘宝的登录日志5亿条, 支付宝登录日志3亿条, 假设账号最多20个汉字. 找到所有两个都登陆过的账号. (哈希表使用的具体数据结构, 冲突如何处理, 分析下分解之后文件应该有多大才能保证内存能装下, 重复条目处理)\n- 100万个数字, 没有重复的有序数组, 有什么办法压缩大小.\n- Hadoop题：一个表每一行是一个key和许多value，有另一个表，记录着value到value'的映射。问题1）若第二个表不很大，写个hadoop 2）若第二个表很大，写个hadoop。\n- 1亿条搜索输入文本记录，找到频率topN条，写代码。\n- \n\n## 数据挖掘和机器学习 ##\n\n> **阿里春招实习**\n\n- 如何识别买家评价的虚假评价\n- SVM特征怎么提的，参数怎么调的，半监督学习是在干嘛，整体学习是在干嘛?\n- 讲解CNN，CNN和DNN相比有什么优点为什么用它?\n- 随机森林和决策树的基本原理 \n- SVM原理及公式推导 \n- Boosting算法 \n- 对数线性模型 \n- 概率主题模型，LDA思想 \n- 怎么判断两个词指的是同一个东西（语言模型，Wordvec）\n- 对推荐和搜索排序的理解\n\n\n## 编程语言 ##\n\n### C/C++ ###\n\n> **阿里春招实习**\n\n- C++的多态和虚函数\n- malloc和new关键字\n- [类的构造函数初始化和初始化列表初始化区别](http://www.cnblogs.com/graphics/archive/2010/07/04/1770900.html)\n- 虚函数表\n- \n- \n\n\n> **网易游戏实习**\n\n- 如果一个static对象被创建，什么时候被创建和删除\n- 介绍overload和override\n- 介绍inline (原理，编译器，优缺点，虚函数和Inline同时声明)\n- 多态的实现机制(虚函数表，虚指针)\n- 知不知道智能指针，介绍一下，如果多个线程同用一个shared_ptr，会不会互相影响，实现机制是什么样的(比如shared_ptr和它所指向的对象分别存在哪)\n- vector实现机制，他和list区别\n- map和set的实现机制，以及为什么不用其他的平衡二叉树；除了上面的BST实现方法,map还能怎么实现，以及实现机制\n- 虚拟内存的作用和实现机制\n- 介绍动态链接库和静态连接库，如果在运行时找到DLL中的那个函数入口\n- \n\n### Java ###\n\n> **阿里春招实习**\n\n- Spring的IOC是什么？Spring是怎么实现依赖控制的？\n- Java的synchronized和lock有什么区别？volatile有什么作用？\n- Java的hashmap怎么实现。\n- \n\n\n> **网易游戏实习**\n\n- \n\n> **豌豆荚实习**\n\n- 类继承/接口实现\n- synchronize\n- 线程安全的单例模式\n- \n\n### Python ###\n\n\n## 移动客户端开发 ##\n\n### Android ###\n\n> **阿里春招实习**\n\n- Android的fragment和activity有什么区别？activity能否在不同的进程中启动？\n- \n\n### iOS ###\n\n## 计算机网络 ##\n\n> **阿里春招实习**\n\n- HTTP协议中的SSL怎么实现？\n- 1G文件, 点到点传输, 提高传输速率\n- \n\n> **网易游戏实习**\n\n- TCP三次握手和四次握手\n- TCP, UPD, HTTP的关系，还问我会不会socket编程\n- cache的作用和实现机制\n- \n\n## 数据库 ##\n\n\n## 操作系统 ##\n\n> **阿里春招实习**\n\n- 操作系统分页和分块有什么区别？\n- 什么是线程安全？\n\n> **网易游戏实习**\n\n- 进程之间通信方法\n\n### Linux ###\n\n\n## 系统设计 ##\n\n> **阿里春招实习**\n\n- 设计个系统：在搜索框里输入一个词，找到以它为前缀的商品，显示给用户作为辅助输入提示\n- \n\n## 数学、智力题 ##\n\n> **Hulu实习**\n\n- 四个瓶子，每个瓶子10个药丸，某些瓶子里的药丸全是坏的，正常药丸是10g，坏药丸是9g。现在只能进行一次称量重量操作，确定哪些药瓶里的药丸是坏的。药瓶里的药丸全是好的或者全是坏的；不准切割或溶解药丸。 如果每个瓶子里只有7个药丸呢？\n- 四个人A、B、C、D，站成一排，面向西边，每人头顶戴顶帽子，帽子有红黄蓝三种颜色，每个人只能看见自己前面的人的帽子的颜色，比如C可以看见A的和B的，A看不见任何人的帽子。现在有3顶红色帽子，2顶黄色帽子，1顶蓝色帽子，随机给这几个人带上。然后D说自己不知道自己是什么颜色，C说自己不知道自己是是什么颜色，B说自己不知道自己是什么颜色，A说自己知道自己是什么颜色，问A怎么推测的。在A说出自己帽子的颜色后，B、C、D能否确定自己帽子的颜色？\n- \n\n## 杂项 ##\n\n> **阿里春招实习**\n\n- 接触过什么开源项目\n- 最近读过的值得推荐的书是什么\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/2015-campus-recurit-technology-interview-summary.html\n\n**最后特别感谢2015年面点交流群各位伙伴的面筋:)**","source":"_posts/2015-campus-recurit-technology-interview-summary.md","raw":"title: 2015年校招总结：技术面试干货\ndate: 2016-03-03 20:11:07\ntags: [Interview, Job, IT, Algorithm]\ncategories: Interview\n---\n\n关于实习及校招的全面概括性总结在[**这篇博文**](http://www.jeyzhang.com/2015-campus-recruit-summary.html)，里面也提出了一些技术面试过程中的注意事项。本文主要是单纯针对**程序员技术面试的面试内容**，将（1）推荐一些优秀的资源（包括书籍、网站等），以及（2）总结一下自己及周遭同学在实习与校招技术面试过程中遇到的各种原题，以供后人参考。\n\n----------\n\n# 推荐资源 #\n\n## 书籍 ##\n\n### 算法类 ###\n\n- **《Crack the code interview》(Gayle Laakmann著) [[PDF下载地址](http://vdisk.weibo.com/s/DpqS8KKk4Vcu)]**\n\n这本书是经典的程序员技术面试必备书了，作者是曾经的Google面试官，从面试官的角度教你应该如何一步步地准备面试。书中分析了硅谷的一些巨头公司的面试风格和特点，对于想要面国外公司的再合适不过了；还帮助你制定了面试准备的流程和计划，给出写简历的建议，如何应对行为面试(Behavioral Interview)等；当然，最主要的篇幅集中在技术面试的准备中，总结了常见的数据结构及相应的算法题，数理概率，及一些其他面试中常见的技术题型。\n\n- **《进军硅谷：程序员面试揭秘》(陈东锋著) [[豆瓣地址](https://book.douban.com/subject/25844586/)]**\n\n尽管这本书在豆瓣上的评分很低（leetcode作者认为该书抄袭了leetcode上的题目...），但对于面试者来说，这本书还是值得推荐的。这本书前面部分也是主要介绍了一下面试流程和注意事项，硅谷公司的特点；其余的大篇幅都是集中在算法题的解题思路分析和代码实现，确实大部分的算法题与leetcode上的一样，所以刷leetcode的时候配合这本书，应该会顺畅挺多的。这本书的代码都是Java，简单易懂。\n\n\n- **《剑指Offer》(何海涛著) [[PDF下载地址](http://vdisk.weibo.com/s/EjagsS5Ugjw)]**\n\n这本书的结构其实与前两本比较类似，但是有一个亮点是，对于所有的算法题都会给出测试样例，包括特殊边界和正常功能测试样例等。写算法题能够提前考虑测试样例是非常好的编程习惯，称之为**`防御式编程`**；大多数人都是习惯写完代码后，再进行样例测试，然后修修补补之类的。\n\n- **《微软面试100题系列》(July著) [[PDF下载地址](http://vdisk.weibo.com/s/akZyBqthxGDMn?from=page_100505_profile&wvr=6)]**\n\n严格上来说，这个并不是一本正式的书籍。但是这个资料里收集了许多经典真实的企业面试题。题型比较杂，大部分是算法题，还有智力题等。虽然答案不是很全，但是值得好好看看里面的题，从本人的笔试面试经历来看，遇到了里面挺多的原题~\n\n- **《编程之美：微软技术面试心得》[[PDF下载地址](http://download.csdn.net/detail/sunmeng_alex/4606246)]**\n\n如果时间充裕的话，这本书也可一看。这本书是由MSRA的一些FTE和实习生们编写的，老实说，这本书中很多题还是挺有难度的，有许多数学相关的题，不折不扣地考验你的智商……偶尔翻翻，转转脑子也挺好的。\n\n此外，还有一些神书，例如《算法导论》《编程珠玑》也可一看。但是，时间总是有限的，**认真刷刷1-2本书，然后多动手配合刷题（刷题平台下面有推荐）**，应付面试的算法能力自然会慢慢变强。\n\n\n### 数据结构类 ###\n\n- **《Java数据结构和算法》(Robert Lafore著) [[PDF下载地址](http://vdisk.weibo.com/s/dhYy6pCj8N-9z?from=page_100505_profile&wvr=6)]**\n\n相比起清华的严奶奶那本，这本书通俗易懂得多:)要是觉得之前的数据结构掌握的不够好，这本书绝对能拉你入门~\n\n- **《数据结构：C语言版》(严蔚敏著) [[PDF下载地址](http://vdisk.weibo.com/s/aFmBnrN-WDuX6)]**\n\n虽然刚学的时候觉得晦涩难懂，但是还是国内经典的书籍，对数据结构研究的比较深刻，内容较上本会丰富很多。\n\n### 编程语言类 ###\n\n- **Java**\n\n《Java编程思想》(Bruce Eckel著) [[PDF下载地址](http://vdisk.weibo.com/s/aPgqW10HL3Q90)]\n\n《Effective Java》(Joshua Bloch著)(中文版) [[PDF下载地址](http://vdisk.weibo.com/s/grsVw)] | (英文版) [[PDF下载地址](http://vdisk.weibo.com/s/dq65Vm6HA4vmD)]\n\n《疯狂Java讲义》(李刚著) [[PDF下载地址](http://vdisk.weibo.com/s/A-1hO0QV0ZhQ)]\n\n- **C**\n\n《C Primer Plus》(Stephen Prata著) [[PDF下载地址](http://vdisk.weibo.com/s/zfhMNTK9gWJOV)]\n\n《征服C指针》(前桥和弥著) [[PDF下载地址](http://vdisk.weibo.com/s/e41M8kWaqoim)]\n\n- **Python**\n\n《Python基础教程》(Magnus Lie Hetland著) [[PDF下载地址](http://vdisk.weibo.com/s/dhZbFvYADsgqr)]\n\n《Python简明教程》(Swaroop著) [[PDF下载地址](http://vdisk.weibo.com/s/BE2Z8B94-5w97)]\n\n《利用Python进行数据分析》(Wes McKinney著) [[PDF下载地址](http://vdisk.weibo.com/s/AFN3jW3skIDf)]\n\n《Learn Python The Hard Way》[[PDF下载地址](http://vdisk.weibo.com/s/BCRaGM7XY1jut)]\n\n\n### 数据库类 ###\n\n《SQL必知必会》(Ben Forta著) [[PDF下载地址](http://vdisk.weibo.com/s/y-3ktzWX4vlzr)]\n\n《深入浅出SQL》(Lynn Beighley著) [[PDF下载地址](http://vdisk.weibo.com/s/aHSh1alRGXpb)]\n\n《高性能MySQL》(Baron Schwarlz等著) [[PDF下载地址](http://vdisk.weibo.com/s/GNZwNnGfiqSm)]\n\n## 刷题网站 ##\n\n- **[Leetcode](https://leetcode.com/)**\n\n众所周知的刷题网站了，许多公司的面试题都是从里面出的。建议刷3遍左右。\n\n- **[Lintcode](http://www.lintcode.com/)**\n\n一个类似于leetcode的刷题网站，但是比起leetcode，里面的题目更加齐全。还有一些特色的功能，如限时提交，编程风格检测等。\n\n- **[九度OJ](http://ac.jobdu.com/)**\n\n里面收录了《剑指Offer》中的题，可以配合看书练习。还有一些考研机试、比赛类型的题，适合刷完leetcode等网站后，磨练算法能力。\n\n- **[hihoCoder](http://www.hihocoder.com/)**\n\n这个平台经常举办一些编程比赛，一些公司的笔试会选择在这个平台进行，例如微软(中国)、网易游戏等。另外，这个平台里面的题有一定难度，适合算法能力中上的人。\n\n## 网站与论坛 ##\n\n- **[九章算法](http://www.jiuzhang.com/)**\n\n曾经上过它的算法课，还可以。里面有leetcode中大多数题的解答（只有代码，大多数是Java），还有一些面筋之类的分享。有时间和米的还可以去听听他家的课，都是PPT+白板+语音的形式。\n\n- **[GeeksforGeeks](http://www.geeksforgeeks.org/)** \n\n- **[Career Cup](https://www.careercup.com/)**\n\n以上这两个网站上面有很多国外最近的、真实的面试题分享和讨论，也可以经常去水水~另外，这个**[知乎问题](https://www.zhihu.com/question/20368410)**，票数第一的回答还总结了挺多的。\n\n- **[July的cnblog](http://home.cnblogs.com/u/v-July-v/)**\n\n这个博主总结了之前提及的《微软面试100题系列》，有个**[教你如何迅速秒杀99%的海量数据处理面试题](http://www.cnblogs.com/v-July-v/archive/2012/03/22/2413055.html)**也写得不错，基本足够应付面试中遇到的大数据相关的题。\n\n- **[我的cnblog](http://www.cnblogs.com/harrygogo/)**\n\n之前在面试准备过程中，在cnblog上建了个博客，记录了以下刷的算法题及面试题。欢迎访问。\n\n# 真实面筋 #\n\n## 算法和数据结构 ##\n\n> **Google SED实习**\n\n- 非递归实现二叉树深度的求解\n- 如何实现双端队列\n\n> **阿里春招实习**\n\n- 一维的连连看实现 \n- 动归和贪心的区别 \n- 大小为999的一维数组，按序存放着1-1000的数字，但有一个数字缺失，找到它\n- 最长公共子序列 \n- 一个排序的数组, 如何做压缩?\n- 三个排序数组, 找到同时存在于三个数组中的元素\n- three sum\n- 判断链表中有环 环的大小\n- 写个KMP\n- 给定一些金币，金币的数额都是2的整数幂，然后每种硬币都有两枚，然后给定一个数额，求可行的组合方式（重复不算）[动态规划]\n- 给定一个m*n的长方形，然后每次对长方形进行分割，分割的直线均平行于长方形的边，而且落在长方形内，给定一系列有顺序的分割直线，问每次分割后形成的所有小长方形中面积最大的。[最小堆]\n- Leetcode: Excel Sheet Column Title\n- 给定N个骰子, 每一面上有一个字母. 给定一个长度为M的单词. 问这些骰子您不能拼出这个单词. 每个骰子只能用一次, 顺序随便排.\n- 两个骰子, 每个骰子各个面上可以放不同数字(自己安排数字), 问能否组成1~31. 如果扩展为N个骰子, 能组成的最长的连续数字(从1开始)是多大.\n- 数组表示的数, 实现一个加一函数.\n- 字符串中找到字母数不超过M的最长子串.\n- \n\n> **Hulu实习**\n\n- 判断一颗二叉树是否完全二叉树\n- 给一个整数数组，找其中的连续子序列，使得字段和的绝对值最小\n- 给一个单链表，写个快排\n- 给一个值已排序的双链表，双链表存储在一个Node*数组里，每个元素是一个指向双链表某个节点的指针。现在只有一次查询x，找到x在双链表中的位置或报告找不到\n- 整数数组，找到满足f(j) > f(i) 最大的（j - i）\n- 一个数组两种操作，1）修改数组中的一个值，2）计算数组某个子区间所有数字之和。写个线段树？\n- 一个矩形格子区域，每个格子上有一个数字，还有红蓝2中颜色其中之一，初始从某个位置开始，问能否找到一条能够走到边界外的路线，这条路线要满足，1）数字大小严格递增，2）红蓝两色至少各出现一次。（搜索？我先说宽搜，后来想想只要找一条就行那就深搜。这里貌似可以记忆化一下存储一些信息，可惜当时并没有很清晰地考虑清楚，而且时间不很足够的样子了。写代码。）\n- 写代码判断一棵树是否是完全二叉树\n- 一个长度为n的数组，求最小连续子段和，求绝对值最小的连续子段和，求绝对值最接近某个数的连续子段和\n- 蛇形打印矩阵\n- n个数字，a1,a2...an，数字之间可以添加+、*、括号变成一个表达式，求表达式的最大值\n- 有一个字符串流，里面是一些单词和空格。给一个api：read_char()，每次调用将在流中读取一个字符，如果遇到流的结尾，则返回0。请设计函数print_stream()，通过调用read_char()打印流中的单词，要求，每行长度不超过M，一个单词不能跨越两行，单词之间只保留1个空格，删除首尾空格。\n- n个元素的数组，设计算法找出现次数大于n/3的元素，要求时空复杂度尽可能小\n- \n\n\n> **有道实习**\n\n- 判断2个url是否是同一个网站的。比如news.sina.com.cn/asdasd和car.sina.com.cn/asdasd/asdasd就是同一个网站的.\n- 给定整数b，求最大的a，满足a*(a+b)是完全平方数\n- 给定一个棋盘，马初始在(0,0)，棋盘上有些点为禁行点，用*表示。另外棋盘上有个兵，兵的移动路线已知，每次移一步，在棋盘上用1,2,3....表示出。要求计算马最少跳多少步能把兵吃掉。\n- \n\n> **豌豆荚**\n\n- 实现atoi函数\n- 码镜像二叉树\n- 找最后一个出现的字符串匹配\n- 求树的深度\n- 高精度加法\n- \n\n> **网易游戏实习**\n\n- m个数中找最小的n个\n- 删除链表的某个节点\n- 无向普通图G中找两个点最短路径\n- \n\n## 大数据 ##\n\n> **阿里春招实习**\n\n- 集合A：40亿个未排序，不重复的unsigned int；集合B：1万个unsined int；判断集合B中的数是否属于集合A。（输出1W个bool值）\n- 1亿个查询记录，找出frequency top1000；follow up：讲解堆的调整过程。\n- [一个100G的文件, 存放搜索的关键词, 统计其中出现最多的20个](http://www.cnblogs.com/v-July-v/archive/2012/03/22/2413055.html)\n- 现在有淘宝的登录日志5亿条, 支付宝登录日志3亿条, 假设账号最多20个汉字. 找到所有两个都登陆过的账号. (哈希表使用的具体数据结构, 冲突如何处理, 分析下分解之后文件应该有多大才能保证内存能装下, 重复条目处理)\n- 100万个数字, 没有重复的有序数组, 有什么办法压缩大小.\n- Hadoop题：一个表每一行是一个key和许多value，有另一个表，记录着value到value'的映射。问题1）若第二个表不很大，写个hadoop 2）若第二个表很大，写个hadoop。\n- 1亿条搜索输入文本记录，找到频率topN条，写代码。\n- \n\n## 数据挖掘和机器学习 ##\n\n> **阿里春招实习**\n\n- 如何识别买家评价的虚假评价\n- SVM特征怎么提的，参数怎么调的，半监督学习是在干嘛，整体学习是在干嘛?\n- 讲解CNN，CNN和DNN相比有什么优点为什么用它?\n- 随机森林和决策树的基本原理 \n- SVM原理及公式推导 \n- Boosting算法 \n- 对数线性模型 \n- 概率主题模型，LDA思想 \n- 怎么判断两个词指的是同一个东西（语言模型，Wordvec）\n- 对推荐和搜索排序的理解\n\n\n## 编程语言 ##\n\n### C/C++ ###\n\n> **阿里春招实习**\n\n- C++的多态和虚函数\n- malloc和new关键字\n- [类的构造函数初始化和初始化列表初始化区别](http://www.cnblogs.com/graphics/archive/2010/07/04/1770900.html)\n- 虚函数表\n- \n- \n\n\n> **网易游戏实习**\n\n- 如果一个static对象被创建，什么时候被创建和删除\n- 介绍overload和override\n- 介绍inline (原理，编译器，优缺点，虚函数和Inline同时声明)\n- 多态的实现机制(虚函数表，虚指针)\n- 知不知道智能指针，介绍一下，如果多个线程同用一个shared_ptr，会不会互相影响，实现机制是什么样的(比如shared_ptr和它所指向的对象分别存在哪)\n- vector实现机制，他和list区别\n- map和set的实现机制，以及为什么不用其他的平衡二叉树；除了上面的BST实现方法,map还能怎么实现，以及实现机制\n- 虚拟内存的作用和实现机制\n- 介绍动态链接库和静态连接库，如果在运行时找到DLL中的那个函数入口\n- \n\n### Java ###\n\n> **阿里春招实习**\n\n- Spring的IOC是什么？Spring是怎么实现依赖控制的？\n- Java的synchronized和lock有什么区别？volatile有什么作用？\n- Java的hashmap怎么实现。\n- \n\n\n> **网易游戏实习**\n\n- \n\n> **豌豆荚实习**\n\n- 类继承/接口实现\n- synchronize\n- 线程安全的单例模式\n- \n\n### Python ###\n\n\n## 移动客户端开发 ##\n\n### Android ###\n\n> **阿里春招实习**\n\n- Android的fragment和activity有什么区别？activity能否在不同的进程中启动？\n- \n\n### iOS ###\n\n## 计算机网络 ##\n\n> **阿里春招实习**\n\n- HTTP协议中的SSL怎么实现？\n- 1G文件, 点到点传输, 提高传输速率\n- \n\n> **网易游戏实习**\n\n- TCP三次握手和四次握手\n- TCP, UPD, HTTP的关系，还问我会不会socket编程\n- cache的作用和实现机制\n- \n\n## 数据库 ##\n\n\n## 操作系统 ##\n\n> **阿里春招实习**\n\n- 操作系统分页和分块有什么区别？\n- 什么是线程安全？\n\n> **网易游戏实习**\n\n- 进程之间通信方法\n\n### Linux ###\n\n\n## 系统设计 ##\n\n> **阿里春招实习**\n\n- 设计个系统：在搜索框里输入一个词，找到以它为前缀的商品，显示给用户作为辅助输入提示\n- \n\n## 数学、智力题 ##\n\n> **Hulu实习**\n\n- 四个瓶子，每个瓶子10个药丸，某些瓶子里的药丸全是坏的，正常药丸是10g，坏药丸是9g。现在只能进行一次称量重量操作，确定哪些药瓶里的药丸是坏的。药瓶里的药丸全是好的或者全是坏的；不准切割或溶解药丸。 如果每个瓶子里只有7个药丸呢？\n- 四个人A、B、C、D，站成一排，面向西边，每人头顶戴顶帽子，帽子有红黄蓝三种颜色，每个人只能看见自己前面的人的帽子的颜色，比如C可以看见A的和B的，A看不见任何人的帽子。现在有3顶红色帽子，2顶黄色帽子，1顶蓝色帽子，随机给这几个人带上。然后D说自己不知道自己是什么颜色，C说自己不知道自己是是什么颜色，B说自己不知道自己是什么颜色，A说自己知道自己是什么颜色，问A怎么推测的。在A说出自己帽子的颜色后，B、C、D能否确定自己帽子的颜色？\n- \n\n## 杂项 ##\n\n> **阿里春招实习**\n\n- 接触过什么开源项目\n- 最近读过的值得推荐的书是什么\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/2015-campus-recurit-technology-interview-summary.html\n\n**最后特别感谢2015年面点交流群各位伙伴的面筋:)**","slug":"2015-campus-recurit-technology-interview-summary","published":1,"updated":"2016-05-24T02:53:01.126Z","_id":"cinjqrkr7003rnfq69uqlaj42","comments":1,"layout":"post","photos":[],"link":"","sticky":0},{"title":"2015年校招求职总结","date":"2015-12-16T03:01:00.000Z","_content":"2015年，对于我而言，是充满忙碌和煎熬的一年。从去年年底到前不久，我几乎全是在实习，面试准备和面试中度过。从刚开始的迷茫，到中间的误打误撞，再到最终的尘埃落定，整个过程中我感受到了自己的成长和进步。\n\n非常感激一路上给予我指点的师兄师姐，实习期间的同事们以及共同求职的小伙伴们，他们在我面试前准备，获取面试机会及最终的工作选择上给予了很多的支持和帮助。如今自己也收获了一份非常满意的工作，在此对过去一年的求职历程（包括实习及校招）做一个总结，希望能够帮助后来人。\n\n本人求职的岗位是IT技术岗（偏机器学习背景的工程师岗位），不同行业，同一行业的不同职位，甚至不同公司的相同职位的求职都可能存在巨大的差异，所以本文尽量凸显求职中的共性问题，避免过多的求职细节。一些求职细节，比如面筋之类的会另辟博文。\n\n----------\n\n# **实习篇** #\n\n我是从研二上学期的末期开始实习的。累积了两段实习经历，分别是搜狗移动搜索研究部和微软（中国）互联网工程院的小冰项目组，实习时间都是半年。在搜狗实习，主要做的是移动端网页的优化排序，包括网页意图识别及用户个性化方面的基础性工作，实习工作主要是独立完成的，所以感觉这段时间学习到了挺多东西的；之后的暑期去了微软实习，在小冰组的CS项目组，CS(Customer Service)项目组主要是负责小冰的商业盈利，实现小冰与企业级客户的合作，例如与招商银行的智能客服项目等。在小冰组做的事情较零散，主要是因为市场需求和决策变化的关系，主要做了些特征工程及分类器训练，以及其他工程相关的工作，微软内部的code review是比较严格的，所以自己的工程能力得到较大的提高。\n\n现在回头看，个人觉得实习对于找工作来说优势还是很明显的，下面详细地介绍下关于实习的那些事儿。\n\n## 实习的前提条件 ##\n\n1. 实验室有较宽松的条件，主要是时间条件和导师的态度方面；\n2. 不影响正常的科研和毕业。\n\n## 实习有哪些好处 ##\n\n实习的好处是显而易见的，主要如下\n\n**1. 充实简历内容**\n\n一般来说，有1-2段的实习经历会让简历看起来更加充实，一般可以将“实习经历”放在“教育背景”和“专业技能”的后面。但是，实习内容需要与你最终求职的方向较相关，否则不太建议放在简历，简历上的东西尽量不要有冗余或者与求职目的背道而驰的内容（如应聘技术岗，尽量不要放太多文艺社团活动之类的）。关于如何书写一份好的简历，会在其他的博文中详述。\n\n值得说明的是，优秀的实习经历会给简历增色不少。建议实习选择平台较大，业界名气较大的公司进行实习，例如微软、谷歌、BAT之类的。这是因为，如果你能去知名的企业实习，一定程度上也说明了你的能力，因为去这些公司实习也是有一定门槛的。优秀的实习经历能让你在正式校招中，更容易得到同行中其他公司的认可。\n\n**2. 提升自身的技术能力及沟通合作能力**\n\n一般来说，在公司和在学校的时候还是有较大差别的。首先，公司以盈利为目的，在互联网公司中，一个项目往往需要能够迅速完成并不断地上线迭代，工作压力较大。其次，周边的同事们往往会比较专注于自己的事情，而且同事之间或许存在这样那样的利益冲突。所以，公司环境较学校环境复杂一些。\n\n现实情况下，产品需求往往是多变的，所以常常要求你能在短时间内快速学习新知识并给予实现。你也能遇到很多的机会，去实践你之前在书本上学习到的理论知识，所以实习对提升自身的技术实践能力有很大的帮助。而且，实习生一般需要经常与你的主管交流沟通，也可能需要和其他的同事合作，所以在这个过程中，你的沟通合作能力也将得到一定的提升。\n\n技术能力和沟通合作能力，是正式招聘面试中考察的两大核心点。在“校招篇”中，我将详细说明。\n\n**3. 人脉积累和可能的转正机会**\n\n实习过程中你能认识一些公司的正式员工或者和你一样的实习生们，这些人可能会在今后会提供一些直接或间接的工作机会，毕竟互联网圈子并不太大。更加重要的是，通过实习，你的表现优秀通常能够获得公司内部直接转正的机会，如果能够成功转正，那么你将在正式校招之前获得一份保底的offer。\n\n一般来说，每年的春季(4-5月份)会有很多大公司进行大规模的实习生招聘，这种类型的实习生往往是有转正机会的，而且公司也会把这一部分的实习生作为校招的提前备选人员。值得一说的是，通常而言公司更加青睐实习过并表现良好的同学，所以很多时候，通过先去该公司实习再转正会比直接参与该公司校招更加简单一些。\n\n**4. 经济上的回报**\n\n在互联网公司实习通常能够获得较高的工资（与其他传统行业相比），通常在月薪在3000-5000之间，当然也有网易游戏这样能够给出近万工资的土豪公司。但是，个人建议，**选择实习主要要以学东西和自己的兴趣方向为主**，不必贪恋这短短数个月的实习工资高低。\n\n## 如何获取实习机会 ##\n\n**1. 师兄师姐的内推**\n\n可以询问认识的师兄师姐，看看他们所在公司内部是否有相应的内推机会。一般而言，内推是互利的，一方面内推你的人如果内推成功往往能够获得一定的奖励；另一方面，相较于普通的实习生求职，内推的成功率会更高一些，因为公司更愿意选择自己员工所推荐的人选。\n\n**2. BBS论坛**\n\n找实习有几个常用的BBS论坛，分别是[北邮人兼职实习版块](http://bbs.byr.cn/#!board/ParttimeJob)，[水木社区实习版块](http://www.newsmth.net/bbsdoc.php?board=Intern)和[未名BBS实习版块](http://intern.bdwm.net/)等。\n\n**3. 相关的学生群**\n\n偶尔一些班级群、年级群等地方，也会有人发布一些实习信息。所以，可以多多加入一些同学群之类的，便于收集这方面的信息。\n\n## 实习面试前该怎么准备 ##\n\n**1. 筛选实习信息，确定候选的意向职位**\n\nBBS论坛上每天都会发布大量的实习信息，如果你对自己喜欢的以及以后要做的事情比较明确，那么筛选起来会比较简单；如果你是第一次找实习，或者对自己今后要做什么不太确定，建议可以按照如下进行筛选：\n\n- **排除自己不感兴趣的和不喜欢的**\n\n往往人对自己排斥的和没感觉的东西是比较明确的，所以可以先排除那些你不感兴趣的，甚至不喜欢的实习工作。\n\n- **总结自己的特长，过去的经历带给你的优势**\n\n举个例子，例如你之前在数学竞赛或者建模竞赛方面的经历较丰富并且还获过一些奖项，那么一方面说明你潜意识里对数学方面还是比较喜欢的，并且比一般的人更擅长；另一方面，这些经历对你申请数据分析师或者算法工程师等需要数据基础较好的职位，会有很大的优势。那么这些职位就可以成为你的候选职位了。\n\n另外，又例如你尽管没有互联网产品相关的经历，但是由于之前听过相关的讲座活动，比较感兴趣并想深入了解下。那么也可以将这样的职位作为你的备选，寻找实习和实习准备的过程中，你也会更加了解这些职位是干什么的，自己究竟喜不喜欢。\n\n总之，投递实习时可以针对自身的特长兴趣和经历进行选择，多了解和多尝试总是没错的。\n\n**2. 针对职位和自身，制作简历**\n\n一份内容优质和格式清晰的简历，能够给你争取一个好的第一印象，也是获取下一步面试资格的必要条件。简单来说，简历需要包含以下条目（排名分前后）：(1)基本的个人信息，包括姓名和联系方式；(2)教育背景，包括学校、学历、专业、GPA及排名情况；(3)专业技能；(4)实习经历/科研经历/项目经历；(5)在校期间获得的各种荣誉和奖励（尽量和所投的职位相关）；(6)社会实践和个人评价（可省略）。\n\n针对职位制作简历的要点在于，尽量在简历中突出该职位要求的要点，举个例子，下面是某BBS上一则实习生招聘信息：\n\n\t数据挖掘实习生\n\t\n\t工作职责:\n\to 数据采集/信息挖掘提取及相关工具开发\n\to 数据处理流程及相关工具开发\n\n\t任职资格:\n\to 熟悉 C/C++，有爬虫开发经验，并有相关实际项目经验以及脚本经验\n\to 熟练掌握至少一门常用脚本语言\n\to 优秀的分析问题和解决问题的能力\n\to 有良好的学习能力及团队合作精神\n\n如果希望投递该职位，那么简历上最好突出几条：\n\n\t(1) 熟悉C/C++编程，良好的编程规范\n\t(2) 熟悉某种脚本编程语言，例如Python或者Shell...\n\t(3) 有过相关的项目经历，如自己用Python编写过爬虫软件，实现了某某功能等\n\n换位思考，如果我们是该公司的HR，即使不懂技术，暂从简历上看会觉得这个同学和该职位比较匹配，至少会给该同学一个面试机会。\n\n针对自身制作简历的要点在于，**认清自己的能力，不要过分谦虚，也不要过分夸奖**。简历本身是一种对自己的包装，所以尽量真实地表达自己，请注意在简历中慎用**“精通”**两字，自己都不熟悉的项目经历最好不要写上简历，总之请确保你对简历上的每一句话都有足够的自信和充分的解释能力。\n\n**3. 投递简历的情商**\n\n论坛上常常充斥着大量的实习招聘信息，而背后的求职者往往要比这多几个数量级。所以对于实习的发布者而言，通常也能够收到大量的求职邮件和求职者的简历信息。下面有一些我自己总结的投递简历的注意事项，\n\n(1) 如果实习招聘信息中有明确的邮件发送格式，请严格按照该格式撰写邮件。因为很有可能招聘人员是编写了一些基于规则的脚本解析程序，来对大量的邮件进行分类和整理的，如果你发的邮件格式不合要求，很有可能会被淹没在收件箱中。\n\n(2) 如果实习招聘信息中没有明确的邮件发送格式，一般而言，邮件的标题可写为“[实习]职位+学校+学历+专业+姓名”，最好让收件人一看邮件标题就知道邮件的来意；邮件的正文可以简单的介绍一下自己的基本情况和个人优势（引起对方阅读你简历的兴趣），注意礼貌；最后记得附上你的简历即可（最好是pdf格式的，因为word格式有可能不同版本的软件打开格式会乱）。\n\n下面是一个示例的邮件正文模板，\n\n\t您好：\n\t\n\t在***看到您的实习招聘信息，对该职位很感兴趣并有一定的基础及实践经历。\n\t附件为我的中英文简历，请查阅。\n\t\n\t期待您的回复。\n\t谢谢，祝好。\n\n可做参考。\n\n**4. 针对职位，准备面试内容**\n\n面试准备主要包括两部分，一是熟悉你的简历，要求能够对简历上的任何一个项目都足够熟悉，可以提前思考可能存在的问题及当时的解决方法；二是准备技术面试，如果是投递IT技术岗位，基本的算法和数据结构要比较熟悉，其次是你熟悉的语言方面的细节问题（如Java中的容器底层实现之类的），如果你投递的岗位有相关背景，你还需要额外准备一下背景知识，如机器学习背景的，你需要熟悉常见的机器学习算法及简单的原理公式等。\n\n\n## 如何选择一份好的实习 ##\n\n考虑如下因素（排名有先后）\n\n- **是否有助于你的职业发展？**\n\n例如如果你今后希望做数据相关的岗位，实习也应该选择类似的职位，因为这段实习经历将会对你今后正式求职过程中给予直接的帮助。几乎所有公司都希望招聘有过职位相关经验的人员。\n\n- **是不是你所感兴趣的，有热情的？**\n\n选择自己感兴趣和有热情的岗位，将不会让你在实习过程中感到无聊和乏味。如果实在没有感兴趣的岗位，那就将这次的实习当做是一次尝试也未尝不可。\n\n- **你能获取的资源有哪些？**\n\n去大公司实习，往往能够学习到大公司中的做事规范，也能认识许多经验丰富的前辈。去小公司实习，往往自己身上的事情会比较多，做事情或许没有那么规范，但是需要你短时间能去学习很多东西。所以，不论在哪种环境下，你都要充分观察你能获取的资源有哪些？哪里的资源对你更加有利。\n\n- **其他因素**\n\n例如，待遇情况，离校距离远近，软性福利，工作时间及压力等。\n\n## 实习期间你需要注意的事项 ##\n\n- **时间观念很重要**\n\n时间观念包括了很多方面，例如保证实习时间（按之前约定的一周几天之类的，有事情一定要记得请假），开组会不要迟到，不要轻易拖后项目的ddl等。\n\n- **与你的主管保持充分沟通**\n\n充分沟通包括，一是主动去寻找任务，弄清楚你主管的任务需求，然后尽量去完成；二是明确任务中各项细节，确保你做的东西是你主管真正需要的；三是，时刻让你的主管知道你的任务进度和遇到的问题。\n\n沟通的方式有很多种，面对面，邮件，电话或信息等。总之，不要胆怯，有问题或者想法尽量去找你的主管交流，他有这个责任帮助和指导你。如果你的主管比较忙，你可以多用书面的形式（例如邮件）进行沟通。\n\n## “特殊”的实习？ ##\n\n一般来说，每年的春季，大概在3-4月份会有许多公司进行暑期实习生的招聘，与平时所招聘的实习生相比，这种类型的实习生往往是具有直接转正机会的，而且流程简单，成功概率较大。例如，微软中国的实习生分为project intern和summer intern两种，summer intern的转正面试一般只需要1-2轮，而project intern的转正面试一般在3轮以上。\n\n----------\n\n# **校招篇 **#\n\n## 校招什么时候开始 ##\n\n校招主要分秋招和春招两批，秋招的时间段为9-12月份，而春招则在下年的3-5月份，秋招的求职机会较春招会多很多，很多企业如果秋招招满就不进行春招了。一般来说，互联网相关企业（包括BAT等私企，MS、GG等外企，华为等国企）的校招在每年的9-11月份比较集中，而研究所、银行以及其他大多数国企一般会稍晚一些，主要集中在11-12月份。\n\n## 如何获取校招信息 ##\n\n校招信息可以通过以下渠道获得：\n\n- 各企业的官方网站中的招聘专栏，相应的微信公众号、微博号等；\n- 高校BBS以及求职相关的群；\n- 学校举办的校招宣讲会\n- 同学、同行们的分享信息；\n\n总之，多关注自己心仪公司的官网里的校招信息（可关注其微博号、微信号等），多关注学校的BBS求职相关的版面，以及就业中心发布的企业宣讲会信息，还有多和周边一起求职的同学们多交流。\n\n## 校招面试的形式及注意事项 ##\n\n一般来说，除了内推之外，正式校招时在获得面试通知前，会先进行投递简历和笔试等流程。如果简历和笔试关都顺利通过，那么你就能进入正式的面试环节了。面试的形式主要有两种，单面和群面。对于技术面试，一般是一对一的面试；对于产品、运营等方面的面试，有可能会有群面。由于本人投递的是技术岗，所以没有遭遇过群面，下面主要讲讲技术面试的流程及注意事项。\n\n对于技术岗，正式校招一般会有1-4轮的技术面试+1轮的HR面试。技术面试主要是考察你的技术能力、表达能力以及沟通能力，普遍的流程是\n\n1.自我介绍 -> 2.谈谈简历上的内容(论文、项目、实习经历等) -> 3.技术测试题(算法题、系统设计、数学题、智力题等)\n\n以上1和2并不是必须的，有些公司为节省时间可能会直接上来让你做题(如GG)。不同方向岗位的技术测试题可能各有偏重，其中，算法题是最常见的，主要考察算法、数据结构及你的基本编程能力，题型可参照`[leetcode]`上的题目。如果你是求职C++开发岗，C++语言特性及细节是你需要重点准备的；如果你是求职机器学习相关岗位，那么你需要熟悉常用的分类、聚类算法，对一些常见简单的模型，要能够进行公式推导(如LR,朴素贝叶斯等)。\n\n## 校招面试前该如何准备 ##\n\n**1. 准备一段精简的自我介绍**\n\n自我介绍往往是面试的开场白，一方面你可以进行下预热，逐渐进入面试状态；另一方面，也有助于面试官在极短的时间内对你有一定的了解，并有一定时间可以浏览你的简历。所以，为了使得面试官在几分钟内对你产生一个较好的第一印象，你需要在自我介绍中释放出足够的信息量，以让对方觉得你的资历与岗位要求是匹配的。\n\n自我介绍的时间一般在1-3分钟，如果对方有时间上的要求，自我介绍就尽量简短，包含要点即可。自我介绍一般包含以下几个要素（主要针对技术岗面试）：\n\n- 基本信息（姓名，学校学院，专业，研究方向等）\n- 专业技能（熟悉的编程语言，工具平台，技能达到的熟练程度等）\n- 实习/项目/论文经历（你在什么时间做了什么事情，担任的什么角色，最终获得的结果和成就）\n- 强调你的求职目标及意愿（表达你对该职位的强烈兴趣和意愿）\n\n其中，**专业技能**和**实习/项目/论文经历**最好与你求职的岗位要求相关，即你的自我介绍中的每一句话应该都要对你求职该岗位是有利的。自我介绍时，如果是面对面的面试，注意目光应该平视，时不时应该要与面试官有眼神交流，（在电话面试中）表达要自信流畅，给别人一种靠谱踏实的感觉。\n\n**2. 熟悉简历上的内容**\n\n面试时最好随身携带简历，一来表示你的求职态度比较真诚；二来防止面试官忘记打印你的简历。对于简历上的内容，应该要做到**对其中的每一项内容都足够熟悉，足够自信并且有能力来给予证明**。\n\n根据经验，需要注意一下的情形：\n\n- **避免出现`精通`、`特别擅长`等较极端词汇**\n\n如果你确实是个大神，请忽略这条。否则，最好用一些较平和的词汇，如`熟悉`、`了解`、`比较擅长`等。这样做的好处是，即使你在面试中遇到某一方面不会的问题，也有一个台阶下，不至于尴尬；否则，如果一开始给别人一个很高的期望值，而结果距离该期望值太远，那么面试官给你no hire的结果也就有充分理由了。总之，尽量保持谦逊的态度，因为谦逊的人往往更易于相处与合作。\n\n- **删去有陌生感和不确定的简历内容**\n\n有一些项目经历，可能是你本科时候的经历，（如果你已经是硕博士）这对你可能会有一些陌生和模糊感。如果你确实不太记得其中的很多技术细节，最好不要写在简历上，因为万一面试官问起，你又支支吾吾地回答，会给人一种不自信或者不诚信的感觉。类似的相关简历内容都最后删去。\n\n**3. 技术面试准备**\n\n对于IT的技术面试，算法题是最常见的题型，主要是因为算法题可以在短时间内对应试者的算法、数据结构、编程语言及风格等方面进行考察。对于`算法题`的相关准备，有以下的一些建议：\n\n- 选择常见的编程语言（最好是面试官所熟悉的），例如C/C++/Java/Python等；\n- 勤刷算法题，相关的OJ练习平台有[leetcode](https://oj.leetcode.com/problems/)、[lintcode](http://www.lintcode.com/)、国内的[九度](http://ac.jobdu.com/)等；\n- 打好算法及数据结构基础，推荐书籍如下：算法面试相关的有《Crack the code interview》、《剑指Offer》、《微软经典面试100题系列》和《编程之美》等；算法理论相关的有《算法导论》、《算法设计与分析》(屈婉玲版)和《Java数据结构和算法》(Robert Lafore版)。\n\n除了算法题之外，技术面试中常考察的还有`编程语言的相关细节`、`数据结构`、`操作系统`、`数据库`和`系统设计`等。`编程语言方面`的考察，一般会以你熟悉的编程语言或者是岗位所要求的编程语言为主。例如，C++中常见的考点是指针、const用法、虚函数、构造函数与构析函数等；Java则是垃圾回收机制、容器细节等(如ArrayList和LinkedList的区别，HashTable和HashMap的区别等)。`数据结构方面`，一定要熟悉常见的数据结构（链表、二叉树及BST、栈及队列、哈希表等），并要能够给予实现，对于高级的数据结构（如红黑树、后缀数组等）做简单了解即可，当然如果你面试GG这样的公司，或许能够深入理解则是更好的；`操作系统方面`需要掌握一些常见问题，如进程和线程的区别、常见的调度算法等；`数据库方面`需要对常见的数据库管理软件例如MySQL有所了解，能够编写简单的SQL语句，推荐的入门书籍有《SQL必知必会》，然后刷刷leetcode上的SQL相关的题即可。`系统设计方面`主要熟悉一些常见的系统模式，如工厂模式和单例模式等，要能够做简单的实现。\n\n技术面试除了以上之外，可能会根据求职方向的不同有所偏倚，例如求职大数据相关的职位，可能需要了解常见的大数据工具如Hadoop，Spark等的原理和使用。技术面试准备时，可以结合职位要求中的条目，如果职位要求中有一些你必备的技术，这方面则需要尽量准备。\n\n**4. HR面试注意事项**\n\n如果前面的技术面试顺利，将会进入到HR面试。一般来说，很多公司的HR面试是终面，所以也不能掉以轻心。HR面试的内容可能有以下项目：\n\n- **基本信息**：包括你的学历情况，基本的家庭情况，对公司和职位的感兴趣和了解程度等。主要考察你的个人信息，家庭对你的期望，以及你对公司和职位的渴求程度。\n- **性格和处事能力**：这一部分可能会问一些你的经历，包括项目经历和实习经历等。[你过程中遇到的困难是什么，如何解决的？]，[你遇到问题是怎么和上级沟通的？]等问题，可以体现出你是一个什么样性格的人，沟通能力以及解决困难的能力。\n\nHR面试中尽量表现出自己积极自信的一面，表现出自己对该职位的感兴趣和渴望。回答问题时，注意目光要平视，语速平顺；进出面试时，要注意基本礼仪；最后，注意态度要真诚，要相信HR阅人无数，撒谎是很容易被识别出来的。\n\n## 模拟？模拟！ ##\n\n如果可以的话，最好找一些职场上的前辈或者同学，给自己做一下模拟面试。模拟面试可以让你提前熟悉面试流程，减轻正式面试过程中的紧张感。最重要的是，可以与你的那位[面试官]进行角色互换，从别人和另一个角度，对自己和别人身上存在的问题进行校正。如果是外企的英文面试，那么模拟面试是十分重要和需要的。\n\n## 面试中的“潜规则” ##\n\n- 不要在技术面试中，问及薪资待遇等与技术无关的问题；\n- 技术面试中，尽量表现出你对该职位的兴趣和热情，轮到你提问时，可以问一下近期的项目情况、遇到的问题及目前的解决方法等，对其中感兴趣的问题可以深入了解；\n- 面试结束后，不要急切地问面试结果如何，但是可以问面试结果的通知时间；\n- 一般来说，如果面试通过，那么你将很快接受到下一轮面试的信息；如果等待了超过一周时间，则很有可能被默拒；很多公司不会发拒信。\n- 面试准备的过程中，多换位思考，假想你是面试官，希望给什么样的面试者机会；多总结，不论面试结果成功还是失败，可以总结总结面筋及经验。\n\n## 如何谈offer ##\n\n如果你顺利通过了所有的面试，那么接下来HR会和你沟通职位信息，包括所在部门、职位、级别及薪资。大多数公司定薪水的依据，一般是你的面试表现，也会和你的学历、个人期望值有关。大多数公司的offer都会有两个档位，普通和special，档位相对应的薪水一般是固定的，没有太多的谈判空间。\n\n但是，有一些公司（尤其是创业型公司，例如滴滴、京东等）可以依人给不同价位的offer，这时候就需要去谈offer了。这时谈offer主要看你对公司的稀缺程度及手上的offer情况，当你拿到一些该公司竞争对手的offer时，对谈offer是极其有利的，因为如果该公司不能够给予至少同等的待遇是不够具有吸引力的。谈offer时，你可以告诉HR你目前手上的offer以及你的期望薪资，表明出如果对方公司愿意用更高的offer，你就会归顺于该公司的决心。\n\n当然，谈offer也要适可而止，对于一个缺乏工作经验和社会经验的应届生而言，公司的争取力度也是有限的。摆正自己的姿态很重要。\n\n## 如何选择一份好的工作 ##\n\n推荐使用[offer比较器](http://web.yingjiesheng.com/offer/)。\n\n## 找完工作后该如何规划 ##\n\n- 完成毕业论文，按时毕业；\n- 技术充电；\n- 完成毕业前的小心愿，或者索性旅游、玩耍一小段时间；\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/2015-campus-recruit-summary.html\n\n**推荐资料**\n\n[连续创业者：如何招聘到适合的员工](http://www.geekpark.net/topics/214781)","source":"_posts/2015-campus-recruit-summary.md","raw":"title: 2015年校招求职总结\ndate: 2015-12-16 11:01:00\ntags: [Interview, Job, IT]\ncategories: Interview\n---\n2015年，对于我而言，是充满忙碌和煎熬的一年。从去年年底到前不久，我几乎全是在实习，面试准备和面试中度过。从刚开始的迷茫，到中间的误打误撞，再到最终的尘埃落定，整个过程中我感受到了自己的成长和进步。\n\n非常感激一路上给予我指点的师兄师姐，实习期间的同事们以及共同求职的小伙伴们，他们在我面试前准备，获取面试机会及最终的工作选择上给予了很多的支持和帮助。如今自己也收获了一份非常满意的工作，在此对过去一年的求职历程（包括实习及校招）做一个总结，希望能够帮助后来人。\n\n本人求职的岗位是IT技术岗（偏机器学习背景的工程师岗位），不同行业，同一行业的不同职位，甚至不同公司的相同职位的求职都可能存在巨大的差异，所以本文尽量凸显求职中的共性问题，避免过多的求职细节。一些求职细节，比如面筋之类的会另辟博文。\n\n----------\n\n# **实习篇** #\n\n我是从研二上学期的末期开始实习的。累积了两段实习经历，分别是搜狗移动搜索研究部和微软（中国）互联网工程院的小冰项目组，实习时间都是半年。在搜狗实习，主要做的是移动端网页的优化排序，包括网页意图识别及用户个性化方面的基础性工作，实习工作主要是独立完成的，所以感觉这段时间学习到了挺多东西的；之后的暑期去了微软实习，在小冰组的CS项目组，CS(Customer Service)项目组主要是负责小冰的商业盈利，实现小冰与企业级客户的合作，例如与招商银行的智能客服项目等。在小冰组做的事情较零散，主要是因为市场需求和决策变化的关系，主要做了些特征工程及分类器训练，以及其他工程相关的工作，微软内部的code review是比较严格的，所以自己的工程能力得到较大的提高。\n\n现在回头看，个人觉得实习对于找工作来说优势还是很明显的，下面详细地介绍下关于实习的那些事儿。\n\n## 实习的前提条件 ##\n\n1. 实验室有较宽松的条件，主要是时间条件和导师的态度方面；\n2. 不影响正常的科研和毕业。\n\n## 实习有哪些好处 ##\n\n实习的好处是显而易见的，主要如下\n\n**1. 充实简历内容**\n\n一般来说，有1-2段的实习经历会让简历看起来更加充实，一般可以将“实习经历”放在“教育背景”和“专业技能”的后面。但是，实习内容需要与你最终求职的方向较相关，否则不太建议放在简历，简历上的东西尽量不要有冗余或者与求职目的背道而驰的内容（如应聘技术岗，尽量不要放太多文艺社团活动之类的）。关于如何书写一份好的简历，会在其他的博文中详述。\n\n值得说明的是，优秀的实习经历会给简历增色不少。建议实习选择平台较大，业界名气较大的公司进行实习，例如微软、谷歌、BAT之类的。这是因为，如果你能去知名的企业实习，一定程度上也说明了你的能力，因为去这些公司实习也是有一定门槛的。优秀的实习经历能让你在正式校招中，更容易得到同行中其他公司的认可。\n\n**2. 提升自身的技术能力及沟通合作能力**\n\n一般来说，在公司和在学校的时候还是有较大差别的。首先，公司以盈利为目的，在互联网公司中，一个项目往往需要能够迅速完成并不断地上线迭代，工作压力较大。其次，周边的同事们往往会比较专注于自己的事情，而且同事之间或许存在这样那样的利益冲突。所以，公司环境较学校环境复杂一些。\n\n现实情况下，产品需求往往是多变的，所以常常要求你能在短时间内快速学习新知识并给予实现。你也能遇到很多的机会，去实践你之前在书本上学习到的理论知识，所以实习对提升自身的技术实践能力有很大的帮助。而且，实习生一般需要经常与你的主管交流沟通，也可能需要和其他的同事合作，所以在这个过程中，你的沟通合作能力也将得到一定的提升。\n\n技术能力和沟通合作能力，是正式招聘面试中考察的两大核心点。在“校招篇”中，我将详细说明。\n\n**3. 人脉积累和可能的转正机会**\n\n实习过程中你能认识一些公司的正式员工或者和你一样的实习生们，这些人可能会在今后会提供一些直接或间接的工作机会，毕竟互联网圈子并不太大。更加重要的是，通过实习，你的表现优秀通常能够获得公司内部直接转正的机会，如果能够成功转正，那么你将在正式校招之前获得一份保底的offer。\n\n一般来说，每年的春季(4-5月份)会有很多大公司进行大规模的实习生招聘，这种类型的实习生往往是有转正机会的，而且公司也会把这一部分的实习生作为校招的提前备选人员。值得一说的是，通常而言公司更加青睐实习过并表现良好的同学，所以很多时候，通过先去该公司实习再转正会比直接参与该公司校招更加简单一些。\n\n**4. 经济上的回报**\n\n在互联网公司实习通常能够获得较高的工资（与其他传统行业相比），通常在月薪在3000-5000之间，当然也有网易游戏这样能够给出近万工资的土豪公司。但是，个人建议，**选择实习主要要以学东西和自己的兴趣方向为主**，不必贪恋这短短数个月的实习工资高低。\n\n## 如何获取实习机会 ##\n\n**1. 师兄师姐的内推**\n\n可以询问认识的师兄师姐，看看他们所在公司内部是否有相应的内推机会。一般而言，内推是互利的，一方面内推你的人如果内推成功往往能够获得一定的奖励；另一方面，相较于普通的实习生求职，内推的成功率会更高一些，因为公司更愿意选择自己员工所推荐的人选。\n\n**2. BBS论坛**\n\n找实习有几个常用的BBS论坛，分别是[北邮人兼职实习版块](http://bbs.byr.cn/#!board/ParttimeJob)，[水木社区实习版块](http://www.newsmth.net/bbsdoc.php?board=Intern)和[未名BBS实习版块](http://intern.bdwm.net/)等。\n\n**3. 相关的学生群**\n\n偶尔一些班级群、年级群等地方，也会有人发布一些实习信息。所以，可以多多加入一些同学群之类的，便于收集这方面的信息。\n\n## 实习面试前该怎么准备 ##\n\n**1. 筛选实习信息，确定候选的意向职位**\n\nBBS论坛上每天都会发布大量的实习信息，如果你对自己喜欢的以及以后要做的事情比较明确，那么筛选起来会比较简单；如果你是第一次找实习，或者对自己今后要做什么不太确定，建议可以按照如下进行筛选：\n\n- **排除自己不感兴趣的和不喜欢的**\n\n往往人对自己排斥的和没感觉的东西是比较明确的，所以可以先排除那些你不感兴趣的，甚至不喜欢的实习工作。\n\n- **总结自己的特长，过去的经历带给你的优势**\n\n举个例子，例如你之前在数学竞赛或者建模竞赛方面的经历较丰富并且还获过一些奖项，那么一方面说明你潜意识里对数学方面还是比较喜欢的，并且比一般的人更擅长；另一方面，这些经历对你申请数据分析师或者算法工程师等需要数据基础较好的职位，会有很大的优势。那么这些职位就可以成为你的候选职位了。\n\n另外，又例如你尽管没有互联网产品相关的经历，但是由于之前听过相关的讲座活动，比较感兴趣并想深入了解下。那么也可以将这样的职位作为你的备选，寻找实习和实习准备的过程中，你也会更加了解这些职位是干什么的，自己究竟喜不喜欢。\n\n总之，投递实习时可以针对自身的特长兴趣和经历进行选择，多了解和多尝试总是没错的。\n\n**2. 针对职位和自身，制作简历**\n\n一份内容优质和格式清晰的简历，能够给你争取一个好的第一印象，也是获取下一步面试资格的必要条件。简单来说，简历需要包含以下条目（排名分前后）：(1)基本的个人信息，包括姓名和联系方式；(2)教育背景，包括学校、学历、专业、GPA及排名情况；(3)专业技能；(4)实习经历/科研经历/项目经历；(5)在校期间获得的各种荣誉和奖励（尽量和所投的职位相关）；(6)社会实践和个人评价（可省略）。\n\n针对职位制作简历的要点在于，尽量在简历中突出该职位要求的要点，举个例子，下面是某BBS上一则实习生招聘信息：\n\n\t数据挖掘实习生\n\t\n\t工作职责:\n\to 数据采集/信息挖掘提取及相关工具开发\n\to 数据处理流程及相关工具开发\n\n\t任职资格:\n\to 熟悉 C/C++，有爬虫开发经验，并有相关实际项目经验以及脚本经验\n\to 熟练掌握至少一门常用脚本语言\n\to 优秀的分析问题和解决问题的能力\n\to 有良好的学习能力及团队合作精神\n\n如果希望投递该职位，那么简历上最好突出几条：\n\n\t(1) 熟悉C/C++编程，良好的编程规范\n\t(2) 熟悉某种脚本编程语言，例如Python或者Shell...\n\t(3) 有过相关的项目经历，如自己用Python编写过爬虫软件，实现了某某功能等\n\n换位思考，如果我们是该公司的HR，即使不懂技术，暂从简历上看会觉得这个同学和该职位比较匹配，至少会给该同学一个面试机会。\n\n针对自身制作简历的要点在于，**认清自己的能力，不要过分谦虚，也不要过分夸奖**。简历本身是一种对自己的包装，所以尽量真实地表达自己，请注意在简历中慎用**“精通”**两字，自己都不熟悉的项目经历最好不要写上简历，总之请确保你对简历上的每一句话都有足够的自信和充分的解释能力。\n\n**3. 投递简历的情商**\n\n论坛上常常充斥着大量的实习招聘信息，而背后的求职者往往要比这多几个数量级。所以对于实习的发布者而言，通常也能够收到大量的求职邮件和求职者的简历信息。下面有一些我自己总结的投递简历的注意事项，\n\n(1) 如果实习招聘信息中有明确的邮件发送格式，请严格按照该格式撰写邮件。因为很有可能招聘人员是编写了一些基于规则的脚本解析程序，来对大量的邮件进行分类和整理的，如果你发的邮件格式不合要求，很有可能会被淹没在收件箱中。\n\n(2) 如果实习招聘信息中没有明确的邮件发送格式，一般而言，邮件的标题可写为“[实习]职位+学校+学历+专业+姓名”，最好让收件人一看邮件标题就知道邮件的来意；邮件的正文可以简单的介绍一下自己的基本情况和个人优势（引起对方阅读你简历的兴趣），注意礼貌；最后记得附上你的简历即可（最好是pdf格式的，因为word格式有可能不同版本的软件打开格式会乱）。\n\n下面是一个示例的邮件正文模板，\n\n\t您好：\n\t\n\t在***看到您的实习招聘信息，对该职位很感兴趣并有一定的基础及实践经历。\n\t附件为我的中英文简历，请查阅。\n\t\n\t期待您的回复。\n\t谢谢，祝好。\n\n可做参考。\n\n**4. 针对职位，准备面试内容**\n\n面试准备主要包括两部分，一是熟悉你的简历，要求能够对简历上的任何一个项目都足够熟悉，可以提前思考可能存在的问题及当时的解决方法；二是准备技术面试，如果是投递IT技术岗位，基本的算法和数据结构要比较熟悉，其次是你熟悉的语言方面的细节问题（如Java中的容器底层实现之类的），如果你投递的岗位有相关背景，你还需要额外准备一下背景知识，如机器学习背景的，你需要熟悉常见的机器学习算法及简单的原理公式等。\n\n\n## 如何选择一份好的实习 ##\n\n考虑如下因素（排名有先后）\n\n- **是否有助于你的职业发展？**\n\n例如如果你今后希望做数据相关的岗位，实习也应该选择类似的职位，因为这段实习经历将会对你今后正式求职过程中给予直接的帮助。几乎所有公司都希望招聘有过职位相关经验的人员。\n\n- **是不是你所感兴趣的，有热情的？**\n\n选择自己感兴趣和有热情的岗位，将不会让你在实习过程中感到无聊和乏味。如果实在没有感兴趣的岗位，那就将这次的实习当做是一次尝试也未尝不可。\n\n- **你能获取的资源有哪些？**\n\n去大公司实习，往往能够学习到大公司中的做事规范，也能认识许多经验丰富的前辈。去小公司实习，往往自己身上的事情会比较多，做事情或许没有那么规范，但是需要你短时间能去学习很多东西。所以，不论在哪种环境下，你都要充分观察你能获取的资源有哪些？哪里的资源对你更加有利。\n\n- **其他因素**\n\n例如，待遇情况，离校距离远近，软性福利，工作时间及压力等。\n\n## 实习期间你需要注意的事项 ##\n\n- **时间观念很重要**\n\n时间观念包括了很多方面，例如保证实习时间（按之前约定的一周几天之类的，有事情一定要记得请假），开组会不要迟到，不要轻易拖后项目的ddl等。\n\n- **与你的主管保持充分沟通**\n\n充分沟通包括，一是主动去寻找任务，弄清楚你主管的任务需求，然后尽量去完成；二是明确任务中各项细节，确保你做的东西是你主管真正需要的；三是，时刻让你的主管知道你的任务进度和遇到的问题。\n\n沟通的方式有很多种，面对面，邮件，电话或信息等。总之，不要胆怯，有问题或者想法尽量去找你的主管交流，他有这个责任帮助和指导你。如果你的主管比较忙，你可以多用书面的形式（例如邮件）进行沟通。\n\n## “特殊”的实习？ ##\n\n一般来说，每年的春季，大概在3-4月份会有许多公司进行暑期实习生的招聘，与平时所招聘的实习生相比，这种类型的实习生往往是具有直接转正机会的，而且流程简单，成功概率较大。例如，微软中国的实习生分为project intern和summer intern两种，summer intern的转正面试一般只需要1-2轮，而project intern的转正面试一般在3轮以上。\n\n----------\n\n# **校招篇 **#\n\n## 校招什么时候开始 ##\n\n校招主要分秋招和春招两批，秋招的时间段为9-12月份，而春招则在下年的3-5月份，秋招的求职机会较春招会多很多，很多企业如果秋招招满就不进行春招了。一般来说，互联网相关企业（包括BAT等私企，MS、GG等外企，华为等国企）的校招在每年的9-11月份比较集中，而研究所、银行以及其他大多数国企一般会稍晚一些，主要集中在11-12月份。\n\n## 如何获取校招信息 ##\n\n校招信息可以通过以下渠道获得：\n\n- 各企业的官方网站中的招聘专栏，相应的微信公众号、微博号等；\n- 高校BBS以及求职相关的群；\n- 学校举办的校招宣讲会\n- 同学、同行们的分享信息；\n\n总之，多关注自己心仪公司的官网里的校招信息（可关注其微博号、微信号等），多关注学校的BBS求职相关的版面，以及就业中心发布的企业宣讲会信息，还有多和周边一起求职的同学们多交流。\n\n## 校招面试的形式及注意事项 ##\n\n一般来说，除了内推之外，正式校招时在获得面试通知前，会先进行投递简历和笔试等流程。如果简历和笔试关都顺利通过，那么你就能进入正式的面试环节了。面试的形式主要有两种，单面和群面。对于技术面试，一般是一对一的面试；对于产品、运营等方面的面试，有可能会有群面。由于本人投递的是技术岗，所以没有遭遇过群面，下面主要讲讲技术面试的流程及注意事项。\n\n对于技术岗，正式校招一般会有1-4轮的技术面试+1轮的HR面试。技术面试主要是考察你的技术能力、表达能力以及沟通能力，普遍的流程是\n\n1.自我介绍 -> 2.谈谈简历上的内容(论文、项目、实习经历等) -> 3.技术测试题(算法题、系统设计、数学题、智力题等)\n\n以上1和2并不是必须的，有些公司为节省时间可能会直接上来让你做题(如GG)。不同方向岗位的技术测试题可能各有偏重，其中，算法题是最常见的，主要考察算法、数据结构及你的基本编程能力，题型可参照`[leetcode]`上的题目。如果你是求职C++开发岗，C++语言特性及细节是你需要重点准备的；如果你是求职机器学习相关岗位，那么你需要熟悉常用的分类、聚类算法，对一些常见简单的模型，要能够进行公式推导(如LR,朴素贝叶斯等)。\n\n## 校招面试前该如何准备 ##\n\n**1. 准备一段精简的自我介绍**\n\n自我介绍往往是面试的开场白，一方面你可以进行下预热，逐渐进入面试状态；另一方面，也有助于面试官在极短的时间内对你有一定的了解，并有一定时间可以浏览你的简历。所以，为了使得面试官在几分钟内对你产生一个较好的第一印象，你需要在自我介绍中释放出足够的信息量，以让对方觉得你的资历与岗位要求是匹配的。\n\n自我介绍的时间一般在1-3分钟，如果对方有时间上的要求，自我介绍就尽量简短，包含要点即可。自我介绍一般包含以下几个要素（主要针对技术岗面试）：\n\n- 基本信息（姓名，学校学院，专业，研究方向等）\n- 专业技能（熟悉的编程语言，工具平台，技能达到的熟练程度等）\n- 实习/项目/论文经历（你在什么时间做了什么事情，担任的什么角色，最终获得的结果和成就）\n- 强调你的求职目标及意愿（表达你对该职位的强烈兴趣和意愿）\n\n其中，**专业技能**和**实习/项目/论文经历**最好与你求职的岗位要求相关，即你的自我介绍中的每一句话应该都要对你求职该岗位是有利的。自我介绍时，如果是面对面的面试，注意目光应该平视，时不时应该要与面试官有眼神交流，（在电话面试中）表达要自信流畅，给别人一种靠谱踏实的感觉。\n\n**2. 熟悉简历上的内容**\n\n面试时最好随身携带简历，一来表示你的求职态度比较真诚；二来防止面试官忘记打印你的简历。对于简历上的内容，应该要做到**对其中的每一项内容都足够熟悉，足够自信并且有能力来给予证明**。\n\n根据经验，需要注意一下的情形：\n\n- **避免出现`精通`、`特别擅长`等较极端词汇**\n\n如果你确实是个大神，请忽略这条。否则，最好用一些较平和的词汇，如`熟悉`、`了解`、`比较擅长`等。这样做的好处是，即使你在面试中遇到某一方面不会的问题，也有一个台阶下，不至于尴尬；否则，如果一开始给别人一个很高的期望值，而结果距离该期望值太远，那么面试官给你no hire的结果也就有充分理由了。总之，尽量保持谦逊的态度，因为谦逊的人往往更易于相处与合作。\n\n- **删去有陌生感和不确定的简历内容**\n\n有一些项目经历，可能是你本科时候的经历，（如果你已经是硕博士）这对你可能会有一些陌生和模糊感。如果你确实不太记得其中的很多技术细节，最好不要写在简历上，因为万一面试官问起，你又支支吾吾地回答，会给人一种不自信或者不诚信的感觉。类似的相关简历内容都最后删去。\n\n**3. 技术面试准备**\n\n对于IT的技术面试，算法题是最常见的题型，主要是因为算法题可以在短时间内对应试者的算法、数据结构、编程语言及风格等方面进行考察。对于`算法题`的相关准备，有以下的一些建议：\n\n- 选择常见的编程语言（最好是面试官所熟悉的），例如C/C++/Java/Python等；\n- 勤刷算法题，相关的OJ练习平台有[leetcode](https://oj.leetcode.com/problems/)、[lintcode](http://www.lintcode.com/)、国内的[九度](http://ac.jobdu.com/)等；\n- 打好算法及数据结构基础，推荐书籍如下：算法面试相关的有《Crack the code interview》、《剑指Offer》、《微软经典面试100题系列》和《编程之美》等；算法理论相关的有《算法导论》、《算法设计与分析》(屈婉玲版)和《Java数据结构和算法》(Robert Lafore版)。\n\n除了算法题之外，技术面试中常考察的还有`编程语言的相关细节`、`数据结构`、`操作系统`、`数据库`和`系统设计`等。`编程语言方面`的考察，一般会以你熟悉的编程语言或者是岗位所要求的编程语言为主。例如，C++中常见的考点是指针、const用法、虚函数、构造函数与构析函数等；Java则是垃圾回收机制、容器细节等(如ArrayList和LinkedList的区别，HashTable和HashMap的区别等)。`数据结构方面`，一定要熟悉常见的数据结构（链表、二叉树及BST、栈及队列、哈希表等），并要能够给予实现，对于高级的数据结构（如红黑树、后缀数组等）做简单了解即可，当然如果你面试GG这样的公司，或许能够深入理解则是更好的；`操作系统方面`需要掌握一些常见问题，如进程和线程的区别、常见的调度算法等；`数据库方面`需要对常见的数据库管理软件例如MySQL有所了解，能够编写简单的SQL语句，推荐的入门书籍有《SQL必知必会》，然后刷刷leetcode上的SQL相关的题即可。`系统设计方面`主要熟悉一些常见的系统模式，如工厂模式和单例模式等，要能够做简单的实现。\n\n技术面试除了以上之外，可能会根据求职方向的不同有所偏倚，例如求职大数据相关的职位，可能需要了解常见的大数据工具如Hadoop，Spark等的原理和使用。技术面试准备时，可以结合职位要求中的条目，如果职位要求中有一些你必备的技术，这方面则需要尽量准备。\n\n**4. HR面试注意事项**\n\n如果前面的技术面试顺利，将会进入到HR面试。一般来说，很多公司的HR面试是终面，所以也不能掉以轻心。HR面试的内容可能有以下项目：\n\n- **基本信息**：包括你的学历情况，基本的家庭情况，对公司和职位的感兴趣和了解程度等。主要考察你的个人信息，家庭对你的期望，以及你对公司和职位的渴求程度。\n- **性格和处事能力**：这一部分可能会问一些你的经历，包括项目经历和实习经历等。[你过程中遇到的困难是什么，如何解决的？]，[你遇到问题是怎么和上级沟通的？]等问题，可以体现出你是一个什么样性格的人，沟通能力以及解决困难的能力。\n\nHR面试中尽量表现出自己积极自信的一面，表现出自己对该职位的感兴趣和渴望。回答问题时，注意目光要平视，语速平顺；进出面试时，要注意基本礼仪；最后，注意态度要真诚，要相信HR阅人无数，撒谎是很容易被识别出来的。\n\n## 模拟？模拟！ ##\n\n如果可以的话，最好找一些职场上的前辈或者同学，给自己做一下模拟面试。模拟面试可以让你提前熟悉面试流程，减轻正式面试过程中的紧张感。最重要的是，可以与你的那位[面试官]进行角色互换，从别人和另一个角度，对自己和别人身上存在的问题进行校正。如果是外企的英文面试，那么模拟面试是十分重要和需要的。\n\n## 面试中的“潜规则” ##\n\n- 不要在技术面试中，问及薪资待遇等与技术无关的问题；\n- 技术面试中，尽量表现出你对该职位的兴趣和热情，轮到你提问时，可以问一下近期的项目情况、遇到的问题及目前的解决方法等，对其中感兴趣的问题可以深入了解；\n- 面试结束后，不要急切地问面试结果如何，但是可以问面试结果的通知时间；\n- 一般来说，如果面试通过，那么你将很快接受到下一轮面试的信息；如果等待了超过一周时间，则很有可能被默拒；很多公司不会发拒信。\n- 面试准备的过程中，多换位思考，假想你是面试官，希望给什么样的面试者机会；多总结，不论面试结果成功还是失败，可以总结总结面筋及经验。\n\n## 如何谈offer ##\n\n如果你顺利通过了所有的面试，那么接下来HR会和你沟通职位信息，包括所在部门、职位、级别及薪资。大多数公司定薪水的依据，一般是你的面试表现，也会和你的学历、个人期望值有关。大多数公司的offer都会有两个档位，普通和special，档位相对应的薪水一般是固定的，没有太多的谈判空间。\n\n但是，有一些公司（尤其是创业型公司，例如滴滴、京东等）可以依人给不同价位的offer，这时候就需要去谈offer了。这时谈offer主要看你对公司的稀缺程度及手上的offer情况，当你拿到一些该公司竞争对手的offer时，对谈offer是极其有利的，因为如果该公司不能够给予至少同等的待遇是不够具有吸引力的。谈offer时，你可以告诉HR你目前手上的offer以及你的期望薪资，表明出如果对方公司愿意用更高的offer，你就会归顺于该公司的决心。\n\n当然，谈offer也要适可而止，对于一个缺乏工作经验和社会经验的应届生而言，公司的争取力度也是有限的。摆正自己的姿态很重要。\n\n## 如何选择一份好的工作 ##\n\n推荐使用[offer比较器](http://web.yingjiesheng.com/offer/)。\n\n## 找完工作后该如何规划 ##\n\n- 完成毕业论文，按时毕业；\n- 技术充电；\n- 完成毕业前的小心愿，或者索性旅游、玩耍一小段时间；\n\n----------\n\n本文结束，感谢欣赏。\n\n**欢迎转载，请注明本文的链接地址：**\n\nhttp://www.jeyzhang.com/2015-campus-recruit-summary.html\n\n**推荐资料**\n\n[连续创业者：如何招聘到适合的员工](http://www.geekpark.net/topics/214781)","slug":"2015-campus-recruit-summary","published":1,"updated":"2016-03-08T00:55:30.999Z","_id":"cinjqrkrd0042nfq69ffe80ad","comments":1,"layout":"post","photos":[],"link":"","sticky":0}],"PostAsset":[],"PostCategory":[{"post_id":"cinjqrkp3001vnfq6jno1547e","category_id":"cinjqrknn0005nfq6t9al9hdm","_id":"cinjqrkp5001wnfq6kw49ivyw"},{"post_id":"cinjqrkpo002jnfq6xp9c0nlz","category_id":"cinjqrkop001bnfq6ykq7nfxt","_id":"cinjqrkpq002knfq6gyavcx2y"},{"post_id":"cinjqrkng0004nfq6w9qo4tag","category_id":"cinjqrknn0005nfq6t9al9hdm","_id":"cio41utus0000l8eqckku92i8"},{"post_id":"cinjqrkny000fnfq61fcpg4fs","category_id":"cinjqrknn0005nfq6t9al9hdm","_id":"cio41utv20001l8eq9duk5f16"},{"post_id":"cinjqrko4000lnfq6crlz8gln","category_id":"cinjqrknn0005nfq6t9al9hdm","_id":"cio41utva0002l8eq9jy9uwd1"},{"post_id":"cinjqrko9000rnfq6d7zjw8fd","category_id":"cinjqrkoh0011nfq6j35bk49c","_id":"cio41utvj0003l8eq2k1nmj3p"},{"post_id":"cinjqrkoe0010nfq6wf05dnk0","category_id":"cinjqrkoh0011nfq6j35bk49c","_id":"cio41utvw0004l8eqwfkzkhiw"},{"post_id":"cinjqrkoi0014nfq6kv333q81","category_id":"cinjqrknn0005nfq6t9al9hdm","_id":"cio41utw30005l8eqp4ei19g2"},{"post_id":"cinjqrkon001anfq629l03iq3","category_id":"cinjqrkop001bnfq6ykq7nfxt","_id":"cio41utwv0006l8eqepe2v3ua"},{"post_id":"cinjqrkos001hnfq6pvaxjriz","category_id":"cinjqrkou001infq6vbrbgpv0","_id":"cio41utx20007l8eqdnmhmcd6"},{"post_id":"cinjqrkoy001qnfq659wi68t2","category_id":"cinjqrkp0001rnfq6k3zc1k2x","_id":"cio41utx70008l8eqg2fe1ctd"},{"post_id":"cinjqrkp70023nfq6j880739p","category_id":"cinjqrkp0001rnfq6k3zc1k2x","_id":"cio41utxj0009l8eq3x9k5w6t"},{"post_id":"cinjqrkph002cnfq631h0zs2o","category_id":"cinjqrkop001bnfq6ykq7nfxt","_id":"cio41utxm000al8eqqyykyp7a"},{"post_id":"cinjqrkpt002pnfq6h2hvwrok","category_id":"cinjqrkop001bnfq6ykq7nfxt","_id":"cio41utxt000bl8eq08kge1ym"},{"post_id":"cinjqrkpz002ynfq6gp2j1ujv","category_id":"cinjqrknn0005nfq6t9al9hdm","_id":"cio41utxx000cl8equdlzamxq"},{"post_id":"cinjqrkq30034nfq6zq4gigcp","category_id":"cinjqrknn0005nfq6t9al9hdm","_id":"cio41uty4000dl8eqksqzisjv"},{"post_id":"cinjqrkq90039nfq6c95hdqgi","category_id":"cinjqrknn0005nfq6t9al9hdm","_id":"cio41utyd000el8eq5g29n5qm"},{"post_id":"cinjqrkrd0042nfq69ffe80ad","category_id":"cinjqrkr9003snfq61qpsh1aj","_id":"cio41utyw000hl8eq6mo4dtf6"},{"post_id":"cinjqrkqj003infq6etx6yfzd","category_id":"cinjqrkop001bnfq6ykq7nfxt","_id":"cio43tqsw0000zweqa9e9w7vn"},{"post_id":"cinjqrkr7003rnfq69uqlaj42","category_id":"cinjqrkr9003snfq61qpsh1aj","_id":"ciokuktzz000008eqy51hj3w8"}],"PostTag":[{"post_id":"cinjqrkng0004nfq6w9qo4tag","tag_id":"cinjqrknn0006nfq69wxyn25m","_id":"cinjqrkns000bnfq67i9x2ecy"},{"post_id":"cinjqrkng0004nfq6w9qo4tag","tag_id":"cinjqrknr0007nfq662xtzgp4","_id":"cinjqrknt000cnfq6hlhn2zuq"},{"post_id":"cinjqrkng0004nfq6w9qo4tag","tag_id":"cinjqrkns0009nfq6rzajkjbg","_id":"cinjqrknu000dnfq6cb19g1w5"},{"post_id":"cinjqrkng0004nfq6w9qo4tag","tag_id":"cinjqrkns000anfq6f9tl7f6w","_id":"cinjqrknu000enfq6j6jjwany"},{"post_id":"cinjqrkny000fnfq61fcpg4fs","tag_id":"cinjqrknn0006nfq69wxyn25m","_id":"cinjqrko2000hnfq60nm0f92o"},{"post_id":"cinjqrkny000fnfq61fcpg4fs","tag_id":"cinjqrknr0007nfq662xtzgp4","_id":"cinjqrko2000infq6lldfxb2o"},{"post_id":"cinjqrkny000fnfq61fcpg4fs","tag_id":"cinjqrkns0009nfq6rzajkjbg","_id":"cinjqrko2000jnfq6jobecw9v"},{"post_id":"cinjqrkny000fnfq61fcpg4fs","tag_id":"cinjqrkns000anfq6f9tl7f6w","_id":"cinjqrko3000knfq61q40ynnk"},{"post_id":"cinjqrko4000lnfq6crlz8gln","tag_id":"cinjqrknn0006nfq69wxyn25m","_id":"cinjqrko6000nnfq6hcascc5v"},{"post_id":"cinjqrko4000lnfq6crlz8gln","tag_id":"cinjqrknr0007nfq662xtzgp4","_id":"cinjqrko6000onfq68jcgo6b7"},{"post_id":"cinjqrko4000lnfq6crlz8gln","tag_id":"cinjqrkns0009nfq6rzajkjbg","_id":"cinjqrko7000pnfq6n6ed5hxl"},{"post_id":"cinjqrko4000lnfq6crlz8gln","tag_id":"cinjqrkns000anfq6f9tl7f6w","_id":"cinjqrko7000qnfq6t9fygwju"},{"post_id":"cinjqrko9000rnfq6d7zjw8fd","tag_id":"cinjqrkoa000snfq6wm4lpfsg","_id":"cinjqrkoc000wnfq6odusp5v4"},{"post_id":"cinjqrko9000rnfq6d7zjw8fd","tag_id":"cinjqrkob000tnfq6lej6t9kg","_id":"cinjqrkod000xnfq6f8s9nrus"},{"post_id":"cinjqrko9000rnfq6d7zjw8fd","tag_id":"cinjqrkob000unfq68pduzicv","_id":"cinjqrkod000ynfq6l2k12vle"},{"post_id":"cinjqrko9000rnfq6d7zjw8fd","tag_id":"cinjqrkoc000vnfq6dyt03ew5","_id":"cinjqrkod000znfq67v52uv1j"},{"post_id":"cinjqrkoe0010nfq6wf05dnk0","tag_id":"cinjqrkoa000snfq6wm4lpfsg","_id":"cinjqrkoh0012nfq6zqzcfbra"},{"post_id":"cinjqrkoi0014nfq6kv333q81","tag_id":"cinjqrknn0006nfq69wxyn25m","_id":"cinjqrkol0016nfq66jqlgi8q"},{"post_id":"cinjqrkoi0014nfq6kv333q81","tag_id":"cinjqrknr0007nfq662xtzgp4","_id":"cinjqrkol0017nfq60clvdi19"},{"post_id":"cinjqrkoi0014nfq6kv333q81","tag_id":"cinjqrkns0009nfq6rzajkjbg","_id":"cinjqrkol0018nfq6j00u37st"},{"post_id":"cinjqrkoi0014nfq6kv333q81","tag_id":"cinjqrkns000anfq6f9tl7f6w","_id":"cinjqrkol0019nfq6y65ovzda"},{"post_id":"cinjqrkon001anfq629l03iq3","tag_id":"cinjqrkop001cnfq642qyjfd4","_id":"cinjqrkor001fnfq6vq1j1iit"},{"post_id":"cinjqrkon001anfq629l03iq3","tag_id":"cinjqrkoq001dnfq6i9hnxfzy","_id":"cinjqrkor001gnfq6qjd7v3nh"},{"post_id":"cinjqrkos001hnfq6pvaxjriz","tag_id":"cinjqrkou001jnfq649w1szf0","_id":"cinjqrkow001nnfq6fl91bw7x"},{"post_id":"cinjqrkos001hnfq6pvaxjriz","tag_id":"cinjqrkou001knfq6z5fnw4ao","_id":"cinjqrkow001onfq6hagnn2tx"},{"post_id":"cinjqrkos001hnfq6pvaxjriz","tag_id":"cinjqrkov001mnfq6rk8nykey","_id":"cinjqrkow001pnfq6kup5uq8u"},{"post_id":"cinjqrkoy001qnfq659wi68t2","tag_id":"cinjqrkp0001snfq63v9wdmlt","_id":"cinjqrkp0001tnfq63tz4l6da"},{"post_id":"cinjqrkp3001vnfq6jno1547e","tag_id":"cinjqrknr0007nfq662xtzgp4","_id":"cinjqrkp5001znfq6j3vwsjym"},{"post_id":"cinjqrkp3001vnfq6jno1547e","tag_id":"cinjqrkns0009nfq6rzajkjbg","_id":"cinjqrkp60020nfq6y60e5mgl"},{"post_id":"cinjqrkp3001vnfq6jno1547e","tag_id":"cinjqrkp5001xnfq6qw75jouz","_id":"cinjqrkp60021nfq6wcb7rqqq"},{"post_id":"cinjqrkp3001vnfq6jno1547e","tag_id":"cinjqrkp5001ynfq6qjm0kutx","_id":"cinjqrkp60022nfq6pcb94xfu"},{"post_id":"cinjqrkp70023nfq6j880739p","tag_id":"cinjqrkp0001snfq63v9wdmlt","_id":"cinjqrkpc0028nfq6y1p3y4zt"},{"post_id":"cinjqrkp70023nfq6j880739p","tag_id":"cinjqrkpa0025nfq6g9douloy","_id":"cinjqrkpc0029nfq6w49a0l71"},{"post_id":"cinjqrkp70023nfq6j880739p","tag_id":"cinjqrkpb0026nfq6u1v903ym","_id":"cinjqrkpc002anfq6w7h7lqla"},{"post_id":"cinjqrkp70023nfq6j880739p","tag_id":"cinjqrkpb0027nfq693pay40a","_id":"cinjqrkpc002bnfq6ooaftpcu"},{"post_id":"cinjqrkph002cnfq631h0zs2o","tag_id":"cinjqrkop001cnfq642qyjfd4","_id":"cinjqrkpm002gnfq64cruwdf4"},{"post_id":"cinjqrkph002cnfq631h0zs2o","tag_id":"cinjqrkpm002enfq6g3xz4v6l","_id":"cinjqrkpn002hnfq660zatig6"},{"post_id":"cinjqrkph002cnfq631h0zs2o","tag_id":"cinjqrkpm002fnfq63m2676xr","_id":"cinjqrkpn002infq6ng6ddj6w"},{"post_id":"cinjqrkpo002jnfq6xp9c0nlz","tag_id":"cinjqrkop001cnfq642qyjfd4","_id":"cinjqrkpr002mnfq67idokmd0"},{"post_id":"cinjqrkpo002jnfq6xp9c0nlz","tag_id":"cinjqrkoq001dnfq6i9hnxfzy","_id":"cinjqrkpr002nnfq6mvtn7ovs"},{"post_id":"cinjqrkpo002jnfq6xp9c0nlz","tag_id":"cinjqrkpq002lnfq6b1oxoic8","_id":"cinjqrkpr002onfq62nb5uc1g"},{"post_id":"cinjqrkpt002pnfq6h2hvwrok","tag_id":"cinjqrkop001cnfq642qyjfd4","_id":"cinjqrkpx002unfq6pvwboe3g"},{"post_id":"cinjqrkpt002pnfq6h2hvwrok","tag_id":"cinjqrkpv002rnfq6jieat680","_id":"cinjqrkpy002vnfq6671oxzsn"},{"post_id":"cinjqrkpt002pnfq6h2hvwrok","tag_id":"cinjqrkpw002snfq6qdnbkejd","_id":"cinjqrkpy002wnfq6bnourr00"},{"post_id":"cinjqrkpt002pnfq6h2hvwrok","tag_id":"cinjqrkpw002tnfq63xc7er1m","_id":"cinjqrkpy002xnfq64elyn47h"},{"post_id":"cinjqrkpz002ynfq6gp2j1ujv","tag_id":"cinjqrknr0007nfq662xtzgp4","_id":"cinjqrkq20031nfq62wb883n4"},{"post_id":"cinjqrkpz002ynfq6gp2j1ujv","tag_id":"cinjqrkns0009nfq6rzajkjbg","_id":"cinjqrkq20032nfq65nva8d7g"},{"post_id":"cinjqrkpz002ynfq6gp2j1ujv","tag_id":"cinjqrkq10030nfq6dl00ygvb","_id":"cinjqrkq20033nfq6c1lr98l6"},{"post_id":"cinjqrkq30034nfq6zq4gigcp","tag_id":"cinjqrknr0007nfq662xtzgp4","_id":"cinjqrkq70036nfq6qahsmg14"},{"post_id":"cinjqrkq30034nfq6zq4gigcp","tag_id":"cinjqrkns0009nfq6rzajkjbg","_id":"cinjqrkq70037nfq6ftd519s3"},{"post_id":"cinjqrkq30034nfq6zq4gigcp","tag_id":"cinjqrkq10030nfq6dl00ygvb","_id":"cinjqrkq70038nfq60ikhcdby"},{"post_id":"cinjqrkq90039nfq6c95hdqgi","tag_id":"cinjqrknr0007nfq662xtzgp4","_id":"cinjqrkqi003dnfq6ceyz96zr"},{"post_id":"cinjqrkq90039nfq6c95hdqgi","tag_id":"cinjqrkns0009nfq6rzajkjbg","_id":"cinjqrkqi003enfq6pl832lwj"},{"post_id":"cinjqrkq90039nfq6c95hdqgi","tag_id":"cinjqrkq10030nfq6dl00ygvb","_id":"cinjqrkqi003fnfq6g28uesek"},{"post_id":"cinjqrkq90039nfq6c95hdqgi","tag_id":"cinjqrkqh003bnfq66tu5482q","_id":"cinjqrkqi003gnfq6sm2bcq4k"},{"post_id":"cinjqrkq90039nfq6c95hdqgi","tag_id":"cinjqrkqh003cnfq6ozdxb15q","_id":"cinjqrkqi003hnfq6jzhfd6sl"},{"post_id":"cinjqrkqj003infq6etx6yfzd","tag_id":"cinjqrkop001cnfq642qyjfd4","_id":"cinjqrkr5003nnfq6gh9znc33"},{"post_id":"cinjqrkqj003infq6etx6yfzd","tag_id":"cinjqrkr0003knfq6q1gr3nin","_id":"cinjqrkr6003onfq6bs7covgn"},{"post_id":"cinjqrkqj003infq6etx6yfzd","tag_id":"cinjqrkr1003lnfq6pxd9y8ws","_id":"cinjqrkr6003pnfq6m6it3imm"},{"post_id":"cinjqrkqj003infq6etx6yfzd","tag_id":"cinjqrkr1003mnfq6awsjm53u","_id":"cinjqrkr6003qnfq6qj80ybmu"},{"post_id":"cinjqrkr7003rnfq69uqlaj42","tag_id":"cinjqrkr9003tnfq6wqxxfyz9","_id":"cinjqrkrc003ynfq6n96f08gv"},{"post_id":"cinjqrkr7003rnfq69uqlaj42","tag_id":"cinjqrkra003unfq68w49f9s7","_id":"cinjqrkrc003znfq6xduw6ade"},{"post_id":"cinjqrkr7003rnfq69uqlaj42","tag_id":"cinjqrkrb003wnfq6otf57b41","_id":"cinjqrkrc0040nfq6i9v620bh"},{"post_id":"cinjqrkr7003rnfq69uqlaj42","tag_id":"cinjqrkrb003xnfq6lvfwwci4","_id":"cinjqrkrc0041nfq68lenh9so"},{"post_id":"cinjqrkrd0042nfq69ffe80ad","tag_id":"cinjqrkr9003tnfq6wqxxfyz9","_id":"cinjqrkrf0044nfq692aok3rv"},{"post_id":"cinjqrkrd0042nfq69ffe80ad","tag_id":"cinjqrkra003unfq68w49f9s7","_id":"cinjqrkrf0045nfq61dy3tkmg"},{"post_id":"cinjqrkrd0042nfq69ffe80ad","tag_id":"cinjqrkrb003wnfq6otf57b41","_id":"cinjqrkrg0046nfq6vmrii4yl"},{"post_id":"cinjqrkqj003infq6etx6yfzd","tag_id":"cio43tqsx0001zweq6he95xo4","_id":"cio43tqti0002zweqehkt88ri"}],"Tag":[{"name":"TensorFlow","_id":"cinjqrknn0006nfq69wxyn25m"},{"name":"Machine Learning","_id":"cinjqrknr0007nfq662xtzgp4"},{"name":"Deep Learning","_id":"cinjqrkns0009nfq6rzajkjbg"},{"name":"Artificial Intelligence","_id":"cinjqrkns000anfq6f9tl7f6w"},{"name":"Python","_id":"cinjqrkoa000snfq6wm4lpfsg"},{"name":"Whoosh","_id":"cinjqrkob000tnfq6lej6t9kg"},{"name":"Jieba","_id":"cinjqrkob000unfq68pduzicv"},{"name":"Search Engine","_id":"cinjqrkoc000vnfq6dyt03ew5"},{"name":"Hexo","_id":"cinjqrkop001cnfq642qyjfd4"},{"name":"Next","_id":"cinjqrkoq001dnfq6i9hnxfzy"},{"name":"Network","_id":"cinjqrkou001jnfq649w1szf0"},{"name":"Windows","_id":"cinjqrkou001knfq6z5fnw4ao"},{"name":"Win10","_id":"cinjqrkov001mnfq6rk8nykey"},{"name":"Markdown","_id":"cinjqrkp0001snfq63v9wdmlt"},{"name":"Word2Vector","_id":"cinjqrkp5001xnfq6qw75jouz"},{"name":"Word Embedding","_id":"cinjqrkp5001ynfq6qjm0kutx"},{"name":"Equation","_id":"cinjqrkpa0025nfq6g9douloy"},{"name":"MathJax","_id":"cinjqrkpb0026nfq6u1v903ym"},{"name":"MarkdownPad 2","_id":"cinjqrkpb0027nfq693pay40a"},{"name":"SEO","_id":"cinjqrkpm002enfq6g3xz4v6l"},{"name":"Web","_id":"cinjqrkpm002fnfq63m2676xr"},{"name":"LeanCloud","_id":"cinjqrkpq002lnfq6b1oxoic8"},{"name":"Github Page","_id":"cinjqrkpv002rnfq6jieat680"},{"name":"Blog","_id":"cinjqrkpw002snfq6qdnbkejd"},{"name":"Personal Website","_id":"cinjqrkpw002tnfq63xc7er1m"},{"name":"CNN","_id":"cinjqrkq10030nfq6dl00ygvb"},{"name":"Sentence Model","_id":"cinjqrkqh003bnfq66tu5482q"},{"name":"NLP","_id":"cinjqrkqh003cnfq6ozdxb15q"},{"name":"Gitcafe","_id":"cinjqrkr0003knfq6q1gr3nin"},{"name":"DNS","_id":"cinjqrkr1003lnfq6pxd9y8ws"},{"name":"Github","_id":"cinjqrkr1003mnfq6awsjm53u"},{"name":"Interview","_id":"cinjqrkr9003tnfq6wqxxfyz9"},{"name":"Job","_id":"cinjqrkra003unfq68w49f9s7"},{"name":"IT","_id":"cinjqrkrb003wnfq6otf57b41"},{"name":"Algorithm","_id":"cinjqrkrb003xnfq6lvfwwci4"},{"name":"Coding","_id":"cio43tqsx0001zweq6he95xo4"}]}}